<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>HPC - 分类 -</title><link>https://gaohongy.github.io/blog/categories/hpc/</link><description>HPC - 分类 -</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 30 Apr 2024 20:49:00 +0800</lastBuildDate><atom:link href="https://gaohongy.github.io/blog/categories/hpc/" rel="self" type="application/rss+xml"/><item><title>OpenMP</title><link>https://gaohongy.github.io/blog/posts/hpc/openmp/</link><pubDate>Tue, 30 Apr 2024 20:49:00 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/openmp/</guid><description>Understand the pragma1 This command is the most important element for OpenMP. On the one hand, it&amp;rsquo;s called 编译制导指令，because these commands instruct the compiler to execute some particular operations when compiling. On the other hand, it&amp;rsquo;s like to the #define command, which is called 预处理指令(Preproc</description></item><item><title>Matrix Multiplication</title><link>https://gaohongy.github.io/blog/posts/hpc/matrix-multiplication/</link><pubDate>Sun, 28 Apr 2024 10:00:06 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/matrix-multiplication/</guid><description>GEMM（General Matrix Multiplication）-通用矩阵乘 BLAS (Basic Linear Algebra Subprograms) - 基本线性代数子程序 SGEMM (Single precision General Matrix Multiply) - 单精度矩阵乘法 DGEMM (Double precision General Matrix Multiply) -</description></item><item><title>Memory Alignment</title><link>https://gaohongy.github.io/blog/posts/hpc/memory-alignment/</link><pubDate>Sat, 23 Mar 2024 21:08:23 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/memory-alignment/</guid><description>内存的编址单位是字节 但是内存 IO 的单位是字长，此数值应当和 数据通路 的宽度有关，当数据通路为 32 位时，那么一次内存 IO 就会读取4B数据1 对于上述内容</description></item><item><title>Parallel Computing</title><link>https://gaohongy.github.io/blog/posts/hpc/parallel-computing/</link><pubDate>Mon, 29 Jan 2024 23:41:59 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/parallel-computing/</guid><description>Law 并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系 The difference between Amdahl&amp;rsquo;s Law and Gustafson&amp;rsquo;s Law The reason for</description></item><item><title>Kokkos Source Code Analysis</title><link>https://gaohongy.github.io/blog/posts/hpc/kokkos-source-code-analysis/</link><pubDate>Fri, 05 Jan 2024 17:39:32 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/kokkos-source-code-analysis/</guid><description>Usage Install &amp;amp; CMake 1 2 3 4 5 6 7 cd some_software-1.4.2 mkdir build cd build cmake .. cmake --build . # It is equivalent to make cmake --build . --target install # It is equivalent to make install After the above flow, we can use Kokkos by CMake directly. Source Code &amp;amp; CMake1 file sturcture: 1 2 3 4 5 . ├── CMakeLists.txt ├──</description></item><item><title>MPI</title><link>https://gaohongy.github.io/blog/posts/hpc/mpi/</link><pubDate>Tue, 12 Dec 2023 21:49:28 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/mpi/</guid><description>mpicc, mpic++, mpicxx mpiexec, mpirun mpichversion mpicc 仅可编译 .c 文件，编译 .cpp文件会报错 mpic++ 编译 .cpp 文件 MPI标准的不同实现：MPICH、MVAPICH、MVAPICH2、Open</description></item><item><title>C++ Asynchronous and Synchronous Mechanisms</title><link>https://gaohongy.github.io/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/</link><pubDate>Sun, 10 Sep 2023 22:06:00 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/</guid><description>Asynchronization (Multithreading) The first thing we need to do is understanding the correlations between multithreading and parallel computing. Multithreading is one of the many ways to implement parallel computing. Why do we need asynchronous mechanisms ? If we excute some time-consuming operations in main thread, they will block main thread which causes the bad user experience. An effective way to solve this problem is to use asynchronous mechanisms. Creating a</description></item><item><title>GPU Structure and Programing(CUDA)</title><link>https://gaohongy.github.io/blog/posts/hpc/gpu-structure-and-programing/</link><pubDate>Wed, 31 May 2023 11:17:35 +0800</pubDate><author>ghy</author><guid>https://gaohongy.github.io/blog/posts/hpc/gpu-structure-and-programing/</guid><description>Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和</description></item></channel></rss>