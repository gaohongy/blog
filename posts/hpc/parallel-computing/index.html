<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Parallel Computing - </title><meta name=author content><meta name=author-link content><meta name=description content="Law
  
    
  
并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系"><meta itemprop=name content="Parallel Computing"><meta itemprop=description content="Law 并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系"><meta itemprop=datePublished content="2024-01-29T23:41:59+08:00"><meta itemprop=dateModified content="2024-03-08T16:35:12+08:00"><meta itemprop=wordCount content="1171"><meta itemprop=keywords content="HPC"><meta property="og:url" content="https://gaohongy.github.io/blog/posts/hpc/parallel-computing/"><meta property="og:title" content="Parallel Computing"><meta property="og:description" content="Law 并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-29T23:41:59+08:00"><meta property="article:modified_time" content="2024-03-08T16:35:12+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Parallel Computing"><meta name=twitter:description content="Law 并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://gaohongy.github.io/blog/posts/hpc/parallel-computing/><link rel=prev href=https://gaohongy.github.io/blog/posts/hpc/kokkos-source-code-analysis/><link rel=next href=https://gaohongy.github.io/blog/posts/c-c++/c-c++-const-keyword-unscramble/><link rel=stylesheet href=/blog/css/style.min.css><link rel=preload href=/blog/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/blog/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Parallel Computing","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/gaohongy.github.io\/blog\/posts\/hpc\/parallel-computing\/"},"genre":"posts","wordcount":1171,"url":"https:\/\/gaohongy.github.io\/blog\/posts\/hpc\/parallel-computing\/","datePublished":"2024-01-29T23:41:59+08:00","dateModified":"2024-03-08T16:35:12+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/blog/ title><img loading=lazy src=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png alt=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png data-title=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png width=26 height=26 class=logo style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text></span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/blog/posts/>Post</a></li><li class=menu-item><a class=menu-link href=/blog/categories/>Category</a></li><li class=menu-item><a class=menu-link href=/blog/tags/>Tag</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents ..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/blog/ title><img loading=lazy src=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png alt=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png data-title=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png width=26 height=26 class=logo style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text></span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents ..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></li><li class=menu-item><a class=menu-link href=/blog/posts/>Post</a></li><li class=menu-item><a class=menu-link href=/blog/categories/>Category</a></li><li class=menu-item><a class=menu-link href=/blog/tags/>Tag</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=Collections></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Parallel Computing</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
Anonymous</span></span><span class=post-included-in>&nbsp;included in <a href=/blog/categories/hpc/ class=post-category title="Category - HPC"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> HPC</a></span></div><div class=post-meta-line><span title="published on 2024-01-29 23:41:59"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2024-01-29>2024-01-29</time></span>&nbsp;<span title="Updated on 2024-03-08 16:35:12"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden=true></i><time datetime=2024-03-08>2024-03-08</time></span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#law>Law</a><ul><li><a href=#the-difference-between-amdahls-law-and-gustafsons-law>The difference between Amdahl&rsquo;s Law and Gustafson&rsquo;s Law</a></li><li><a href=#contradiction>Contradiction</a></li></ul></li><li><a href=#motivation>Motivation</a></li><li><a href=#classification>Classification</a><ul><li><a href=#shared-memory-parallel-programming>Shared Memory Parallel Programming</a></li><li><a href=#distributed-memory-parallel-programming>Distributed Memory Parallel Programming</a></li></ul></li><li><a href=#programming-model-definition>Programming model Definition</a></li><li><a href=#performance-evaluation>Performance Evaluation</a></li><li><a href=#data-parallel>Data Parallel</a></li><li><a href=#example>Example</a></li></ul></nav></div></div><div class=content id=content data-end-flag=EOF><h2 id=law class=heading-element><span>Law</span>
<a href=#law class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 <strong>加速比</strong> 与 <strong>系统串行化程度</strong>、<strong>CPU核心数</strong> 之间的关系</p><h3 id=the-difference-between-amdahls-law-and-gustafsons-law class=heading-element><span>The difference between Amdahl&rsquo;s Law and Gustafson&rsquo;s Law</span>
<a href=#the-difference-between-amdahls-law-and-gustafsons-law class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>The reason for the discrepancy between the speed up predictions by the two laws is that<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>:</p><ol><li>Gustafson&rsquo;s Law assumes that the amount of work to be done increases as the number of processor increases!</li><li>Amdahl&rsquo;s Law, on the other hand, assumes the amount of work to be done is static no matter how much parallelization is available.</li></ol><p>简单来说，就是 Amdahl 认为工作负载是不变的，但是 Gustafson 认为工作负载是变化的。</p><p>由于在 Amdahl 的假设中，工作负载不变，那么在计算加速比时就可以以加速前的时间处于加速后的时间</p><p>由于在 Gustafson 的观点中，工作负载是变化的，所以计算加速比更好的方法是通过比较相同时间处理的数据量</p><p>假设基准工作量是 1，并行比例是 f，串行比例是 1-f，则加速前并行部分工作量为 f，串行部分工作量为 1-f，加速后并行部分工作量为 f * p（p是处理器数量，因为是并行，所以不同处理器可以同时完成工作），串行部分工作量不变仍为 1-f（由于是串行，即使处理器增多也需要逐一执行，所以完成的工作量不变）</p><p>因此 Gustafson 定律得出的加速比为 $speedup = \frac{(1-f) + f \times p}{(1 -f) + f}$</p><h3 id=contradiction class=heading-element><span>Contradiction</span>
<a href=#contradiction class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>根据 Amdahl，即使处理器数量无限增大，加速比是存在一个上限的。但是 Gustafson 得出的结论却是 随着处理器数量增大，加速比可以无限增大。</p><p>两个定律的结论不同，这是不是说两个定律中有一个是错误的呢，其实不然，两者的差异其实是因为这两个定律对一个客观事实从不同角度去审视的后果，他们的侧重点不同。<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>Amdahl强调，当串行化比例一定时，加速比是有上限的，不管你堆叠多少个CPU参与计算，都不能突破上限。</p><p>而Gustafson 定律的出发点不同，对Gustafson定律来说，如果可被并行化的代码所占比例足够大，那么加速比就能随着CPU的数量线性增长。</p><p>所以这两者并不矛盾，从极端的角度来说，如果系统中没有可以被并行化的代码，那么对于两个定律，其 加速比是1，反之，如果系统中可被并行化的代码比例100%，那么两个定律得到的加速比都是处理器个数。</p><h2 id=motivation class=heading-element><span>Motivation</span>
<a href=#motivation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>Moores&rsquo;s Law states that, when the price remains constant, the number of components per chip that can be accommodated approximately doubles every 18-24 months, leading to a corresponding doubling of performance.</p><p>The phenomenon of failure of Moores&rsquo;s Law means that now we use more transistors to increse core number instead of frequency per chip(performance per chip).</p><p>So it is the developing tendency that how to use multi-cores to complete the computation tasks now, which is called parallel-computing.</p><h2 id=classification class=heading-element><span>Classification</span>
<a href=#classification class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=shared-memory-parallel-programming class=heading-element><span>Shared Memory Parallel Programming</span>
<a href=#shared-memory-parallel-programming class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>Manual: multi-threading</li><li>Automatic: OpenMP</li></ol><h3 id=distributed-memory-parallel-programming class=heading-element><span>Distributed Memory Parallel Programming</span>
<a href=#distributed-memory-parallel-programming class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>Message passing: e.g. MPI</li></ol><p>并行编程模型和并行计算机的底层硬件结构是相互对应的，是有一种硬件结构从而对应到一种并行编程模型，对应关系如下：</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051845492.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>如何理解编程模型所处的层次结构
以下图多线程编程模型为例，编程模型层或者说抽象层给使用者提供的接口就是“线程”，向底层则对应到pthread等多种类型的多线程库实现，再向下则是OS系统调用API，然后到达硬件层</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051822525.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h2 id=programming-model-definition class=heading-element><span>Programming model Definition</span>
<a href=#programming-model-definition class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>It is made of languages and libraries that create abstract view of the machine.</p><p>The key concepts for creating a parallel programming model:</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202402051844780.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h2 id=performance-evaluation class=heading-element><span>Performance Evaluation</span>
<a href=#performance-evaluation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>Two important factor:</p><ol><li>what needs to be done</li><li>what it costs to do it</li></ol><h2 id=data-parallel class=heading-element><span>Data Parallel</span>
<a href=#data-parallel class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>一般认为，向量化 和 并行 还是有一点差别的，并行更多强调的是线程级或者说核一级的并行，向量化指代的更多是在一个核心上通过向量化指令和底层支持向量化的硬件结构实现的SIMD</p><h2 id=example class=heading-element><span>Example</span>
<a href=#example class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://gist.github.com/nadavrot/5b35d44e8ba3dd718e595e40184d03f://gist.github.com/nadavrot/5b35d44e8ba3dd718e595e40184d03f0 target=_blank rel="external nofollow noopener noreferrer">High-Performance Matrix Multiplication</a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href="https://infogram.com/amdahl-vs-gustafson-1g6qo2qq66nk278?ref=hackernoon.com#:~:text=The%20reason%20for%20the%20discrepancy%20between%20the%20speed,static%20no%20matter%20how%20much%20parallelization%20is%20available." target=_blank rel="external nofollow noopener noreferrer">AMDAHL VS. GUSTAFSON</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href="https://developer.aliyun.com/article/1093916#:~:text=%E5%BF%AB%E7%9A%84%E9%80%9F%E5%BA%A6%E3%80%82-,%E4%BA%8C%E3%80%81%E6%98%AF%E5%90%A6%E7%9F%9B%E7%9B%BE,-%E4%B8%A4%E4%B8%AA%E5%AE%9A%E5%BE%8B" target=_blank rel="external nofollow noopener noreferrer">Whether the Amdahl&rsquo;s law and Gustafon&rsquo;s law contradict each other?</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="Updated on 2024-03-08 16:35:12">Updated on 2024-03-08&nbsp;</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/blog/>Home</a></span></section></div><div class=post-nav><a href=/blog/posts/hpc/kokkos-source-code-analysis/ class=post-nav-item rel=prev title="Kokkos Source Code Analysis"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Kokkos Source Code Analysis</a>
<a href=/blog/posts/c-c++/c-c++-const-keyword-unscramble/ class=post-nav-item rel=next title="C C++ Const Keyword Unscramble">C C++ Const Keyword Unscramble<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=Contents><h2 class=toc-title>Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>This website works best with JavaScript enabled.</div></noscript></div><link rel=stylesheet href=/blog/lib/lightgallery/css/lightgallery-bundle.min.css><link rel=preload href=/blog/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/blog/lib/cookieconsent/cookieconsent.min.css><script src=/blog/lib/autocomplete/autocomplete.min.js defer></script><script src=/blog/lib/fuse/fuse.min.js defer></script><script src=/blog/lib/twemoji/twemoji.min.js defer></script><script src=/blog/lib/lightgallery/lightgallery.min.js defer></script><script src=/blog/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.js defer></script><script src=/blog/lib/lightgallery/plugins/zoom/lg-zoom.min.js defer></script><script src=/blog/lib/katex/katex.min.js defer></script><script src=/blog/lib/katex/auto-render.min.js defer></script><script src=/blog/lib/katex/copy-tex.min.js defer></script><script src=/blog/lib/katex/mhchem.min.js defer></script><script src=/blog/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"Got it!",link:"Learn more",message:"This website uses Cookies to improve your experience."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},lightgallery:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/blog/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:20,minMatchCharLength:2,noResultsFound:"No results found",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},twemoji:!0,version:"v0.3.9"}</script><script src=/blog/js/theme.min.js defer></script></body></html>