<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>GPU Structure and Programing - </title><meta name=author content><meta name=author-link content><meta name=description content="Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和"><meta itemprop=name content="GPU Structure and Programing"><meta itemprop=description content="Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和"><meta itemprop=datePublished content="2023-05-31T11:17:35+08:00"><meta itemprop=dateModified content="2024-06-10T01:11:59+08:00"><meta itemprop=wordCount content="17611"><meta itemprop=keywords content="HPC"><meta property="og:url" content="https://gaohongy.github.io/blog/posts/hpc/gpu-structure-and-programing/"><meta property="og:title" content="GPU Structure and Programing"><meta property="og:description" content="Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-31T11:17:35+08:00"><meta property="article:modified_time" content="2024-06-10T01:11:59+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="GPU Structure and Programing"><meta name=twitter:description content="Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical href=https://gaohongy.github.io/blog/posts/hpc/gpu-structure-and-programing/><link rel=prev href=https://gaohongy.github.io/blog/posts/linux/linux-basic-knowledge/><link rel=next href=https://gaohongy.github.io/blog/posts/compile-link/cuda-compilation/><link rel=stylesheet href=/blog/css/style.min.css><link rel=preload href=/blog/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/blog/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"GPU Structure and Programing","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/gaohongy.github.io\/blog\/posts\/hpc\/gpu-structure-and-programing\/"},"genre":"posts","wordcount":17611,"url":"https:\/\/gaohongy.github.io\/blog\/posts\/hpc\/gpu-structure-and-programing\/","datePublished":"2023-05-31T11:17:35+08:00","dateModified":"2024-06-10T01:11:59+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Author"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/blog/ title><img loading=lazy src=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png alt=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png data-title=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png width=26 height=26 class=logo style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text></span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/blog/posts/>Post</a></li><li class=menu-item><a class=menu-link href=/blog/categories/>Category</a></li><li class=menu-item><a class=menu-link href=/blog/tags/>Tag</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder="Search titles or contents ..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/blog/ title><img loading=lazy src=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png alt=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png data-title=https://img2024.cnblogs.com/blog/1898659/202406/1898659-20240630192930755-1492568318.png width=26 height=26 class=logo style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text></span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents ..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></li><li class=menu-item><a class=menu-link href=/blog/posts/>Post</a></li><li class=menu-item><a class=menu-link href=/blog/categories/>Category</a></li><li class=menu-item><a class=menu-link href=/blog/tags/>Tag</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=Collections></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>GPU Structure and Programing</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
Anonymous</span></span><span class=post-included-in>&nbsp;included in <a href=/blog/categories/hpc/ class=post-category title="Category - HPC"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> HPC</a></span></div><div class=post-meta-line><span title="published on 2023-05-31 11:17:35"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2023-05-31>2023-05-31</time></span>&nbsp;<span title="Updated on 2024-06-10 01:11:59"><i class="fa-regular fa-calendar-check fa-fw me-1" aria-hidden=true></i><time datetime=2024-06-10>2024-06-10</time></span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#todo>Todo</a></li><li><a href=#宏观视角>宏观视角</a></li><li><a href=#simd--simt>SIMD & SIMT</a></li><li><a href=#kernel-hardware-mapping>Kernel hardware mapping</a></li><li><a href=#hardware-structure>Hardware structure</a><ul><li><a href=#simt-architecture>SIMT Architecture</a></li></ul></li><li><a href=#memory-structure>Memory structure</a><ul><li><a href=#cache>Cache</a><ul><li><a href=#l2-cache>L2 cache</a></li></ul></li><li><a href=#register--local-memory>Register & Local Memory</a></li><li><a href=#global-memory>Global Memory</a><ul><li><a href=#coalesced--uncoalesced>coalesced & uncoalesced</a></li><li><a href=#common-memory-access-types>Common memory access types</a></li></ul></li><li><a href=#shared-memory>Shared Memory</a><ul><li><a href=#create-shared-memory>Create Shared Memory</a></li><li><a href=#bank-conflict>Bank Conflict</a></li></ul></li><li><a href=#constant-memory>Constant Memory</a></li><li><a href=#host-side-memory>Host Side Memory</a><ul><li><a href=#pageable-memory>pageable memory</a></li><li><a href=#pinned-memory>pinned memory</a></li><li><a href=#zero-copy-memory>Zero-Copy Memory</a></li></ul></li><li><a href=#unified-memory>Unified Memory</a><ul><li><a href=#optimization-techniques>Optimization Techniques</a></li></ul></li></ul></li><li><a href=#memory-api>Memory API</a><ul><li><a href=#2d-array>2D Array</a></li></ul></li><li><a href=#software-structure>Software structure</a></li><li><a href=#software-stack>Software stack</a></li><li><a href=#kernel-function>Kernel Function</a></li><li><a href=#指针>指针</a><ul><li><a href=#设备指针>设备指针</a></li><li><a href=#主机指针与设备指针数据拷贝>主机指针与设备指针数据拷贝</a></li></ul></li><li><a href=#function-type>Function type</a></li><li><a href=#common-parallelization-methods>Common Parallelization methods</a><ul><li><a href=#grid-stride-loop>Grid-stride loop</a></li><li><a href=#fixed-location-solve-the-data-conflict>Fixed location solve the data conflict</a></li></ul></li><li><a href=#synchronization>Synchronization</a><ul><li><a href=#atomic>Atomic</a></li></ul></li><li><a href=#asynchronization-cuda-stream>Asynchronization (CUDA stream)</a><ul><li><a href=#execution-order>Execution order</a></li><li><a href=#related-api>Related API</a></li><li><a href=#如何理解流>如何理解流</a></li></ul></li><li><a href=#c-encapsulation>C++ Encapsulation</a></li><li><a href=#gpu-execution-core>GPU execution core</a></li><li><a href=#device-api>Device API</a></li><li><a href=#cuda-libraries>CUDA Libraries</a><ul><li><a href=#cublas>cuBLAS</a></li><li><a href=#cusolver>cuSOLVER</a></li><li><a href=#cufft>cuFFT</a></li><li><a href=#thrust>Thrust</a></li></ul></li><li><a href=#cuda-compilation>CUDA Compilation</a></li><li><a href=#gpgpu-sim>GPGPU-Sim</a><ul><li><a href=#how-to-run>How to run</a></li><li><a href=#source-code-organization-structure>Source code organization structure</a></li><li><a href=#reference>Reference</a></li></ul></li><li><a href=#related-programming-models>Related Programming Models</a></li><li><a href=#如何使用cuda加速程序>如何使用CUDA加速程序</a><ul><li><a href=#公共概念>公共概念</a></li><li><a href=#对任务划分的理解>对任务划分的理解</a></li><li><a href=#矩阵乘法>矩阵乘法</a><ul><li><a href=#tiled-matrix-multiplication>Tiled Matrix Multiplication</a></li><li><a href=#reference-1>Reference</a></li></ul></li><li><a href=#reduction>Reduction</a></li><li><a href=#convolution>Convolution</a></li><li><a href=#understand-of-convolution>understand of convolution</a><ul><li><a href=#tiled-1d-convolution>Tiled 1D Convolution</a></li><li><a href=#2d-convolution>2D Convolution</a></li><li><a href=#3d-convolutoin>3D Convolutoin</a></li></ul></li></ul></li><li><a href=#gpu-microarchitecturesimt-core>GPU Microarchitecture(SIMT Core)</a><ul><li><a href=#one-loop-approximation>One-Loop Approximation</a><ul><li><a href=#simt-stack>SIMT stack</a></li><li><a href=#simt-deadlock>SIMT deadlock</a></li></ul></li><li><a href=#two-loop-approximation>Two-Loop Approximation</a><ul><li><a href=#scoreboard>Scoreboard</a></li></ul></li><li><a href=#three-loop-approximation>Three-Loop Approximation</a><ul><li><a href=#operand-collector>Operand Collector</a></li><li><a href=#instruction-replay>Instruction Replay</a></li></ul></li><li><a href=#memory-system>Memory system</a><ul><li><a href=#first-level>First Level</a></li><li><a href=#memory-partition-unit>Memory Partition Unit</a></li></ul></li><li><a href=#warp>Warp</a><ul><li><a href=#warp-scheduling-strategy>Warp Scheduling Strategy</a></li></ul></li></ul></li><li><a href=#cuda-related-documents>CUDA Related Documents</a></li><li><a href=#reference-2>Reference</a></li></ul></nav></div></div><div class=content id=content data-end-flag=EOF><h2 id=todo class=heading-element><span>Todo</span>
<a href=#todo class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><ul><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> L2 cache gpgpu-sim 源码分析</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> Bank conflict 的题目分析</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> warp occupancy 概念和计算</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> 由broadcast式访问global memory引申的对于constant memory的理解和使用</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> 并行化+访存优化，并行化中有一个branch divergence的问题</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> 查找 DRAM burst突发传送官方文档说明</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> 发现矩阵乘法是一个结合各种并行算法以及CUDA硬件架构知识的好的入手点，create一门课程 “从矩阵乘法入门并行计算-CUDA版”</li><li><i class="fa-regular fa-square fa-fw" aria-hidden=true></i> 需要验证如果shared memory中的元素大小和bank大小不一致时，访问其中更小的数据是否会造成bank conflict。需要借助nvprof，但是nvprof在选择检测bank事件时无法正常工作</li></ul><blockquote><ul><li>CUDA C只是对标准C进行了语言级的扩展，通过增加一些修饰符使编译器可以确定哪些代码在主机上运行，哪些代码在设备上运行</li><li>GPU计算的应用前景很大程度上取决于能否从问题中发掘出大规模并行性</li></ul></blockquote><h2 id=宏观视角 class=heading-element><span>宏观视角</span>
<a href=#%e5%ae%8f%e8%a7%82%e8%a7%86%e8%a7%92 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>高性能计算的第一性原理：访存优化。所有的努力（优化硬件设计，优化算法）都是在试图解决内存墙。</p><p>访存优化3大关键：</p><ul><li>一是减少数据搬运</li><li>二是减少数据访存延时</li><li>三是保证负载均衡</li></ul><p>GPU中的并行算法设计：设计block和thread的workload，搞清楚一个block负责哪部分的计算，一个thread要负责哪部分的计算。而设计的原则就是尽可能地减少访存，提高数据的复用概率，然后让所有的处理器都满负荷地进行工作，不能浪费。</p><h2 id=simd--simt class=heading-element><span>SIMD & SIMT</span>
<a href=#simd--simt class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>涉及到AVX指令，正在尝试
说明两种方式的区别</p><p>The two most important things about SIMD and SIMT are:</p><ol><li>How is the SIMT to implement ?</li><li>How is the SIMD to calculate ?</li></ol><p>GPU从整体上来说是SIMT，但是到Warp层次后实际就是SIMD了</p><h2 id=kernel-hardware-mapping class=heading-element><span>Kernel hardware mapping</span>
<a href=#kernel-hardware-mapping class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>kernel function -> GPU
block -> SM（one block can only be executed by one SM, but one SM can execute multiple blocks)</p><blockquote><p>这里有一个疑问，一个SM可以执行多个block，多个block的执行是并发的还是可以并行的，换个角度来说就是正在执行的warp是同属于一个block的，还是可以隶属于多个block</p></blockquote><p>关于此问题，还尚未找到官方资料中给出的证据，暂且认为SM上执行的warp可能属于不同block，也就是可以理解为开始执行kernel函数后，grid中的多个block被分配到某一个SM上，然后在SM的视角下就不再有block的概念，它所能看到的就是一些warp，通过warp scheduler来对warp进行调度，并且认为block一开始被分配到某个SM后不会在执行过程中去更换SM，直到执行完毕。</p><p>这种理解方式有一定的合理性，原因在于grid，block，warp本身就是为programmer所提供的逻辑概念，对于硬件来说，它能看到的不过是一些thread，它调度的也是thread。但是对于人来说，thread这一调度单位太细，很难实现对具体问题的抽象，所以才提供了更高一级的概念，即grid，block和warp。从这一角度来看，一个SM在同一时间能调度多个block就是合理的。</p><p>thread -> SP</p><p>main time consuming:</p><ol><li>kernel function startup</li><li>thread block switch</li></ol><h2 id=hardware-structure class=heading-element><span>Hardware structure</span>
<a href=#hardware-structure class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>Grid、Block are login concepts, they are created by CUDA for programmers.
According to the real physical level, every SM in GPU will excute multiple blocks, and it will divides block into multiple warps. The basic execution unit of SM is warp.</p><p>In fact, the amazing computing capility of GPU comes from multiple thread. But we couldn&rsquo;t just use thread this only one concept to program since that it is difficult to describe the job or we can say organize them.</p><p>So, CUDA introduce the concept of Grid and Block which are logic concepts, they are created by CUDA for programmers. In fact, we we can see them as a organization structure.</p><p>首先给出一个gpu的简易逻辑图，理解gpu，sm，sp，warp scheduler的关系</p><p>一个kernel 函数是一个grid，对应整个gpu
然后grid中包含很多block，这个和gpu中的sm对应
block包含很多thread，这个和sm中的sp对应</p><p>sm的组成：</p><ol><li>register</li><li>shared memory</li><li>the cache of constant memory</li><li>the cache of texture and surface memory</li><li>L1 cache</li><li>warp scheduler</li><li>SP（截止到2023/12/09，对sp的理解是它只是一个泛称，不是特指某种具体的运算单元，SP可能对应于不同的硬件组件，包括浮点运算单元（FP）、整数运算单元（INT）、特殊功能单元（SFU））</li></ol><p>所以调度问题分为两个层面：</p><ol><li>对于block的调度: 这个和sm有关系，多个block和多个sm，sm可以任意选择block执行，而且这种选择并不是一选定终生，中间过程还可以调整，但是block并不能拆分，只能整个放到sm上</li><li>对于thread的调度: 把一个block放到一个sm上，这时候我们的视角就要缩小到这个sm中了，这时候我们不需要考虑block层面了，只是要考虑block中这一大堆thread如何调度。这时候warp的概念就出现了，把一大堆thread范围为一些warp。然后由warp scheduler调度这一个warp，更准确的说法是由warp scheduler调度warp中的thread，所以warp只是一个中间概念，最终调度的仍然是thread(明确这一点对于理解后文的<a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#bank-conflict target=_blank rel="external nofollow noopener noreferrer">bank conflict</a>至关重要)</li></ol><p>According to the real physical level, a SM(Streaming Multiprocessor) has many SP(Streaming Processor). Considure how can a
every SM in GPU will excute multiple blocks, and it will divides block into multiple warps. The basic execution unit of SM is warp.</p><blockquote><p>Some official concepts about warp:</p></blockquote><ol><li>A block assigned to an SM is further divided into 32 thread units called warps.</li><li>The warp is the unit of thread scheduling in SMs.</li><li>Each warp consists of 32 threads of consecutive threadIdx values: thread 0 through 31 form the first warp, 32 through 63 the second warp, and so on.</li><li>An SM is designed to execute all threads in a warp following the Single Instruction, Multiple Data (SIMD) model</li></ol><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241749537.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h3 id=simt-architecture class=heading-element><span>SIMT Architecture</span>
<a href=#simt-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>There is a question involved here that branch divergence between difference threads in the same warp.(Branch divergence occurs only within a warp, different warps execute independently regardless of whether they are executing common or disjoint code paths.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>)</p><p>It is worth noting that not all branch divergence elimination will generate performance benefits. Because if there is only a single if sentence such as the following code</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=n>condition</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// code block A
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=c1>// rest of the code
</span></span></span></code></pre></td></tr></table></div></div><p>Although maybe there are some threads which satisfies the condition, they will enter to the if sturct and execute the code block A and other threads will not. 但这些不进入的线程只需等待进入 code block A 的线程执行完即可。</p><p>If we have an integral if-else sturct such as the following code</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=n>condition</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// code block A
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// code block B
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=c1>// rest of the code
</span></span></span></code></pre></td></tr></table></div></div><p>在这种情况下，Warp中的线程会分别执行 code block A 和 code block B。如果条件不同，线程会分别进入 code block A 或 code block B，这就意味着Warp中的一部分线程需要先执行一个分支，然后再执行另一个分支。这样每个分支都要被串行执行一次，导致性能降低，因为每个分支的执行时间都被加起来了。</p><p>So, it does not mean that performance will decrease if branch divergence arises.</p><h2 id=memory-structure class=heading-element><span>Memory structure</span>
<a href=#memory-structure class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311151322227.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a>
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311081852318.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p><strong>How to detect the using situation of the different types of memory?</strong></p><ol><li>Use nvcc compilation option <code>--ptxas-option=-v</code>
<code>--ptxas-option</code> is used to specify options directly to ptxas(the PTX optimizing assembler, its location in the whole compilation process can be seen at <a href="https://www.cnblogs.com/hongyugao/p/17445574.html#CUDA%20Compilation:~:text=occupancy%28%E5%8D%A0%E7%94%A8%E7%8E%87%29%E3%80%82-,CUDA%20Compilation,-%E6%B6%89%E5%8F%8A%E5%88%B0%E4%B8%A4" target=_blank rel="external nofollow noopener noreferrer">CUDA Compilation</a>)</li><li>Use nvcc compilation option <code>-keep</code></li><li>Use <code>nvprof</code> command <code>nvprof --print-gpu-trace &lt;program path></code></li></ol><h3 id=cache class=heading-element><span>Cache</span>
<a href=#cache class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>There are 5 types of cache in cuda:</p><ol><li>shared memory(equivalent to a user-managed chache)</li><li>L1 cache</li><li>L3 cache</li><li>constant cache</li><li>texture cache</li></ol><p>We will talk more details about shared memory later, so we only focus on the remaining four types of real cache.</p><h4 id=l2-cache class=heading-element><span>L2 cache</span>
<a href=#l2-cache class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Just like L1 cache and shared memory, the L2 cache and global memory is related.</p><p>L2 cache is used to provide higher bandwidth and lower latency accesses to global memory.</p><p>We can refer to <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#query-l2-cache-properties target=_blank rel="external nofollow noopener noreferrer">Query L2 cache Properties</a> to get the properties of L2 cache.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311242150971.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h3 id=register--local-memory class=heading-element><span>Register & Local Memory</span>
<a href=#register--local-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=global-memory class=heading-element><span>Global Memory</span>
<a href=#global-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>The path of accessing global memory: L1 cache -> L2 cache -> global memory</p><h4 id=coalesced--uncoalesced class=heading-element><span>coalesced & uncoalesced</span>
<a href=#coalesced--uncoalesced class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>coalesced memory access &lt;=> a global memory access request from <strong>a warp</strong> will cause to 100% degree of coalescing.</p><blockquote><p>The above conclusion has two important things we need to pay attention to:</p><ol><li>The object we talk about is a warp</li><li>The definition of degree of coalescing is described as the following formula</li></ol></blockquote><p>$Degree \ of \ coalescing \ (合并度) = \frac{ request \ bytes \ number \ (warp实际请求数据量) }{ bytes \ number \ that \ participate \ in \ the \ data \ transforming \ (实际输出的数据量)}$</p><p>看到一句话，提到了DRAM burst，暂时还没有找到官方的解释</p><blockquote><p>CUDA Coalesced access uses the DRAM’s burst mode</p></blockquote><p>因为coalesced access是基于DRAM的burst mode来实现的，所以本质上会涉及到DRAM burst发生的性质和要求：</p><ul><li>对齐</li><li>访存大小</li></ul><p>疑惑点其实是在于发生coalesced是否和warp相关，是不是必须是同一个warp内的线程的访问才肯跟造成coalesced access，还是说同一个block不同warp，还是说不同block都可以？如果仅从DRAM burst发生的角度考虑，burst发生的条件应该是和CUDA的一些概念无关的，所以视角似乎可以直接放到不同线程上，并不需要考虑是否是同一warp或者是否是同一block</p><p>想要理解memory coalesced和uncoalesced，思维必须从串行思维转换到并行思维，</p><blockquote><p>Coalesce happens amongst threads, not amongst different iterations of the loop within each thread’s execution.</p></blockquote><p>关注的重点不应放在一个单独的thread上，我觉得一个比较合适的视角是放在一个warp上（关于这一点，有一个很明显的错误示范，就是矩阵乘法P=MxN，如果从单一thread的角度来看，对M的访问应当是满足coalesced地，但是如果考虑属于一个warp的不同thread，就会发现实际上对N的访问才是coalesced。考虑某一时刻属于同一个warp的thread的访存方式。关于这一示例的详细分析，可见<a href=https://nichijou.co/cuda5-coalesce/ target=_blank rel="external nofollow noopener noreferrer">The CUDA Parallel Programming Model - 5. Memory Coalescing</a></p><h4 id=common-memory-access-types class=heading-element><span>Common memory access types</span>
<a href=#common-memory-access-types class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Please note that the third and the last code can&rsquo;t get the right answer. The following code is just to used to describe types of memory access type.</p><ol><li>Sequential <strong>coalesced</strong> access(顺序的合并访问)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__global__ void add_sequential_coalesced(float *x, float *y, float *z) {
</span></span><span class=line><span class=cl>    int threadId = threadIdx.x + blockDim.x * blockIdx.x;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    z[threadId] = x[threadId] + y[threadId];
</span></span><span class=line><span class=cl>}</span></span></code></pre></td></tr></table></div></div><ol start=2><li>Out-of-order <strong>coalesced</strong> access(乱序的合并访问)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__global__ void add_out_of_order_coalesced(float *x, float *y, float *z) {
</span></span><span class=line><span class=cl>    int threadId = threadIdx.x ^ 0x1;
</span></span><span class=line><span class=cl>    threadId = threadIdx.x + blockDim.x * blockIdx.x;
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    z[threadId] = x[threadId] + y[threadId];
</span></span><span class=line><span class=cl>}</span></span></code></pre></td></tr></table></div></div><ol start=3><li>Misaligned <strong>uncoalesced</strong> access(不对齐的非合并访问)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__global__ void add_misaligned_uncoalesced(float *x, float *y, float *z) {
</span></span><span class=line><span class=cl>    int threadId = threadIdx.x + blockDim.x * blockIdx.x + 1;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    z[threadId] = x[threadId] + y[threadId];
</span></span><span class=line><span class=cl>}</span></span></code></pre></td></tr></table></div></div><ol start=4><li>Strided <strong>uncoalesced</strong> access(跨越式的非合并访问)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__global__ void add_stripped_uncoalesced(float *x, float *y, float *z) {
</span></span><span class=line><span class=cl>    int threadId = blockIdx.x + threadIdx.x * blockDim.x;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    z[threadId] = x[threadId] + y[threadId];
</span></span><span class=line><span class=cl>}</span></span></code></pre></td></tr></table></div></div><blockquote><p>Please Note that this is different from <a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#grid-stride-loop target=_blank rel="external nofollow noopener noreferrer">grid stride loop</a>, which emphasizes that how to solve the big problem which the scale is bigger than the amount of threads. But there we want to emphasize a type of memory access.</p></blockquote><ol start=5><li>Broadcast <strong>uncoalesced</strong> access(广播式的非合并访问)</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__global__ void add_broadcast_uncoalesced(float *x, float *y, float *z) {
</span></span><span class=line><span class=cl>    int threadId = threadIdx.x + blockDim.x * blockIdx.x;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    z[threadId] = x[0] + y[threadId];
</span></span><span class=line><span class=cl>}</span></span></code></pre></td></tr></table></div></div><p>broatcast这种方式还涉及到constant memory的使用</p><p>其实global memory就类似dram，l2 cache也就是个cache，所以thread访问global memory的过程和体系结构里面对于cache的分析过程是完全一样的，thread请求一个字节的数据，发现cache中不存在，即发生cache miss，然后就去访存，并且把数据缓存到cache line中，访问同一cache line对应数据的thread的再访存就是cache hit了，所说的这个合并访问似乎不过是访问这个cache line的过程，只要是一次访存对应几次都是cache hit就算是合并访存了，似乎完全可以这样理解.
其实这块判断是否会发生合并的一个前提就是确定从global memory一次到底取多少数据，现有认知是按照字节编制，但是按照字进行读取，但是书上却说一次读取32Bytes，一个字总不能有32Bytes吧。</p><h3 id=shared-memory class=heading-element><span>Shared Memory</span>
<a href=#shared-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>共享内存中的内存块通常被直接称为 memory tile 或简称为 tile。（可能这就是Tiled Matrix Multiplication的由来）</p><h4 id=create-shared-memory class=heading-element><span>Create Shared Memory</span>
<a href=#create-shared-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ol><li>静态shared memory，使用<code>__shared__</code>限定符创建时就指定存储空间的大小</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>__shared__ float array[1024];</span></span></code></pre></td></tr></table></div></div><ol start=2><li>动态shared memory，不确定空间大小，需要动态申请时</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>extern __shared__ float array[1024];</span></span></code></pre></td></tr></table></div></div><p>需要在kernel函数调用时，指定申请的shared memory的大小</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kernel&lt;&lt;&lt;gridSize, blockSize, sizeof(float) * 1024&gt;&gt;&gt;( … );</span></span></code></pre></td></tr></table></div></div><p>在C/C++中，存在一个变长数组（Variable Length Arrays，VLA）的概念，允许使用变量来指定数组的大小。
但是实际测试，变量指定数组大小应用于kernel函数时，会报错"error: expression must have a constant value"</p><h4 id=bank-conflict class=heading-element><span>Bank Conflict</span>
<a href=#bank-conflict class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>To understand this problem well, we should revisiv the <a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#hardware-structure target=_blank rel="external nofollow noopener noreferrer">hardware structure of gpu</a>.</p><p>在此基础上，我们将gpu的建议结构图进行扩充，装入shared memory和bank的结构
还需要一张shared memory中是如何划分的bank</p><p>bank的划分单位和最大bandwith都是32bits=4bytes=1word
但是寻址单位还是1byte</p><p>哪些情况下会产生bank conflict, 首先看一下都有哪些可能的bank访问情况</p><ol><li><p>同一warp：</p><ul><li><p>1.1 两个thread访问同一个bank中相同的字中的地址 (broadcast, conflict-free)</p></li><li><p>1.2 两个thread访问同一个bank中不同的字中的地址 (conflict)</p></li><li><p>1.3 两个thread访问不同bank (conflict-free)</p></li></ul></li><li><p>不同warp：</p><ul><li><p>2.1 两个thread访问同一个bank相同的字中的地址 (conflict)</p></li><li><p>2.2 两个thread访问同一个bank不同的字中的地址 (conflict)</p></li><li><p>2.3 两个thread访问不同bank (conflict-free)</p></li></ul></li></ol><p>要理解bank conflict，需要首先了解bank是怎么回事，</p><blockquote><p>To achieve high bandwidth, shared memory is divided into equally-sized memory modules, called banks, which can be <strong>accessed simultaneously</strong>.</p></blockquote><p>尤其是后面这句话比较重要，不同bank可以同时响应数据请求（实现这一点应该是需要硬件支持的，每一个bank是一个独立的存储单元）</p><p>所以就可以理解为什么不同thread访问同一个bank的时会降低效率，因为本来可以同时读，现在只能串行读(关于这一点还有以下疑点：bank coflict 只发生在不同warp中的thread在访问同一个bank的不同byte时，同一个warp内的thread无论如何访问都不会产生bank conflict)</p><p>这样来看，bank本身和ram的性质类似，但是整个shared_memory可以看为是多个ram拼接而成</p><p>According to the <a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#hardware-structure target=_blank rel="external nofollow noopener noreferrer">real hardware architecture of SM</a>, SM has multiple <strong>warp schedulers</strong>.</p><p>A block will be distributed to a SM, but the unit of execution of SM is warp which has 32 threads.</p><blockquote><p>It is easy to understand the principle of this setting, as we all know a block has many threads, if SM dispatch all of them at the same time, it will casuce difficulties. So the designer divide the block into warp.</p></blockquote><p>All warps in the same block will share the same shared memory. Shared memory is also divided into many subdivisions. The number of subdivisions equals to the number of warp.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222214856.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>Warp access shared memory use the bank as the unit.</p><p>The most optimal situation is every warp correspondens to a bank. At this situation, the time of accessing whole 32 banks is just 1 memory cycle.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222218255.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>To be precise, it should contains 32 threads and banks in figure. It is just a schematic drawing.</p></blockquote><p>But if many bank access the same bank, it will cause the following situation. At this situation, the time of accessing whole 32 banks is 32 memory cycles.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222219570.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>To be precise, it should contains 32 threads and banks in figure. It is just a schematic drawing.</p></blockquote><p><strong>An correlative calculation of this problem</strong>
The hardware splits a memory request with bank conflicts into as many separate conflict-free requests as necessary, decreasing throughput by a factor equal to the number of separate memory requests.</p><p>If the number of separate memory requests is n, the initial memory request is said to cause n-way bank conflicts.</p><p>To get maximum performance, it is therefore important to understand how memory addresses map to memory banks in order to schedule the memory requests so as to minimize bank conflicts.</p><p><strong>How can we solve this problem ?</strong></p><p>We can pad and adjust the memory structure as the following picture shows.
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311222225417.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>Reference</p><ul><li>[1] <a href=https://github.com/Kobzol/hardware-effects-gpu/blob/master/bank-conflicts/README.md target=_blank rel="external nofollow noopener noreferrer">hardware-effects-gpu-Bank conflicts</a></li><li>[2] <a href=https://docs.nvidia.com/nsight-compute/NsightComputeCli/index.html#nvprof-metric-comparison target=_blank rel="external nofollow noopener noreferrer">Nsight Compute CLI - Metric Comparison</a></li></ul></blockquote><h3 id=constant-memory class=heading-element><span>Constant Memory</span>
<a href=#constant-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>A simple use of constant memory comes from <a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#convolution target=_blank rel="external nofollow noopener noreferrer">convolution</a>.</p><p>In convolution, because there are four aspects which leads to that we can use constant memory.</p><ol><li>The ratio of floating-point arithmetic calculation to global memory accesses is so low.(计算访存比较低，简单理解就是读了很多数据但是计算的比较少，事倍功半)</li><li>The size of mask is small. (The constant memory size is small)</li><li>The constants of mask are not changed throughout the execution of the kernel. (The constant memory is prohibited modification)</li><li>All threads need to access the mask elements. (store memory into cache is effective)</li></ol><p>According to the <a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#memory-structure target=_blank rel="external nofollow noopener noreferrer">picture</a> at the beginning of the Memory structure. We can learn about the constant memory is in DRAM.</p><p>But because the variable or space in constant is prohibited modification, so cuda runtime can put its content to cache trustfully, at the same time, no modification means that there is no cache coherence issue.</p><p>There are three important aspects of using constant memory:</p><ol><li><code>__constant__ float M[];</code>, use the <code>__constant__</code> specifier and M should be a global variable</li><li><code>cudaMemcpyToSymbol(M, M_h, Mask_Width*sizeof(float));</code></li></ol><h3 id=host-side-memory class=heading-element><span>Host Side Memory</span>
<a href=#host-side-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=pageable-memory class=heading-element><span>pageable memory</span>
<a href=#pageable-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><blockquote><p>可分页内存</p></blockquote><ul><li>使用<code>malloc()/new()</code>和<code>free()/delete()</code>函数分配和释放</li><li>此类型内存是可以从内存被换出到磁盘的</li></ul><h4 id=pinned-memory class=heading-element><span>pinned memory</span>
<a href=#pinned-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><blockquote><p><a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#page-locked-host-memory target=_blank rel="external nofollow noopener noreferrer">pinned memory</a>, aka non-pageable memory(不可分页内存) / page-locked(页锁定内存)</p></blockquote><ul><li>使用<a href=https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gb65da58f444e7230d3322b6126bb4902 target=_blank rel="external nofollow noopener noreferrer"><code>cudaHostAlloc()</code></a> / <a href=https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gab84100ae1fa1b12eaca660207ef585b target=_blank rel="external nofollow noopener noreferrer"><code>cudaMallocHost()</code></a>和<code>cudaFreeHost()</code>函数分配和释放</li></ul><blockquote><p><code>cudaHostAlloc()</code>和<code>cudaMallocHost()</code>的关系是 <code>cudaHostAlloc(xxx, yyy, cudaHostAllocDefault)</code> 等价于 <code>cudaMallocHost(xxx, yyy)</code></p></blockquote><ul><li>此类型内存一直停留在内存，不会被换出到磁盘</li><li>此类型内存支持DMA访问，支持与GPU之间进行异步通信（asynchronous data transfer）</li></ul><p><strong>Some background on the memory management in operating systems</strong></p><ul><li><code>cudaMemcpy()</code> uses the hardware <strong>direct memoryory access (DMA) device</strong>.</li><li>The operating system give a translated physical address to DMA, i.e. the DMA hardware operates on physical addresses.</li><li>Uses the DMA to implement the <code>cudaMemcpy()</code> faces a chance that the data in the pageable memroy can be overwritten by the paging activity before the DMA transmission.</li></ul><p>The solution is to perform the copy operation in two steps:</p><ol><li>For a host-to-device copy, the CUDA runtime first copies the source host memory data into a <strong>pinned memory buffer</strong>, sometimes also referred to as <strong>page locked memory buffer</strong>.</li><li>It then uses the DMA device to copy the data from the pinned memory buffer to the device memory.</li></ol><p>The problems of this solution:</p><ol><li>Extra copy adds delay to the cudaMemcpy() operation.</li><li>Extra complexity involved leads to a synchronous implementation of the cudaMemcpy() function.</li></ol><blockquote><p>About the synchronous and asynchronous, please see the <a href=https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-sync target=_blank rel="external nofollow noopener noreferrer">API synchronization behavior</a></p></blockquote><p>To solve this problem, we can use the <code>cudaHostAlloc()</code> to open up pinned memory buffer, and use the <code>cudaMemcpyAsync()</code> to copy a data asynchronously.</p><h4 id=zero-copy-memory class=heading-element><span>Zero-Copy Memory</span>
<a href=#zero-copy-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>首先，零拷贝内存并不是像unified memory这样的逻辑存在，其是一种物理存在。其特别之处在于实际的物理存储空间实际是 Host Memory，但是 device 却可以通过某种方式直接访问，无需人工进行拷贝操作。</p><p><strong>The way of opening up zero-copy memory</strong></p><p>The zero-copy memory is a special host memory, it is a pinned memory.</p><ol><li>When we use <code>cudaHostAlloc()</code> to open up a pinned memory, we need to transmit the third parameter <code>flag</code>. We need to transmit <code>cudaHostAllocMapped</code> as a flag to cudaHostAlloc().</li><li><strong>Host code</strong> use <a href=https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc00502b44e5f1bdc0b424487ebb08db0 target=_blank rel="external nofollow noopener noreferrer"><code>cudaHostGetDevicePointer()</code></a> to get a pointer which points to the pinned memroy.</li></ol><blockquote><p>Please note that we should get the zero-copy memory pointer in host code rather than device cost, although it is more reasonable to get this pointer in device code.</p></blockquote><ol start=3><li>At this time, the pinned memory is called zero-copy memory.</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;iostream&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=n>__host__</span> <span class=n>__device__</span> <span class=kt>void</span> <span class=nf>output</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>printf</span><span class=p>(</span><span class=s>&#34;%d&#34;</span><span class=p>,</span> <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>    <span class=n>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>kernel</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>d_a</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span><span class=p>(</span><span class=n>d_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>d_a</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=mi>5</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=o>*</span><span class=n>h_a</span><span class=p>,</span> <span class=o>*</span><span class=n>d_a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span> <span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>h_a</span><span class=p>,</span> <span class=mi>10</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocMapped</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaHostGetDevicePointer</span><span class=p>((</span><span class=kt>void</span> <span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>d_a</span><span class=p>,</span> <span class=n>h_a</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=n>h_a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span><span class=p>(</span><span class=n>h_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// output:
</span></span></span><span class=line><span class=cl><span class=c1>// 1111111111
</span></span></span><span class=line><span class=cl><span class=c1>// 1151111111
</span></span></span></code></pre></td></tr></table></div></div><h3 id=unified-memory class=heading-element><span>Unified Memory</span>
<a href=#unified-memory class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Unified Memory是一种逻辑上的存在，它提供了一种抽象层，让程序员可以将主机（CPU）和设备（GPU）上的内存视为一个统一的内存空间。</p><p>使用Unified Memory的情况下，程序员无需显式地管理数据的迁移，系统会根据需要自动处理。</p><p>Unified Memory通过使用页表和硬件支持，实现了逻辑上的一致性。</p><p>Unified Memory并不是物理上的一块内存，而是一个逻辑概念，通过系统的管理和硬件支持，实现了对主机和设备上内存的透明管理。这有助于简化GPU编程中的内存管理任务。</p><h4 id=optimization-techniques class=heading-element><span>Optimization Techniques</span>
<a href=#optimization-techniques class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p><a href=https://developer.nvidia.com/blog/unified-memory-cuda-beginners/ target=_blank rel="external nofollow noopener noreferrer">Unified Memory for CUDA Beginners</a></p><h2 id=memory-api class=heading-element><span>Memory API</span>
<a href=#memory-api class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>CUDA C提供了与C语言在语言级别上的集成，主机代码和设备代码由不同的编译器负责编译，设备函数调用样式上接近主机函数调用</p><p><code>cudaMemcpy()</code> will synchronize automatically, so if the last line code is <code>cudaMemcpy()</code>, we needn&rsquo;t to use the <code>cudaDeviceSynchronize()</code></p><p><strong>Different devices corresponding to different memory functions</strong></p><table><thead><tr><th>Location</th><th>memory allocate</th><th>memory release</th></tr></thead><tbody><tr><td>Host</td><td>malloc/new</td><td>free/delete</td></tr><tr><td>Device</td><td>cudaMalloc</td><td>cudaFree</td></tr><tr><td>Unified Memory</td><td>cudaMallocManaged</td><td>cudaFree</td></tr></tbody></table><p><strong>Which memory types do we have ?</strong>
Host and device has different authorities to use the memory. The following table describes their authorities.</p><table><thead><tr><th>Memory type</th><th>Host</th><th>Device</th></tr></thead><tbody><tr><td>Global memory</td><td>W/R</td><td>W/R</td></tr><tr><td>Constant memory</td><td>W/R</td><td>R</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><p><strong>Why we need unified memory ?</strong></p><ol><li>Additional transfers between host and device memory increase the latency and reduce the throughput.</li><li>Device memory is small compared with the host memory. Allocating the large data from host memory to device memory is difficult.</li></ol><blockquote><p>Annotate: W means Write and R means Read</p></blockquote><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309271517094.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h3 id=2d-array class=heading-element><span>2D Array</span>
<a href=#2d-array class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Refering to the methos of opening up a 2D space in host code which see the first dimension of array is some pointers and the second dimension of array is a 1D array. When we want to allocate a 2D array in device memory, the above method is difficult, because we need to access a space of device memory in host code.</p><p>So, CUDA provide <strong>pitched memory</strong> to implement it. We can use <code>cudaMallocPitch()</code> to create a 2D space in device memory, <code>cudaMemset2D()</code> to copy data between host and device and <code>cudaFree()</code> to release space.</p><h2 id=software-structure class=heading-element><span>Software structure</span>
<a href=#software-structure class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>All CUDA threads in a grid execute the same kernel function;</p></blockquote><p>It is easy to explain it. When we want to call a kernel function, we will specify the grid and block structure using the <code>dim3</code> data type. It means that we want to use all these threads where locate in the grid to execute this kernel function.</p><p>In general, a grid is a three-dimensional array of blocks1, and each block is a three dimensional array of threads.
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122206388.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>From a code implementation perspective, these two three-dimensional arrays are both a <code>dim3</code> type parameter, which is a C struct with three unsigned integer fields: x, y, and z.
The first execution configuration parameter specifies the dimensions of the grid in the number of blocks. And the second specifies the dimensions of each block in the number of threads.
For example, as the following code shows, there is a grid and a block. The grid consists of 32 blocks, and it is a linear structure. The block consists of 128 threads, and it is also a linear structure.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>dim3 dimGrid(32, 1, 1);
</span></span><span class=line><span class=cl>dim3 dimBlock(128,  1, 1);
</span></span><span class=line><span class=cl>vecAddKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(...);</span></span></code></pre></td></tr></table></div></div><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202310122217866.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>About the more detail specifications please see <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#features-and-technical-specifications target=_blank rel="external nofollow noopener noreferrer">official technical specifications</a></p></blockquote><h2 id=software-stack class=heading-element><span>Software stack</span>
<a href=#software-stack class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311251423321.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241804271.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h2 id=kernel-function class=heading-element><span>Kernel Function</span>
<a href=#kernel-function class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>Because the execution of the kernel function is asynchronous, that means the subsequent codes don&rsquo;t know when the result will be returned by kernel funcion, so the type of returen value of kernel funciont must be void.</p></blockquote><ol><li>CPU以及系统内存成为主机，GPU及其内存成为设备</li><li>GPU设备上执行的函数称为核函数（Kernel）</li><li>核函数调用时&#171;&lt;para1，para2&#187;>中的para1表示设备在执行核函数时使用的并行线程块的数量，通俗来说总共将创建para1个核函数来运行代码，共para1个并行执行环境，para1个线程块。这para1个线程块称为一个线程格（Grid）</li><li>核函数中存在一个CUDA运行时已经预先定义的内置变量blockIdx，表示当前执行设备代码的线程块索引</li></ol><p>The difficulty of writing parallel programs comes from arranging the structure of grid、block and thread so that they can adapt the programs.
What we ought to know is that the kernel funtion is just like a big loop in logic, it will enumerate the whole grid in threads.</p><blockquote><p>Note: This perspective is just from code, it is not the true execution logic.</p></blockquote><h2 id=指针 class=heading-element><span>指针</span>
<a href=#%e6%8c%87%e9%92%88 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>主机指针只能访问主机代码中的内存，设备指针只能访问设备代码中的内存</p><h3 id=设备指针 class=heading-element><span>设备指针</span>
<a href=#%e8%ae%be%e5%a4%87%e6%8c%87%e9%92%88 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>虽然<code>cudaMalloc()</code>同<code>malloc()</code>，<code>cudaFree()</code>同<code>free()</code>非常相似，但是设备指针同主机指针之间并不完全相同，设备指针的使用规则如下</p><ol><li><code>cudaMalloc()</code>分配的指针可以传递给设备函数，设备代码可以使用该指针进行内存读/写操作（解引用）</li><li><code>cudaMalloc()</code>分配的指针可以传递给主机函数，主机代码不可以使用该指针进行内存读/写操作（解引用）</li></ol><h3 id=主机指针与设备指针数据拷贝 class=heading-element><span>主机指针与设备指针数据拷贝</span>
<a href=#%e4%b8%bb%e6%9c%ba%e6%8c%87%e9%92%88%e4%b8%8e%e8%ae%be%e5%a4%87%e6%8c%87%e9%92%88%e6%95%b0%e6%8d%ae%e6%8b%b7%e8%b4%9d class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>主机->主机：<code>memcpy()</code></li><li>主机->设备：<code>cudaMemcpy()</code>指定参数<code>cudaMemcpyHostToDevice</code></li><li>设备->主机：<code>cudaMemcpy()</code>指定参数<code>cudaMemcpyDeviceToHost</code></li><li>设备->设备：<code>cudaMemcpy()</code>指定参数<code>cudaMemcpyDeviceToDevice</code></li></ol><p>The communication between CPU and GPU is asynchronous for high performance. So need to use the synchronous mechnisms for them.</p><h2 id=function-type class=heading-element><span>Function type</span>
<a href=#function-type class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><ul><li><code>__host__</code></li><li><code>__global__</code></li><li><code>__device__</code></li></ul><table><thead><tr><th>function type \ action</th><th>Callable from</th><th>Executed on</th></tr></thead><tbody><tr><td><code>__global__</code></td><td>host / divice(compute capability 5.0 or higher)</td><td>device</td></tr><tr><td><code>__device__</code></td><td>device</td><td>device</td></tr><tr><td><code>__host__</code></td><td>host</td><td>host</td></tr></tbody></table><p>Without any of the <code>__host__</code>, <code>__device__</code>, or <code>__global__</code> specifier is equivalent only the <code>__host__</code> specifier.</p><p>Some special usage:</p><ul><li><p>The <code>__global__</code> and <code>__device__</code> execution space specifiers <strong>cannot</strong> be used together.</p></li><li><p>The <code>__global__</code> and <code>__host__</code> execution space specifiers <strong>cannot</strong> be used together.</p></li><li><p>The <code>__device__</code> and <code>__host__</code> execution space specifiers <strong>can</strong> be used together.(This usage is used to decrease the verbose codes, the compiler will compile the function for host and device seperately)</p></li></ul><p>More informations please see the <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#function-execution-space-specifiers target=_blank rel="external nofollow noopener noreferrer">official station</a>.</p><h2 id=common-parallelization-methods class=heading-element><span>Common Parallelization methods</span>
<a href=#common-parallelization-methods class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=grid-stride-loop class=heading-element><span>Grid-stride loop</span>
<a href=#grid-stride-loop class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>This method is used to solve the problem, the parallelism(并行度) is more than the quantity of threads.</p><p>In some situations, we can create many threads so that satisfied the parallelism, that we can allocate a separate thread for every threads.</p><p>But if the parallelism is more than the quantity of threads and we still use the above strategy, we will get the following result.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241915666.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>The parallelism is 32, but we just have 8 threads, we can&rsquo;t allocate a separate thread for every threads.</p></blockquote><p>Grid-stride loop provide a new approach to solve this problem. At first, we studt the content of this method and we will think the core principle of this method.
The process of grid-stride loop looks like the following figure.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202309241933388.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>In short, the core approach to implement it is <code>for (size_t i = threadIdx.x; i &lt; n; i += &lt;total number of threads></code>. When the number of threads is smaller than parallelism, we can&rsquo;t use the traditional method to implement the parallel, simply speaking, the distribution of thread can&rsquo;t satisfied the parallelism.</p><p>Grid-stride loop uses <total number of threads>to map the threads to tasks reasonably, the <total number of threads>is a magic number, it can ensure different thread will not intersect with each other and finish all tasks.</p><h3 id=fixed-location-solve-the-data-conflict class=heading-element><span>Fixed location solve the data conflict</span>
<a href=#fixed-location-solve-the-data-conflict class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>The most obvious answer is using mutex or atomic operation. But as we all know, whether it&rsquo;s mutex or atomic, they both have some consuming.</p><p>We know that the data conflict comes from shared data, different thread maybe use the same data at the same time. So an approach to avoid happening this problem is that control different threads use different data.</p><p>According to the process of Grid-stride loop, we notice that different threads use the different datas which have different locations. We can specify a fixed location to store a thread&rsquo;s data to avoid using the mutex or atomic.</p><p>A good example is array summation. As the following code shows.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;iostream&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;vector&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;cuda_runtime.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;CudaAllocator.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;ticktock.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;stdio.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>parallel_sum</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>arr</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>sum</span><span class=p>,</span> <span class=kt>int</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		 <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=o>/</span> <span class=mi>4</span><span class=p>;</span>
</span></span><span class=line><span class=cl>		 <span class=n>i</span> <span class=o>+=</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>+</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span> <span class=o>+=</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>			<span class=n>sum</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+=</span> <span class=n>arr</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=mi>4</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// unified memory
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=p>,</span> <span class=n>CudaAllocator</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;&gt;</span> <span class=n>arr</span><span class=p>(</span><span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=p>,</span> <span class=n>CudaAllocator</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;&gt;</span> <span class=n>sum</span><span class=p>(</span><span class=n>n</span> <span class=o>/</span> <span class=mi>4</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>(</span><span class=n>size_t</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>arr</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// 设置共n/4个thread，每个block为4个thread，因此block数量为n / 4 / 4
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=n>dim3</span> <span class=n>blockSize</span><span class=p>(</span><span class=mi>4</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=n>dim3</span> <span class=n>gridSize</span><span class=p>(</span><span class=n>n</span> <span class=o>/</span> <span class=mi>4</span> <span class=o>/</span> <span class=mi>4</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>parallel_sum</span><span class=o>&lt;&lt;&lt;</span><span class=n>gridSize</span><span class=p>,</span> <span class=n>blockSize</span><span class=o>&gt;&gt;&gt;</span> <span class=p>(</span><span class=n>arr</span><span class=p>.</span><span class=n>data</span><span class=p>(),</span> <span class=n>sum</span><span class=p>.</span><span class=n>data</span><span class=p>(),</span> <span class=n>n</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	<span class=n>cudaDeviceSynchronize</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>final_sum</span><span class=p>{</span><span class=mi>0</span><span class=p>};</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>n</span> <span class=o>/</span> <span class=mi>4</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>final_sum</span> <span class=o>+=</span> <span class=n>sum</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=s>&#34;sum = &#34;</span> <span class=o>&lt;&lt;</span> <span class=n>final_sum</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><h2 id=synchronization class=heading-element><span>Synchronization</span>
<a href=#synchronization class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>CPU programing needs synchronous mechanism, GPU programing also needs it.</p><h3 id=atomic class=heading-element><span>Atomic</span>
<a href=#atomic class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>We can learn about the execution logic by refering to <a href=https://www.cnblogs.com/hongyugao/p/17692121.html#atomic target=_blank rel="external nofollow noopener noreferrer">C++ atomic</a> and details of function by refering to <a href=https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf target=_blank rel="external nofollow noopener noreferrer">CUDA C++ Programming Guide</a>.</p><h2 id=asynchronization-cuda-stream class=heading-element><span>Asynchronization (CUDA stream)</span>
<a href=#asynchronization-cuda-stream class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>Serialize data transfer and GPU computation causes that PCIe idle and GPU idel appear interleavly.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081112953.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>Most CUDA devices support device overlap. Because data transmission is more timeless than computation, so simultaneously execute a kernel while performing a copy between device and host memory can cover up the time consumation of data transmission.</p><p>CUDA supports parallel execution of kernels and cudaMemcpy with streams. A stream is a sequence of commands that execute in order.</p><p>The commands issued on a stream may execute when all the dependencies of the command are met. The dependencies could be previously launched commands on same stream or dependencies from other streams.</p><p>About the PCIe transmission rate is shown as the following picture:
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312081517982.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>流的分类：</p><ol><li>根据发出方分类：</li></ol><ul><li>Host端发出的流(主要讨论的是这种)</li><li>Device端发出的流</li></ul><ol start=2><li>根据有无内容分类：</li></ol><ul><li>默认流(default stream) / 空流(null stream)</li><li>明确指定的非空流</li></ul><h3 id=execution-order class=heading-element><span>Execution order</span>
<a href=#execution-order class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>同一个CUDA流中的操作是串行顺次执行的，不同stream中的operation随机执行，可能是并发交错执行的</p><h3 id=related-api class=heading-element><span>Related API</span>
<a href=#related-api class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><code>__host__ ​cudaError_t cudaStreamCreate ( cudaStream_t* pStream )</code></li></ol><blockquote><p>Create an asynchronous stream.</p></blockquote><ol start=2><li><code>__host__ ​__device__ ​cudaError_t cudaStreamDestroy ( cudaStream_t stream )</code></li></ol><blockquote><p>Destroys and cleans up an asynchronous stream.</p></blockquote><ol start=3><li><code>__host__ ​cudaError_t cudaStreamQuery ( cudaStream_t stream )</code></li></ol><blockquote><p>Queries an asynchronous stream for completion status.</p></blockquote><ol start=4><li><code>__host__​ cudaError_t cudaStreamSynchronize ( cudaStream_t stream )</code></li></ol><blockquote><p>Waits for stream tasks to complete.</p></blockquote><h3 id=如何理解流 class=heading-element><span>如何理解流</span>
<a href=#%e5%a6%82%e4%bd%95%e7%90%86%e8%a7%a3%e6%b5%81 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>从主机和设备两个视角的动作来分析</p><p>使用<code>cudaMemcpyAsync()</code>时，Host memory必须是<a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#host-side-memory target=_blank rel="external nofollow noopener noreferrer">non-pageable memroy / pinned memory</a>, 数据传输过程由GPU的DMA负责</p><p>如果是<a href=https://gaohongy.github.io/blog/posts/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/gpu-structure-and-programing/#host-side-memory target=_blank rel="external nofollow noopener noreferrer">pageable memroy</a>使用<code>cudaMemcpyAsync()</code>, 需要首先将pageable memory移动到pinned memory，这个过程中就会涉及到数据同步。</p><p>还有一个需要注意的事情就是PCIe，同一时刻H2D和D2H都只能进行1个操作。</p><h2 id=c-encapsulation class=heading-element><span>C++ Encapsulation</span>
<a href=#c-encapsulation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>As we all know, the style of many CUDA APIs is C-style, we need to learn about how to use it conjunction with C++.</p><p><strong>How does the std::vector standard template library use the Device(GPU) memory ?</strong>
Many examples use the original pointer to point a Device memory. But if we want to use a std::vector or other standard template library that locates in Device memory, we can&rsquo;t use the <code>cudaMalloc()</code> or <code>cudaMallocManaged()</code>.</p><p>Taking the <code>std::vector</code> as an example, next, we will discuss the method of allocating Device memory for containers.</p><blockquote><p>Whether it&rsquo;s principle or usage methods is too complex to understand in a short time. So pause it for a period of time. When we must need to learn its principle we study it again. We can learn about it from <a href=https://www.coonote.com/cplusplus-note/space-allocator.html target=_blank rel="external nofollow noopener noreferrer">一篇文章搞懂STL中的空间配置器allocator</a>. In short, std::allocator integrates the memory management and object management by using four member function.</p></blockquote><h2 id=gpu-execution-core class=heading-element><span>GPU execution core</span>
<a href=#gpu-execution-core class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>一个kernel函数在逻辑上以block为单位映射到SM中，物理上以warp为单位解析指令将指令分发到具体的运算单元(SP/core, SFU, DP)或访存单元(LD/ST)。
SM中活动的warp数量占物理warp数量的比率为occupancy(占用率)。</p><h2 id=device-api class=heading-element><span>Device API</span>
<a href=#device-api class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><ol><li><code>__host__ ​__device__ ​cudaError_t cudaGetDeviceCount ( int* count )</code></li></ol><blockquote><p>Returns the number of compute-capable devices.</p></blockquote><ol start=2><li><code>__host__ ​cudaError_t cudaGetDeviceProperties ( cudaDeviceProp* prop, int device )</code></li></ol><blockquote><p>Returns information about the compute-device.</p></blockquote><ol start=3><li><code>__host__​ cudaError_t cudaSetDevice ( int device )</code></li></ol><blockquote><p>Set device to be used for GPU executions.</p></blockquote><p>More information please see the <a href=https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE target=_blank rel="external nofollow noopener noreferrer">official website</a>.</p><p>Three are three ways to transfer data from one device to another:</p><ol><li><code>cudaMemcpyPeerAsync()</code></li><li><code>cudaMemcpy()</code>: rely on the unified address system</li><li>Implicit peer memory access performed by the driver</li></ol><h2 id=cuda-libraries class=heading-element><span>CUDA Libraries</span>
<a href=#cuda-libraries class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=cublas class=heading-element><span>cuBLAS</span>
<a href=#cublas class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=cusolver class=heading-element><span>cuSOLVER</span>
<a href=#cusolver class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=cufft class=heading-element><span>cuFFT</span>
<a href=#cufft class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=thrust class=heading-element><span>Thrust</span>
<a href=#thrust class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>Three main functionalities</li></ol><ul><li>The host and device vector containers</li><li>A collection of parallel primitives such as, sort, reduce and transformations</li><li>Fancy iterators</li></ul><h2 id=cuda-compilation class=heading-element><span>CUDA Compilation</span>
<a href=#cuda-compilation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>For detailed information, please refer to <a href=https://gaohongy.github.io/blog/posts/compile-link/cuda-compilation/ target=_blank rel="external nofollow noopener noreferrer">this article</a>.</p><h2 id=gpgpu-sim class=heading-element><span>GPGPU-Sim</span>
<a href=#gpgpu-sim class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p><a href=http://gpgpu-sim.org/ target=_blank rel="external nofollow noopener noreferrer">Official site</a></p></blockquote><h3 id=how-to-run class=heading-element><span>How to run</span>
<a href=#how-to-run class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>Use the command <code>ldd</code> to make sure the application&rsquo;s executable file is dynamically linked to CUDA runtime library</li><li>Copy the contents of configs/QuadroFX5800/ or configs/GTX480/ to your application&rsquo;s working directory.</li></ol><blockquote><p>These files configure the microarchitecture models to resemble the respective GPGPU architectures.</p></blockquote><ol start=3><li>Run a CUDA application on the simulator</li></ol><blockquote><p>source setup_environment &lt;build_type></p></blockquote><h3 id=source-code-organization-structure class=heading-element><span>Source code organization structure</span>
<a href=#source-code-organization-structure class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Gpgpu-sim的源码位于<code>gpgpu-sim_distribution/src/gpgpu-sim</code>。
目前，我们主要关注其中和配置相关的内容，我们通过修改gpgpu-simi的源码（增加一个配置项），重新编译并用其执行程序来简单理解gpgpu-sim对于配置项的设置方式。</p><ol><li>修改<code>gpu-sim.cc:gpgpu_sim_config::reg_options()</code>，在其中添加一个配置项</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>option_parser_register(opp, &#34;-magic_number&#34;, OPT_INT32, &amp;magic_number_opt, &#34;A dummy magic number&#34;, &#34;0&#34;);</span></span></code></pre></td></tr></table></div></div><ol start=2><li>修改<code>gpu-sim.h</code>，在配置项对应结构体中添加对应字段</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>int magic_number_opt;</span></span></code></pre></td></tr></table></div></div><ol start=3><li>重新编译gpgpu-sim项目</li><li>将编译后生成的<code>gpgpusim.config</code>拷贝到待执行cuda程序路径下</li><li>修改待执行cuda程序路径下的<code>gpgpusim.config</code>配置文件，添加配置项</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>-magic_number 25</span></span></code></pre></td></tr></table></div></div><ol start=6><li>执行cuda程序，在输出信息中就可以看到新增的配置项</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>-magic_number                          25 # A dummy magic number</span></span></code></pre></td></tr></table></div></div><h3 id=reference class=heading-element><span>Reference</span>
<a href=#reference class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><ul><li>[1] <a href=https://coffeebeforearch.github.io/2020/03/30/gpgpu-sim-1.html target=_blank rel="external nofollow noopener noreferrer">Working with GPGPU-Sim - Introduction</a></li><li>[2] <a href=https://coffeebeforearch.github.io/2020/04/13/gpgpu-sim-2.html target=_blank rel="external nofollow noopener noreferrer">Working with GPGPU-Sim - Adding Configuration Options</a></li><li>[3] <a href=https://coffeebeforearch.github.io/2020/03/31/perf-gpgpu-sim.html target=_blank rel="external nofollow noopener noreferrer">Improving GPGPU-Sim Performance</a></li><li>[4] <a href=https://zhuanlan.zhihu.com/p/576442425 target=_blank rel="external nofollow noopener noreferrer">ECE 695 GPGPU-Sim Tutorial 学习笔记</a></li><li>[5] <a href="https://blog.sciencenet.cn/home.php?mod=space&amp;uid=1067211&amp;do=blog&amp;view=me" target=_blank rel="external nofollow noopener noreferrer">GPGPU-SIM系列文章 | 科学网</a></li></ul></blockquote><p>附加内容：</p><ol><li>If want to use ptxplus (native ISA) change the following options in the configuration file</li></ol><blockquote><p>-gpgpu_ptx_use_cuobjdump 1
-gpgpu_ptx_convert_to_ptxplus 1</p></blockquote><ol start=2><li>If want to use GPUWatch change the following options in the configuration file</li></ol><blockquote><p>-power_simulation_enabled 1 (1=Enabled, 0=Not enabled)
-gpuwattch_xml_file <filename>.xml</p></blockquote><h2 id=related-programming-models class=heading-element><span>Related Programming Models</span>
<a href=#related-programming-models class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312131446434.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>就目前了解到的 OpenACC 和 OpenMP 是由编译器提出的一种叫做<a href=https://gcc.gnu.org/wiki/Offloading target=_blank rel="external nofollow noopener noreferrer">Offloading</a>的机制实现的</p><ol><li>OpenCL</li></ol><blockquote><p>Open Computing Language</p></blockquote><ol start=2><li>OpenACC</li></ol><blockquote><p>Open Accelerators</p></blockquote><p>OpenACC is a feature of the compiler, so we don&rsquo;t need to install it if we want use it. More details please see the <a href=https://gcc.gnu.org/wiki/openmp target=_blank rel="external nofollow noopener noreferrer">gnu official website</a>.</p><ol start=3><li>OpenMP</li></ol><blockquote><p>Open Multi-Processing</p></blockquote><p>Reference to the memroy modle of OpenMP, we can get the following information: &ldquo;The OpenMP API provides a relaxed-consistency, shared-memory model.&rdquo;</p><p>threaded parallelism</p><p>虽然OpenMP只能用于单机，但是可以处理单机上的多卡</p><p>OpenMP is a feature of the compiler, so we don&rsquo;t need to install it if we want use it. More details please see the <a href=https://gcc.gnu.org/wiki/openmp target=_blank rel="external nofollow noopener noreferrer">gnu official website</a>.</p><ol start=4><li>MPI</li></ol><blockquote><p>Message Passing Interface</p></blockquote><p>MPI可以理解为是一种独立于语言的信息传递标准, 本身和代码没有关系，可以看为是一种规定。
OpenMPI和MPICH等编程模型是对这种标准的具体实现。也就是说，OpenMPI和MPICH这类库是具体用代码实现了MPI标准。因此我们需要安装OpenMPI或者MPICH去实现我们所学的MPI的信息传递标准。</p><p>process parallelism</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202311221659870.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h2 id=如何使用cuda加速程序 class=heading-element><span>如何使用CUDA加速程序</span>
<a href=#%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8cuda%e5%8a%a0%e9%80%9f%e7%a8%8b%e5%ba%8f class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>目前理解到的CUDA加速程序的两个关键问题是：</p><ol><li>任务并行化
寻找到任务中可以并行完成的部分，制定某种策略将任务合理分配到每个线程中。此过程期望解决的是计算瓶颈(cpu-bound)问题。</li></ol><p>1.1 udacity的视频主要讲解的就是这部分
1.2 小彭课程第6讲也是这部分
主要就是讲解一些并行原语</p><ol start=2><li>访存优化
此过程期望解决的是内存瓶颈(memory-bound)问题。</li></ol><p>2.1 gpu的存储模型（《大众高性能》）
2.2 小彭课程第7讲</p><h3 id=公共概念 class=heading-element><span>公共概念</span>
<a href=#%e5%85%ac%e5%85%b1%e6%a6%82%e5%bf%b5 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>在使用 tile 的算法中，存在 ghost cell 和 halo cell / skirt cell，按照目前的理解，前者指的是实际不存在元素，后者指的是实际存在，但是不在当前 tile 范围内的元素。下面以 tiled 1D convolution 为例来说明它们的实际指向
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201233345.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></li></ol><h3 id=对任务划分的理解 class=heading-element><span>对任务划分的理解</span>
<a href=#%e5%af%b9%e4%bb%bb%e5%8a%a1%e5%88%92%e5%88%86%e7%9a%84%e7%90%86%e8%a7%a3 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>想要实现并行化，很重要的一点是考虑“如何合理地将任务划分到不同的thread上”</p><p>如何选择grid和block的规模，除了考虑以上合理的任务划分之外，还可以从性能的角度进行考量。
如果仅从下图内容来看，block规模的确定要更为重要，grid的规模只需要根据任务划分和block规模来确定即可</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312092139368.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><h3 id=矩阵乘法 class=heading-element><span>矩阵乘法</span>
<a href=#%e7%9f%a9%e9%98%b5%e4%b9%98%e6%b3%95 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li>SGEMM</li></ol><blockquote><p>Single-precision General Matrix Multiply
单精度通用矩阵乘法</p></blockquote><ol start=2><li>DGEMM</li></ol><blockquote><p>Double-precision General Matrix Multiply
双精度通用矩阵乘法</p></blockquote><ol start=3><li>CGEMM</li></ol><blockquote><p>Complex-single-precision General Matrix Multiply
复数单精度通用矩阵乘法</p></blockquote><ol start=4><li>ZGEMM</li></ol><blockquote><p>Complex-double-precision General Matrix Multiply
复数双精度矩阵乘法</p></blockquote><p>目前感觉从具体的算子入门CUDA编程中的各种概念、并行算法、访存优化的手段是个非常好的方式，因为各种算法，访存优化一定都是基于实际的应用场景而出现的，都不是仅仅的概念本身</p><p>把thread都放置在同一个block中的缺点在于，SM无法对block进行调度，原本的两层调度：block调度和warp调度，现在就只剩下一个warp调度了</p><p>native implementation 的核心问题是：计算访存比过低，即使将global memory替换为shared memory，访存时间占比仍然远大于计算时间占比。所以才会考虑矩阵分块</p><h4 id=tiled-matrix-multiplication class=heading-element><span>Tiled Matrix Multiplication</span>
<a href=#tiled-matrix-multiplication class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/tiled-matrix-multiplication.gif style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>tiled matrix multiplication之所以减小了对内存带宽的要求，是因为一个thread读取的内容是可以被其他thread共享的。在分tile之前，一个thread从global memory读取的数据只会让它自己使用，但是分了tile之，一个thread从global memory加载的数据也可以被处于同一个tile中的其他thread所访问，增加了数据重用率。</p><p>More information please see the original passage <a href=https://penny-xu.github.io/blog/tiled-matrix-multiplication target=_blank rel="external nofollow noopener noreferrer">Tiled Matrix Multiplication</a>.</p><h4 id=reference-1 class=heading-element><span>Reference</span>
<a href=#reference-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><blockquote><ul><li>[1] <a href=https://github.com/NervanaSystems/maxas/wiki/SGEMM target=_blank rel="external nofollow noopener noreferrer">Intel-maxas | SGEMM</a></li></ul></blockquote><h3 id=reduction class=heading-element><span>Reduction</span>
<a href=#reduction class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=convolution class=heading-element><span>Convolution</span>
<a href=#convolution class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=understand-of-convolution class=heading-element><span>understand of convolution</span>
<a href=#understand-of-convolution class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>在 <a href=https://www.eet-china.com/mp/a109236.html target=_blank rel="external nofollow noopener noreferrer">很详细的讲解什么以及为什么是卷积</a> 一文中，作者从物理意义的角度解释了信号处理中的卷积操作</p><p>卷积操作的核心目的在于计算某一时刻下全局的信号强度值。具体的过程包括 “卷” 和 “积” 两个过程，系统响应函数 g 可以看为信号衰减的变化函数曲线，把 g 翻转过来并且平移的过程刚好遵循了信号衰减的变化情况。积的原因在于某一时刻下全局的信号强度值不仅和某一时刻的信号相关，还和此前的还未衰减完成的信号强度相关，所以实际需要进行累加操作。</p><p>卷积这块有一个神奇的题目和神奇的公式：</p><p>问: kD convolution 过程中（不考虑ghost elements的运算），每个元素的平均访问次数</p><p>答: 平均访问次数=$\frac{output_{width}^k \times mask_{width}^k}{input_{width}^k}$</p><p>其中，在$stride=1$的情况下，满足$output_{width} = input_{width} - mask_{width} + 1$,即$input_{width} = output_{width} + mask_{width} - 1$</p><p>2D convolution上述公式的验证代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;iostream&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;vector&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;algorithm&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>m</span><span class=p>,</span> <span class=n>n</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cin</span> <span class=o>&gt;&gt;</span> <span class=n>m</span> <span class=o>&gt;&gt;</span> <span class=n>n</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>width</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cin</span> <span class=o>&gt;&gt;</span> <span class=n>width</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>auto</span> <span class=n>count</span> <span class=o>=</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;&gt;</span><span class=p>(</span><span class=n>m</span> <span class=o>+</span> <span class=mi>10</span><span class=p>,</span> <span class=n>std</span><span class=o>::</span><span class=n>vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span> <span class=o>+</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>begin_x</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>begin_x</span> <span class=o>+</span> <span class=n>width</span> <span class=o>-</span> <span class=mi>1</span> <span class=o>&lt;=</span> <span class=n>m</span><span class=p>;</span> <span class=n>begin_x</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>begin_y</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>begin_y</span> <span class=o>+</span> <span class=n>width</span> <span class=o>-</span> <span class=mi>1</span> <span class=o>&lt;=</span> <span class=n>n</span><span class=p>;</span> <span class=n>begin_y</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>			<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>width</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>				<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>width</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>					<span class=kt>int</span> <span class=n>x</span> <span class=o>=</span> <span class=n>begin_x</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>begin_y</span> <span class=o>+</span> <span class=n>j</span><span class=p>;</span>
</span></span><span class=line><span class=cl>					<span class=n>count</span><span class=p>[</span><span class=n>x</span><span class=p>][</span><span class=n>y</span><span class=p>]</span><span class=o>++</span><span class=p>;</span>
</span></span><span class=line><span class=cl>				<span class=p>}</span>
</span></span><span class=line><span class=cl>			<span class=p>}</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=kt>float</span> <span class=n>sum</span> <span class=o>=</span> <span class=mf>0.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;=</span> <span class=n>m</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;=</span> <span class=n>n</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>			<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>count</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>&lt;&lt;</span> <span class=sc>&#39; &#39;</span><span class=p>;</span>
</span></span><span class=line><span class=cl>			<span class=n>sum</span> <span class=o>+=</span> <span class=n>count</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>		<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span> <span class=o>&lt;&lt;</span> <span class=n>sum</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=s>&#34;</span><span class=se>\n</span><span class=s>&#34;</span> <span class=o>&lt;&lt;</span> <span class=p>(</span><span class=n>sum</span> <span class=o>/</span> <span class=p>(</span><span class=n>m</span> <span class=o>*</span> <span class=n>n</span><span class=p>))</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><h4 id=tiled-1d-convolution class=heading-element><span>Tiled 1D Convolution</span>
<a href=#tiled-1d-convolution class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>边界处理：</p><ul><li>判断法</li><li>扩展法</li></ul><p><strong>背景介绍</strong></p><ol><li>假定每个thread处理一个output element</li><li>每一个block要处理的部分称为一个input tile, 生成的部分称为一个output tile</li></ol><p><strong>Common calculation formula</strong></p><p>下图包含了一些常见概念的对应关系。</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201114459.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><ol><li>$input \ tile \ width = output \ tile \ width + \frac{mask \ width - 1}{2} \times 2 = output \ tile \ width + (mask \ width - 1)$</li></ol><p>需要额外关注的一点是，有一些题目会给定 output tile width 和 mask width，要求计算input tile width，这类题目一般认为 input tile 是包含 helo cells 的，也就是下图中黄色部分标注的内容，其对应的output tile是下图中上方的黄色部分标注的内容。</p><p><strong>Two tiled strategy</strong></p><ol><li>Strategy-1 (most intuitive): loading all input data elements into the shared memory, which is needed for calculating all output elements of a thread block</li></ol><p>这种方式存在的问题是，存在重复的 global memory 的访问。按照现在的划分方式，每一个 tile 都对应着一个 block, 而不同 block 对应的 shared memory 是不同的，因此 tile1 中的 2 和 3 号元素，虽然在 加载 tile0 时已经被加载到shared memory中了，但是存储 tile0 的 shared memory 和存储 tile1 的 shared memory 是不同的存储空间，因此 2 和 3 号元素需要从 global memory 中访问 2 次。</p><blockquote><p>如果只使用一个 block 来计算确实可以解决重复访问的问题，但是仅使用一个 block，无法充分利用大量的 SM（CUDA 中采用的 2 种 scheduling：block scheduling 和 warp scheduling，只使用一个 block 就无法充分进行 block scheduling 了）</p></blockquote><p><strong>Performance Evaluation</strong>
所谓的性能评估就是分别计算一下采用 tile 和不采用 tile 时 global memory 的访问次数。注意以下在分析时，均只分析一个 block 的访存情况</p><ol><li>basic 1D convolution</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=n>convolution_1D_ba</span> <span class=nf>sic_kernel</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>N</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>P</span><span class=p>,</span> <span class=kt>int</span> <span class=n>Mask_Width</span><span class=p>,</span> <span class=kt>int</span> <span class=n>Width</span><span class=p>)</span> <span class=p>{</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>Pvalue</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>N_start_point</span> <span class=o>=</span> <span class=n>i</span> <span class=o>-</span> <span class=p>(</span><span class=n>Mask_Width</span><span class=o>/</span><span class=mi>2</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>Mask_Width</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>N</span> <span class=n>start_</span> <span class=n>point</span> <span class=o>+</span> <span class=n>j</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=o>&amp;&amp;</span> <span class=n>N_</span> <span class=n>start_</span> <span class=n>point</span> <span class=o>+</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>Width</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>Pvalue</span> <span class=o>+=</span> <span class=n>N</span><span class=p>[</span><span class=n>N_start_point</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span><span class=o>*</span><span class=n>M</span><span class=p>[</span><span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>P</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>Pvalue</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><p>为了绘图的方便，这里假设采用的 mask width 为 5，即左右两侧会各出现 2 个 ghost cell
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201416808.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>假设 ghost cell 不需要读取 global memory。考虑一种计算方式：假设 ghost cell 需要读取 global memory，计算总的访存次数，然后减去 ghost cell 涉及到的访存次数。</p><ol><li>总的访存次数</li></ol><p>每一个 output element 对应的访存次数为 mask width 次。因此每一个 thread block 的访存次数为 $blockDim.x \times mask \ width$</p><ol start=2><li>ghost cell 涉及到的访存次数</li></ol><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201427241.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>首先只考虑最左侧的 ghost cell 的访存情况，最左侧的 cell 只有一个 output element 的计算才会涉及，每往右侧走一个涉及到的访问次数就会加 1，最左侧的 ghost cells 的最右侧一个，涉及的次数是$\frac{mask \ width - 1}{2}$</p><p>因此再考虑上右侧，全部ghost cell 涉及的访存次数为 $(1 + 2 + \dots + \frac{mask \ width - 1}{2}) \times 2 = \sum_{i=1}^{\frac{mask \ width - 1}{2}}(i) \times 2$</p><ol start=2><li>tiled 1D convolution</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>convolution_1D_tiled_kernel</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>N</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>P</span><span class=p>,</span> <span class=kt>int</span> <span class=n>Mask_Width</span><span class=p>,</span> <span class=kt>int</span> <span class=n>Width</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>__shared__</span> <span class=kt>float</span> <span class=n>N_ds</span><span class=p>[</span><span class=n>TILE_SIZE</span> <span class=o>+</span> <span class=n>MAX_MASK_WIDTH</span> <span class=o>-</span> <span class=mi>1</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>n</span> <span class=o>=</span> <span class=n>Mask_Width</span><span class=o>/</span><span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>halo_index_left</span> <span class=o>=</span> <span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> 
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>&gt;=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>-</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>N_ds</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>-</span> <span class=p>(</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>-</span> <span class=n>n</span><span class=p>)]</span> <span class=o>=</span> <span class=p>(</span><span class=n>halo_index_left</span> <span class=o>&lt;</span> <span class=mi>0</span><span class=p>)</span> <span class=o>?</span> <span class=mi>0</span> <span class=o>:</span> <span class=n>N</span><span class=p>[</span><span class=n>halo_index_left</span><span class=p>];</span> 
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>N_ds</span><span class=p>[</span><span class=n>n</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>N</span><span class=p>[</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>halo_index_right</span> <span class=o>=</span> <span class=p>(</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span> 
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>N_ds</span><span class=p>[</span><span class=n>n</span> <span class=o>+</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>halo_index_right</span> <span class=o>&gt;=</span> <span class=n>Width</span><span class=p>)</span> <span class=o>?</span> <span class=mi>0</span> <span class=o>:</span> <span class=n>N</span><span class=p>[</span><span class=n>halo_index_right</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>Pvalue</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> 
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>Mask_Width</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span> 
</span></span><span class=line><span class=cl>        <span class=n>Pvalue</span> <span class=o>+=</span> <span class=n>N_ds</span><span class=p>[</span><span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>j</span><span class=p>]</span><span class=o>*</span><span class=n>M</span><span class=p>[</span><span class=n>j</span><span class=p>];</span> 
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>P</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>Pvalue</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312201459756.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>此时的代码分析起来有点困难，但是计算要简单很多，因为除了 ghost cells 不用访存，helo cells 访存2次，其余 cell 都只需要访存 1 次</p><ol><li>对于 boundary thread block 来说，访存次数为 $blockDim.x + \frac{mask \ width - 1}{2}$</li><li>对于 internal thread block 来说，访存次数为 $blockDim.x + 2 \times \frac{mask \ width - 1}{2}$</li></ol><h4 id=2d-convolution class=heading-element><span>2D Convolution</span>
<a href=#2d-convolution class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>想要使用 shared memory 来降低 DRAM（global memory）的访问次数，加载到 shared memory 中的数据必须发生数据重用。我理解着只有一个block多对应一些数据，就会包含一些数据重用了。</p><h4 id=3d-convolutoin class=heading-element><span>3D Convolutoin</span>
<a href=#3d-convolutoin class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><h2 id=gpu-microarchitecturesimt-core class=heading-element><span>GPU Microarchitecture(SIMT Core)</span>
<a href=#gpu-microarchitecturesimt-core class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>The microarchitecture of the GPU pipeline is divided into a SIMT front-end and a SIMD back-end.</p><p>The GPU pipeline consists of three scheduling “loops”:</p><ol><li>instruction fetch loop: Fetch, I-Cache, Decode, and I-Buﬀer</li><li>instruction issue loop: I-Buﬀer, Scoreboard, Issue, and SIMT Stack</li><li>register access scheduling loop: Operand Collector, ALU, and Memory</li></ol><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171448912.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>注意蓝色和橙色部分存在I-Buffer的交叉</p></blockquote><p>在讲述One/Two/Three-Loop Approximation之前，需要明确的是我们要分析的是SIMT Core的结构，要考虑的问题是如何统筹规划每一个warp所要执行的指令。这一点前提认知很重要，会直接影响到对后面一些结构的理解。</p><p>还有一个比较重要的事情，就是弄清楚这里说的one,two,three到底指的是什么，目前理解指的是3种scheduler,分别是SIMT stack, Scoreboard 和 Operand Collector.</p><h3 id=one-loop-approximation class=heading-element><span>One-Loop Approximation</span>
<a href=#one-loop-approximation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=simt-stack class=heading-element><span>SIMT stack</span>
<a href=#simt-stack class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>The SIMT stack is used to solve the thread divergence. It sends the target PC to the fetch unit and the active mask to the issue unit.</p><blockquote><ul><li>The fetch unit is used to control which instruction is fetched next.</li><li>The issue unit is used to control which lanes of the warp are active.</li></ul></blockquote><p>The mask is a bit vector with 1 for every thread that is active for the corresponding control flow branch. When that control flow branch is being executed, only the threads with 1 in the corresponding branch bit execute those instructions.</p><p>A simple method to address the control divergence is PDOM mechanism(post-dominator stack-based reconvergence mechanism). The post-dominator active mask has 1 for every thread that is active in each of the divergent paths that reconverge at that point.</p><p>When we hit a divergent point, we push on the stack:</p><ul><li>(1) the current active mask and the next PC at the reconverge point;</li></ul><blockquote><p>虽然这里说的是current active mask，但是current active mask和 reconverge point 的active mask实际是一样的</p></blockquote><ul><li>(2) the active mask, PC, and reconverge PC for every branch.</li></ul><blockquote><p>如果有多个branch，入栈的先后顺序一般采取 the entry with the most active threads ﬁrst and then the entry with fewer active threads。我的理解是thread越多越有可能引入新的branch，所以优先让较少thread先执行，避免使局面变得更加混乱。由于栈是FILO，所以the entry with fewer active threads后入栈.不过这只是一般做法，并非强制要求。</p></blockquote><p>For example, look at the following picture, we hit a divergent point A</p><ul><li>(1) the current active mask / reconverge point active mask is 1111, and the reconverge point is G</li><li>(2) the branch of this divergent point A contains B and F</li></ul><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181346451.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>关于(2)中不同branch入栈的顺序，下图B分支点处采用的是一般的原则，A处则和一般原则相反</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181352896.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>以上我们只讲述了SIMT stack是怎么使用的，现在思考一下它到底起到了什么作用，我们为何需要引入这样一种结构</p><p>观察上图中的(b)部分，不难发现程序的执行流从(a)那种复杂的形式，已经转变为了(b)中这种串行的方式。每个cycle执行一条指令即可，所以引入stack的目标就是 To achieve this serialization of divergent code paths one approach.</p><hr><p>The SIMT stack helps eﬃciently handle two key issues that occur when <strong>all threads can execute independently</strong>:</p><ol><li>nested control ﬂow</li><li>skipping computation</li></ol><p>a warp is eligible to issue an instruction if it has a valid and ready (according to the scoreboard) in the I-Buffer.</p><h4 id=simt-deadlock class=heading-element><span>SIMT deadlock</span>
<a href=#simt-deadlock class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p><strong>What is the SIMT deadlock problem?</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=o>*</span><span class=n>mutex</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=c1>// A
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>while</span> <span class=p>(</span><span class=o>!</span><span class=n>atomicCAS</span><span class=p>(</span><span class=n>mutex</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>));</span> <span class=c1>// B
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>atomicExch</span><span class=p>(</span><span class=n>mutex</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span> <span class=c1>// C
</span></span></span></code></pre></td></tr></table></div></div><p>上述代码中包含一个分支， 考虑在使用 SIMT-stack 时的场景</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312191937165.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><blockquote><p>图中B表示条件命中，B&rsquo;表示条件不命中</p></blockquote><p>SIMT-stack内容如下</p><table><thead><tr><th>Ret/Reconv PC</th><th>Next PC</th><th>Active Mask</th></tr></thead><tbody><tr><td>-</td><td>C</td><td>mask-A / mask-C</td></tr><tr><td>C</td><td>B'</td><td>mask-B'</td></tr><tr><td>C</td><td>B</td><td>mask-B</td></tr></tbody></table><blockquote><p>最下方一行是TOS(top of stack)</p></blockquote><p>根据SIMT stack的内容，首先弹栈会让第一个命中的thread退出循环，它通过<code>atomicCAS()</code>将mutex修改为了1。然后SIMT stack会继续弹栈，这时候其他thread开始执行。但是问题在于现在还没有把C弹栈，所以mutex还没有被改回0，而现在正在执行的指令必须等到mutex等于0后才可以正常执行从而推出循环，而它们不执行完，SIMT stack就不会继续弹栈。这就造成了死锁。</p><p><strong>A mechanism for avoiding SIMT deadlock</strong>
stackless branch reconvergence mechanism</p><p>Assuming a warp contains 32 threads, the barrier participation mask is 32-bits wide.</p><p>If a bit is set, that means the corresponding thread in the warp participates in this convergence barrier</p><p>The barrier participation mask is used by the warp scheduler to stop threads at a specific convergence barrier</p><h3 id=two-loop-approximation class=heading-element><span>Two-Loop Approximation</span>
<a href=#two-loop-approximation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>The problem of One-Loop Approximation is that it assumes that the warp will not issue another instruction until the first instruction completes execution, so maybe it will cause a long execution latencies.</p><p>A method to address this problem is that issue a subsequent instruction from a warp while earlier instructions have not yet completed, but it will face a new problem, we don&rsquo;t know whether the next instruction to issue for the warp has a dependency upon an earlier instruction that has not yet completed execution.</p><p>So a separate scheduler is introduced, it is used to decide which of several instructions in the instruction buﬀer should be issued next to the rest of the pipeline to avoid dependency problem.</p><p>总结一下，简单来说，所谓的two-loop approximation不过是面对one-loop approximation所遇到的问题，考虑额外添加一个调度器，在前一条指令还没有执行完毕时就能够发射其他指令以类似流水线的方式执行从而可以增加指令吞吐量，但是遇到一个依赖性的问题，可能还没有执行的指令和要发射的指令存在数据相关，所以就引入了计分板来尝试解决这个问题，然后又发现单纯使用计分板同样遇到了一些问题，然后就有一个大佬提出了一种解决方案。这整个过程就是一个发现问题，然后解决问题的循环。</p><h4 id=scoreboard class=heading-element><span>Scoreboard</span>
<a href=#scoreboard class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>Scoreboards can be designed to support either in-order execution or out-of-order execution.</p><p>Scoreboarding keeps track of dependencies to make sure we do not allow an instruction to start executing if there is a dependency with a previous instruction that is still executing. As the following example shows:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>add r3, r2, r1    // r3 = r2+r1
</span></span><span class=line><span class=cl>sub r5, r3, r4    // RAW
</span></span><span class=line><span class=cl>add r5, r2, r1    // WAW</span></span></code></pre></td></tr></table></div></div><ol><li>After the first instruction issues, we mark r3 as unavailable.</li><li>When the sub instruction arrives, it cannot issue since r3 is not ready (RAW).</li><li>After the first instruction completes, sub now can read the new value of r3 and issue, marking r5 which is the destination register as unavailable.</li><li>The third instruction cannot issue since it writes to r5 (WAW).</li></ol><blockquote><p>Please note that in the above example, we issue in order: the read has already read the register values when we issue the write after it. So there is no WAR.</p></blockquote><p><strong>The two problem and solve method of the above implementation of scoreboard is used in in-order execution</strong></p><ol><li>The simple in-order scoreboard design needs too many storage space</li></ol><blockquote><p>Solution: change the implementation of scoreboard</p></blockquote><ul><li>The original way is hold a single bit per register per warp(每个warp都有一个完整的下图的结构), it looks like the following picture</li></ul><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172233091.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><ul><li>Now, the design contains a small number of entries per warp(每个warp一个bit vector), where each entry is the identifier of a register. It looks like the following picture</li></ul><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312172236391.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><ol start=2><li>If an instruction that encounters a dependency must repeatedly lookup its operands in the scoreboard until the prior instruction it depends upon writes its results to the register file. It consumes too many computation resources</li></ol><p>首先可以确定的一点在计分板结构改变后，维护计分板内容的方式也发生了改变。根据书上说的，改变了修改计分板的时机。我现在对于解决这个问题大致的一个理解是，计分板和指令buffer是两个分离的结构，当一条指令执行结束后会修改计分板的内容，然后顺便把指令buffer中对应存在依赖的寄存器标记清空，这样在从指令buffer中取指令的时候拿到的就是新的状态，如果从指令buffer中读取到的指令不存在对于某个寄存器的依赖时就去执行这一指令，如果存在就换别的执行，不过这块的逻辑还没有看的太明白。</p><h3 id=three-loop-approximation class=heading-element><span>Three-Loop Approximation</span>
<a href=#three-loop-approximation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=operand-collector class=heading-element><span>Operand Collector</span>
<a href=#operand-collector class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>为了隐藏长时间的内存访问延迟，一种方法就是实现以周期为单位对warp进行切换，通过warp切换来掩盖延迟。</p><p>为了实现这一点，就需要使用较大的 registers file。而 registers file最朴素的实现方式就是 one port per operand per instruction issued per cycle， 但是这样我理解着是只能串行访问，吞吐量比较低。所以一种方式就是划分bank，不同bank可以做到并行访问，从而增大并行度。</p><p>引入了 bank，同时也就引入了bank conflict, 下图的naive microarchitecture就具有这种问题，设计operand collector也正是为了解决这种问题, operand collector就是引入的第3个scheduler，完成指令在并行访问寄存器堆时的调度工作。</p><p>naive microarchitecture for providing increased register file bandwidth(by single-ported logical banks of registers)</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181639756.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>operand collector microarchitecture(the staging registers have been replaced with collector units)</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181640755.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>operand collector究竟是怎么调度的似乎书上并没有详细描述，只是给了一种新的从 register 到 bank 的映射方式(如下图所示），确保不同 warp 原来会被分到同一个 bank 的register 现在会被分到不同bank，但是同一个 warp 内不同 thread 之间的 bank conflict 并没有解决, 也就是它只对减少不同 warp 间的 bank conflict 起到了作用。</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312181709819.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p>具有 WAR hazard, 3种可能的解决方法：</p><ol><li>release-on-commit warpboard: at most one instruction per warp to be executing</li><li>release-on-read warpboard: only one instruction at a time per warp to be collecting operands</li><li>instruction level parallelism</li></ol><h4 id=instruction-replay class=heading-element><span>Instruction Replay</span>
<a href=#instruction-replay class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>当一条指令在GPU流水线上发生结构冒险了怎么办？对于一般的CPU来说我们可以简单的暂停当前指令，直到结构冒险消除再继续执行。但是这种方法在高吞吐量的系统中并不适用，停滞的指令可能处于任务的关键路径上进而影响到任务的完成时间，并且大量的停滞需要额外的缓冲区来存储寄存器信息。同时停滞一个指令可能会停滞其他完全不必要停滞的指令，降低了系统的吞吐量。</p><p>在GPU中我们可以尝试使用instruction replay来解决这个问题。instruction replay最早是在CPU的推测执行中作为一种恢复机制出现的，当我们执行了错误的分支，正确的指令会被重新取回并执行，消除错误分支的影响。在GPU中我们一般会避免推测执行，因为这会浪费宝贵的能源以及吞吐量。GPU实现instruction replay是为了减少流水线阻塞以及芯片面积和对应的时间开销。</p><p>在GPU上实现instruction replay可以通过在instruction buffer中保存当前指令直到这条指令已经执行完成，然后再将其移出。</p><h3 id=memory-system class=heading-element><span>Memory system</span>
<a href=#memory-system class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h4 id=first-level class=heading-element><span>First Level</span>
<a href=#first-level class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>The shared memory is implemented as a static random access memory (SRAM).</p><p>每一个lane都有一个对应的bank，bank上各有一个读port和一个写port</p><p>shared memory 和 global memory 的访问粒度似乎是不同的，shared memory可以以warp为单位进行访问，但是global memory每次就是访问一个cache block</p><blockquote><p>While the data array is highly banked to enable ﬂexible access to shared memory by individual warps, access to global memory is restricted to a single cache block per cycle.</p></blockquote><p>The L1 cache block size is 128 bytes in Fermi and Kepler and is further divided into four 32byte sectors in Maxwell and Pascal.</p><p>要是按照这个的说法，每次读取global memory最小单位就是32B</p><p>The 32-byte sector size corresponds to the minimum size of data that can be read from a recent graphics DRAM chip in a single access.</p><p>一个128B的cache block，会分为32个bank，每个bank对应4B(32-bit entries)
Each 128-byte cache block is composed of 32-bit entries at the same row in each of the 32 banks.</p><p>The data to be written either to shared memory or global memory is ﬁrst placed write data buﬀer (WDB).</p><h4 id=memory-partition-unit class=heading-element><span>Memory Partition Unit</span>
<a href=#memory-partition-unit class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><p>The memory access schedulers in memory partition unit contains <strong>frame buffer</strong>(FB) and <strong>raster operation</strong>(ROP) unit.</p><ol><li>L2 cache
To match the DRAM atom size of 32 bytes in GDDR5, each cache line inside the slice has four 32-byte sectors.</li></ol><p>L2 cache line的长度是128B，由4个32B组成</p><h3 id=warp class=heading-element><span>Warp</span>
<a href=#warp class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>The multiprocessor creates, manages, schedules, and executes threads in groups of 32 parallel threads called warps.</p></blockquote><p>一个SM可能执行多个block。虽然说不同block之间可以并行执行（不过要求在不同SM上才可以并行），但是映射到同一个SM的block，它上面的warp是不能并行执行的，只能相互等待。</p><p><strong>How block’s threads get mapped to warps?</strong></p><p>We can get answer from <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture target=_blank rel="external nofollow noopener noreferrer">4.1. SIMT Architecture</a>.</p><blockquote><p>The way a block is partitioned into warps is always the same; each warp contains threads of consecutive, increasing thread IDs with the first warp containing thread 0.</p></blockquote><p>从这个答案中，不难引发另一个疑问，即</p><p><strong>How thread ID can be calculated?</strong></p><p>We can get answer from <a href=https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy target=_blank rel="external nofollow noopener noreferrer">2.2. Thread Hierarchy</a>.</p><blockquote><p>The index of a thread and its thread ID relate to each other in a straightforward way:</p><ul><li>For a one-dimensional block, they are the same;</li><li>for a two-dimensional block of size $(D_x, D_y)$, the thread ID of a thread of index $(x, y)$ is $(x + y \times D_x)$;</li><li>for a three-dimensional block of size $(D_x, D_y, D_z)$, the thread ID of a thread of index $(x, y, z)$ is $(x + y \times D_x + z \times D_x \times D_y)$.</li></ul></blockquote><p>(Editer replenishment): please note that the above comparison is between <strong>index of thread</strong> and <strong>thread ID</strong>, so dont&rsquo;s be confused about the first situation. i.e. &ldquo;for a one-dimensional block, they are the same&rdquo;, it means for a one-dimensional block, the thread ID is equals to the index of this thread.</p><p>According to the question of &ldquo;<a href=https://stackoverflow.com/questions/31058001/cuda-griddim-blockdim-and-threadidx target=_blank rel="external nofollow noopener noreferrer">Does CUDA think of multi-dimensional gridDim, blockDim and threadIdx just as a linear sequence?</a>&rdquo;, we can see the type of thread organization as the <strong>row major ordered multi-dimensional arrays</strong>. But please note the difference between the index in CUDA and the index of traditional array or matrix.</p><p>For traditional array or matrix, we are used to use the <strong>(row_index, col_index)</strong> to indicate the position of an element in an array or a matrix. But in CUDA, the coordinates seem to become adverse, CUDA uses the <strong>(x = column_number, y = row_number)</strong> to express a grid or block.</p><p>In fact, these two expressions don&rsquo;t create conflicts. The (row_index, col_index) is a perspective of actual storage mode. Now, if we place the array or the matrix into a coordinate system, we can also use the (x, y) to indicate an element of the array or matrix.</p><p>We can say that the (row_index, col_index) is a coordinate from storage structure perspective and the (x = column_number, y = row_number) is a coordinate from math coordinate system perspective.</p><p>Because the concept grid and block are just for programmer convenience, so they don&rsquo;t imply the actual storage structure, so the CUDA use the math coordinate to indicate the position of an element in an array or a matrix. For the thread index $(x, y)$, the x is the column number, y is the row number, it is like the following picture of block index.</p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312061851353.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p><a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312062024529.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p><p><strong>How to understand and calculate occupancy ?</strong></p><h4 id=warp-scheduling-strategy class=heading-element><span>Warp Scheduling Strategy</span>
<a href=#warp-scheduling-strategy class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h4><ol><li><p>Loose Round Robin (LRR)
处于Ready状态了就开始执行，否则跳过先发射下一个warp
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171630189.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p></li><li><p>Two-level (TL)
把warp分为两组，Pending warps 和 Active warps，warp在这两个组之间变换，当warp需要等待某些长延迟操作时，就切换到pending warp那一组，当条件就绪后，则转到active warp这一组，在active warp这一组采用LRR的调度策略
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171633345.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p></li><li><p>Greedy-then-oldest (GTO)
考虑到局部性，会贪婪地执行一个warp，直到它进入stall状态才会切换其他warp执行
<a class=lightgallery href="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png?size=large" data-thumbnail="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png?size=small" data-sub-html="<h2>https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png</h2>"><img loading=lazy src=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png alt=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png srcset="https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png?size=small, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png?size=medium 1.5x, https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png?size=large 2x" data-title=https://cdn.jsdelivr.net/gh/gaohongy/cloudImages@master/202312171635290.png style="background:url(/blog/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p></li></ol><h2 id=cuda-related-documents class=heading-element><span>CUDA Related Documents</span>
<a href=#cuda-related-documents class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><ol><li><a href=https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html target=_blank rel="external nofollow noopener noreferrer">NVIDIA CUDA Compiler Driver NVCC</a></li></ol><h2 id=reference-2 class=heading-element><span>Reference</span>
<a href=#reference-2 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><ul><li>[1] <a href=https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf target=_blank rel="external nofollow noopener noreferrer">CUDA C++ Programming Guide</a></li><li>[2] <a href=https://forums.developer.nvidia.com/t/does-nvcc-include-header-files-automatically/48972 target=_blank rel="external nofollow noopener noreferrer">Does NVCC include header files automatically?</a></li><li>[3] <a href=https://lulaoshi.info/gpu/python-cuda/stride.html target=_blank rel="external nofollow noopener noreferrer">网格跨步</a></li><li>[4] <a href=https://docs.nvidia.com/cuda/cuda-runtime-api/index.html target=_blank rel="external nofollow noopener noreferrer">CUDA Runtime API Documentation</a> <strong>(Please note the version of coda)</strong></li><li>[5] <a href=https://www.zhihu.com/column/c_1139113249399345152 target=_blank rel="external nofollow noopener noreferrer">CUDA编程方法论-知乎专栏</a></li><li>[6] <a href="https://www.youtube.com/playlist?list=PLxNPSjHT5qvtYRVdNN1yDcdSl39uHV_sU" target=_blank rel="external nofollow noopener noreferrer">CUDA Crash Course - Youtube</a></li><li>[7] <a href=https://team.inria.fr/pacap/members/collange/ target=_blank rel="external nofollow noopener noreferrer">GPGPU架构优秀PPT(Teaching部分)</a></li><li>[8] <a href=https://tschmidt23.github.io/cse599i/ target=_blank rel="external nofollow noopener noreferrer">Accelerated Computing - Programming GPUs</a></li><li>[9] <a href=https://www.zhihu.com/column/c_1522503697624346624 target=_blank rel="external nofollow noopener noreferrer">CUDA编程入门及优化 | 知乎</a></li><li>[10] <a href=https://www.cnblogs.com/wujianming-110117/p/12992932.html target=_blank rel="external nofollow noopener noreferrer">Tensor Core技术解析（上）</a></li><li>[11] <a href=https://www.cnblogs.com/wujianming-110117/p/12993096.html target=_blank rel="external nofollow noopener noreferrer">Tensor Core技术解析（下）</a></li><li>[12] <a href=https://developer.nvidia.com/tools-overview target=_blank rel="external nofollow noopener noreferrer">NVIDIA Developer Tools 汇总</a></li><li>[13] <a href=https://zhuanlan.zhihu.com/p/522546744 target=_blank rel="external nofollow noopener noreferrer">《General-Purpose Graphics Processor Architecture》中文翻译</a></li></ul></blockquote><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#simt-architecture:~:text=on%20that%20path.-,Branch,-divergence%20occurs%20only" target=_blank rel="external nofollow noopener noreferrer">GPU SIMT Architecture - branch divergence</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="Updated on 2024-06-10 01:11:59">Updated on 2024-06-10&nbsp;</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/blog/>Home</a></span></section></div><div class=post-nav><a href=/blog/posts/linux/linux-basic-knowledge/ class=post-nav-item rel=prev title="Linux Basic Knowledge"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Linux Basic Knowledge</a>
<a href=/blog/posts/compile-link/cuda-compilation/ class=post-nav-item rel=next title="CUDA Compilation">CUDA Compilation<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=Contents><h2 class=toc-title>Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>This website works best with JavaScript enabled.</div></noscript></div><link rel=stylesheet href=/blog/lib/lightgallery/css/lightgallery-bundle.min.css><link rel=preload href=/blog/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/blog/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/blog/lib/cookieconsent/cookieconsent.min.css><script src=/blog/lib/autocomplete/autocomplete.min.js defer></script><script src=/blog/lib/fuse/fuse.min.js defer></script><script src=/blog/lib/twemoji/twemoji.min.js defer></script><script src=/blog/lib/lightgallery/lightgallery.min.js defer></script><script src=/blog/lib/lightgallery/plugins/thumbnail/lg-thumbnail.min.js defer></script><script src=/blog/lib/lightgallery/plugins/zoom/lg-zoom.min.js defer></script><script src=/blog/lib/katex/katex.min.js defer></script><script src=/blog/lib/katex/auto-render.min.js defer></script><script src=/blog/lib/katex/mhchem.min.js defer></script><script src=/blog/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{enable:!1},cookieconsent:{content:{dismiss:"Got it!",link:"Learn more",message:"This website uses Cookies to improve your experience."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},lightgallery:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{distance:100,findAllMatches:!1,fuseIndexURL:"/blog/index.json",highlightTag:"em",ignoreFieldNorm:!1,ignoreLocation:!1,isCaseSensitive:!1,location:0,maxResultLength:20,minMatchCharLength:2,noResultsFound:"No results found",snippetLength:50,threshold:.3,type:"fuse",useExtendedSearch:!1},twemoji:!0,version:"v0.3.9"}</script><script src=/blog/js/theme.min.js defer></script></body></html>