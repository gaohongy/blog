[{"categories":["Compile-Link"],"content":"与 CUDA Compilation 不同在于 The tools used in the CUDA compilation are all closed source except gcc, g++ etc., for example fatbinary and nvlink. We need to substitue these tools to tools in clang system. Clang Offload Bundler is used to combined different code for different machine structurel. Clang Offload Packager is used to embed device code into host code. Clang Linker Wrapper is used to . 这里面最复杂的感觉是怎么处理链接关系，如果仅仅说代码嵌入，从 CUDA 的流程来看，在 cudafe1.cpp include stub.c 生成 .o 这一步中 host code 中就已经包含了 device code，如果仅仅说 embed 的话，这显然就已经完成了，但是为何 CUDA 还进行后续那么多步骤，因为这一步生成的 .o 显然是无法运行的，device code 都还只是一个 extern signal，还需要同 CUDA runtime library 进行链接，这个过程该怎么进行比较难想。 但是链接的难点是，目前程序中的 device code 二进制的 fatbinary，同 CUDA runtime library 之间的链接该如何完成 ","date":"2024-06-07","objectID":"/blog/posts/compile-link/heterogeneous-compilation/:0:0","tags":null,"title":"Heterogeneous Compilation","uri":"/blog/posts/compile-link/heterogeneous-compilation/"},{"categories":["Compile-Link"],"content":"目标分析 分析的核心目的是：学习现有异构程序编译链接生成 host end 单可执行文件的方法，将流程迁移到图计算机上实现异构编译。现有的场景基础是，已经生成了 device ELF object，后续需要由此生成带额外信息的结构化数据，然后嵌入到 host object 中，经过链接器链接 runtime library，生成 host end 可执行文件。 因为目前没有其他 device，只能拿 gpu 的进行。关键在于分析打包的格式，打包后的数据嵌入流程，以及在这种嵌入方式下，链接工作和嵌入后文件结构之间的关联。 cubin 和 fatbinary 的区别在于，前者是打包后生成的普通二进制文件，虽然打包遵循了一定格式，但这种格式通过 file 是无法获知的，显示的仅仅是 data；后者也是二进制文件，但是其遵循的是 ELF 文件格式。 CUDA的编译流程是： .cu -\u003e .s (clang 生成 ptx) clang -cc1 \\ -triple nvptx64-nvidia-cuda \\ -aux-triple x86_64-unknown-linux-gnu \\ -S \\ -dumpdir main- \\ -disable-free \\ -clear-ast-before-backend \\ -main-file-name main.cu \\ -mrelocation-model static \\ -mframe-pointer=all \\ -fno-rounding-math \\ -no-integrated-as \\ -aux-target-cpu x86-64 \\ -fcuda-is-device \\ -mllvm \\ -enable-memcpyopt-without-libcalls \\ -fcuda-allow-variadic-functions \\ -mlink-builtin-bitcode /home/jiaheng/dev/cuda-12.1/nvvm/libdevice/libdevice.10.bc \\ -target-sdk-version=12.1 -target-cpu sm_52 \\ -target-feature +ptx81 \\ -debugger-tuning=gdb \\ -fno-dwarf-directory-asm \\ -fdebug-compilation-dir=/home/jiaheng/gaohy/clang-offload-packager-test \\ -v \\ -resource-dir /home/jiaheng/gaohy/llvm-install/lib/clang/19 \\ -internal-isystem /home/jiaheng/gaohy/llvm-install/lib/clang/19/include/cuda_wrappers \\ -include __clang_cuda_runtime_wrapper.h \\ -c-isystem /home/jiaheng/gaohy/opencv-install/include \\ -c-isystem /home/jiaheng/gaohy/llvm-install/include \\ -c-isystem . \\ -cxx-isystem /home/jiaheng/gaohy/opencv-install/include \\ -cxx-isystem /home/jiaheng/gaohy/llvm-install/include \\ -cxx-isystem . \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9 \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/x86_64-linux-gnu/c++/9 \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/backward \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9 \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/x86_64-linux-gnu/c++/9 \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../include/c++/9/backward \\ -internal-isystem /home/jiaheng/gaohy/llvm-install/lib/clang/19/include \\ -internal-isystem /usr/local/include \\ -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include \\ -internal-externc-isystem /usr/include/x86_64-linux-gnu -internal-externc-isystem /include \\ -internal-externc-isystem /usr/include -internal-isystem /home/jiaheng/dev/cuda-12.1/include \\ -internal-isystem /home/jiaheng/gaohy/llvm-install/lib/clang/19/include \\ -internal-isystem /usr/local/include -internal-isystem /usr/lib/gcc/x86_64-linux-gnu/9/../../../../x86_64-linux-gnu/include \\ -internal-externc-isystem /usr/include/x86_64-linux-gnu \\ -internal-externc-isystem /include -internal-externc-isystem /usr/include \\ -fdeprecated-macro \\ -fno-autolink \\ -ferror-limit 19 \\ -fgnuc-version=4.2.1 \\ -fskip-odr-check-in-gmf \\ -fcxx-exceptions \\ -fexceptions \\ -cuid=2ca25e66da768d70 \\ -D__GCC_HAVE_DWARF2_CFI_ASM=1 \\ -o 1-main-sm_52-21aa72.s \\ -x cuda \\ main.cu .s -\u003e .cubin (ptxas汇编器由 ptx 生成 ELF 格式的 cubin) ptxas -m64 \\ -O0 \\ -v \\ --gpu-name sm_52 \\ --output-file 2-main-sm_52-02c6a6.cubin \\ 1-main-sm_52-21aa72.s .s + .cubin -\u003e .fatbin (fatbinary 将 ptx 和 对应的 ELF 打包为 fatbinary) fatbinary -64 \\ --create 3-main-4a26e4.fatbin \\ --image=profile=sm_52,file=2-main-sm_52-02c6a6.cubin \\ --image=profile=compute_52,file=1-main-sm_52-21aa72.s .fatbin -\u003e .o (clang 将 fatbinary 嵌入 host object，形成 ELF 格式的 .o) clang -cc1 \\ -triple x86_64-unknown-linux-gnu \\ -target-sdk-version=12.1 \\ -fcuda-allow-variadic-functions \\ -aux-triple nvptx64-nvidia-cuda \\ -emit-obj \\ -mrelax-all \\ -dumpdir main- \\ -disable-free \\ -clear-ast-before-backend \\ -main-file-name main.cu \\ -mrelocation-model pic \\ -pic-level 2 \\ -pic-is-pie \\ -mframe-pointer=all \\ -fmath-errno \\ -ffp-contract=on \\ -fno-rounding-math \\ -mconstructor-aliases \\ -funwind-tables=2 \\ -target-cpu x86-64 \\ -tune-cpu generic \\ -debugger-tuning=gdb \\ -fdebug-compilation-dir=/home/jiaheng/gaohy/clang","date":"2024-06-07","objectID":"/blog/posts/compile-link/heterogeneous-compilation/:1:0","tags":null,"title":"Heterogeneous Compilation","uri":"/blog/posts/compile-link/heterogeneous-compilation/"},{"categories":["Compile-Link"],"content":"packager 打包的意义何在 简单来看，clang-offload-packager 或者 fatbinary 就是在原有的 ELF 数据基础上添加了部分额外信息然后封装为了特定的结构化数据，然后将此数据装填到 host object 中。 至于为什么一定要经过这样一个打包的步骤，按照目前理解，可能目的是为 device object 添加额外信息后，后续的处理程序便于定位 device object 中不同部分的数据（正确的理解视角应当是 device object 中包含多种类型的数据，直接装载多种 device object 的 ELF 数据到 host object 中后续过程无法定位要所需要的数据，所以为不同数据添加上相关信息再嵌入到 host object 中）。 ","date":"2024-06-07","objectID":"/blog/posts/compile-link/heterogeneous-compilation/:2:0","tags":null,"title":"Heterogeneous Compilation","uri":"/blog/posts/compile-link/heterogeneous-compilation/"},{"categories":["Compile-Link"],"content":"对于现有工具的理解 无论有哪些工具，所需要做的核心工作就三点： 生成类 fatbinary（关于 fatbinary 这个词的理解似乎不同场景有所不同，有些认为是 device code 相关内容的结合结果是 fatbinary，有些认为是 device object 嵌入 host object 之后的结果是 fatbinary，但是 wikipedia 给出的 fatbinary 这个概念本身对应后者，这里暂时不纠结用词，理解这个意思即可） 代码嵌入 链接 Prerequisite explanation: the following content references to the [Clang] Introduce clang-offload-packager tool to bundle device files 现在的工具情况是： clang-offload-packager clang-offload-packager 实现的作用类似与 CUDA 的 fatbinary 工具类似，it creates a binary that can then be embedded into the host. clang-offload-bundler The clang-offload-bundler is to embed device files into the host. Now the tool chain does this directly in clang by creating a global string in the LLVM-IR of the host rather than calling this tool. But HIP toolchain still uses the clang-offload-bundler. clang-offload-bundler 似乎还有一些特殊的用途: There is still functionality that the clang-offload-bundler provides that I don’t intend to replace, namely the bundling and un-bundling of text files. clang-offload-bundler 似乎还有一个问题: I don’t think we want to stick with the clang-offload-bundler approach, because the files that the –clang-offload-bundler spat out weren’t valid input to the rest of LLVM, e.g. clang -S -emit-llvm –offload-arch=gfx908 foo.hip -o - | opt would break. clang-offload-bundler 的作用似乎比较混乱，按照目前理解它应当是既具备生成类 fatbinary 的作用，同时也具备代码嵌入的作用（这个从 --help 信息中无法验证，还需要实际测试一下）。LLVM-project 可能是为了实现功能细化，单独创造了一个clang-offload-packager工具用于生成类 fatbinary，同时因为上述提到的 bundler 作为一个独立工具所具备的问题，因此把代码嵌入的工具集成到 clang 中来实现。当然这只是预期的效果，如以下内容所示目前有一个问题就是在 HIP toolchain 中，仍然使用着 clang-offload-bundler 生成类 fatbinary 的功能，如果想要实现 bundler 和 HIP toolchain 之间的解耦，需要修改 HIP runtime，这并不是段时间内能够解决的问题，所以这些工具目前仍然保留了下来。 For HIP toolchain, clang-offload-bundler is also used to generate fatbinary files which can be loaded dynamically at run time through module API’s. So far I don’t think this can be replaced by clang-offload-packager in a short time, since it needs HIP runtime change. 所以按照我的理解，packager 可以看为 bundler 的一个子集，最终期望实现的工具结合方式应该就是 clang-offload-packager + clang. 前者负责 device object 打包，后者负责将 device object 嵌入 host object. clang-linker-wrapper (由clang-offload-wrapper合并而来) ","date":"2024-06-07","objectID":"/blog/posts/compile-link/heterogeneous-compilation/:3:0","tags":null,"title":"Heterogeneous Compilation","uri":"/blog/posts/compile-link/heterogeneous-compilation/"},{"categories":["Compile-Link"],"content":"clang-offload-packager 源代码位于 llvm-project/clang/tools/clang-offload-packager/ClangOffloadPackager.cpp 源代码中涉及到一个数据类型 OffloadBinary 文档中给出这样一句话： We use this format to embed the offloading image into the host executable so it can be extracted and used by the linker. 也就是说假设我们希望向 clang 中添加对于其他数据的支持，核心依据只是要和 linker 的工作对应即可，让 linker 能够正确解析出来数据从而完成链接工作。 ","date":"2024-06-07","objectID":"/blog/posts/compile-link/heterogeneous-compilation/:4:0","tags":null,"title":"Heterogeneous Compilation","uri":"/blog/posts/compile-link/heterogeneous-compilation/"},{"categories":["HPC"],"content":"We can reference this article About the last method that using rdtsc assembly command to obtain time, there are some error prone points, we can reference to this article. If you want to learn about the TST, please reference to this article. ","date":"2024-06-04","objectID":"/blog/posts/hpc/several-methods-for-obtaining-time/:0:0","tags":null,"title":"Several Methods For Obtaining Time","uri":"/blog/posts/hpc/several-methods-for-obtaining-time/"},{"categories":["HPC"],"content":"说明 SIMD Extension 的各种函数中参数的顺序以及各种函数的实现机制都是遵循着机器在实际存储时采用的小端序，注意在和数组混用时可能会产生一定思维上的混乱。 ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:1:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Categories Hot to check the SIME extension support of cpu ? cat /proc/cpuinfo For x86 instruction set MMX SSE (Streaming SIMD extensions) AVX (Advanced Vector Extensions) AVX2 AVX512 etc For ARM instruction set NEON AVX ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:2:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Usage of SIMD intrinsic ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:3:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"header file If you don’t know which header file to include, please find the function you want to call in Intel Intrinsics Guide，when you launch the detail of function, you will find the header file you need to include. \u003cmmintrin.h\u003e MMX \u003cxmmintrin.h\u003e SSE \u003cemmintrin.h\u003e SSE2 \u003cpmmintrin.h\u003e SSE3 \u003ctmmintrin.h\u003e SSSE3 \u003csmmintrin.h\u003e SSE4.1 \u003cnmmintrin.h\u003e SSE4.2 \u003cammintrin.h\u003e SSE4A \u003cwmmintrin.h\u003e AES \u003cimmintrin.h\u003e AVX, AVX2, FMA But there is a saying that These days you should normally just include \u003cimmintrin.h\u003e. It includes everything. 1 After actual testing(use SSE2 but include the \u003cimmintrin.h\u003e), this statement has no problem. ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:3:1","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"compile option -mmmx -msse -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -msse4 -mavx -mavx2 You can search more compile options in gnu Option Summary | x86 Options. ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:3:2","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Data load and store The quantity of load and store function is limited. Taking functions for handling float date types as an example, there are only 4 most commonly used functions for loading and storing: __m256d _mm256_load_pd (double const * mem_addr) __m256d _mm256_loadu_pd (double const * mem_addr) void _mm256_store_pd (double * mem_addr, __m256d a) void _mm256_storeu_pd (double * mem_addr, __m256d a) What we need to pay attention to is that what are the judgement strategy differences between aligned data and non aligned data when these functions executing. About the knowledge of data align, you can reference this article, we will not talk it repeatly here. Before we give the right answer of this question, we can see some code snippets This is a plain version of $ x = a \\times x $ implementation. void sapxy(int n, float a, float *x) { int i; for (i=0; i\u003cn; i++) { x[i] = x[i] * a; } } We can use SIMD extension to optimize the above code. If we use the first line sse_sapxy function call, we will get “Segmentation fault (core dumped)”. If we use the second line code, we will get the right result. If we use the third line code, we will get the wrong result but we will not get the “Segmentation fault (core dumped)”. void sse_sapxy(int n, float a, float *x) { float aa[4]; aa[0] = aa[1] = aa[2] = aa[3] = a; __m128 v_a = _mm_load_ps(aa); int i; for (i = 0; i \u003c n / 4 * 4; i += 4) { __m128 v_x = _mm_load_ps(x + i); v_x = _mm_mul_ps(v_x, v_a); _mm_store_ps(x + i, v_x); } for (; i \u003c n; i++) { x[i] = x[i] * a; } } float a[1000000]; int main() { for (int i = 0; i \u003c 1000000; i++) { a[i] = i * 1.0; } sse_sapxy(999999, 3.14159, a + 1); // sse_sapxy(1000000, 3.14159, a); // sse_sapxy(999996, 3.14159, a + 4); } Now, let’s see the right implementation of SIMD extension optimize version code void sse_sapxy_unaligned_load(int n, float a, float *x) { float aa[4]; aa[0] = aa[1] = aa[2] = aa[3] = a; __m128 v_a = _mm_loadu_ps(aa); int i; if (((unsigned long long)x % 16) == 0) { // check if memory is aligned. for (i = 0; i \u003c n / 4 * 4; i += 4) { __m128 v_x = _mm_load_ps(x + i); v_x = _mm_mul_ps(v_x, v_a); _mm_store_ps(x + i, v_x); } } else { for (i = 0; i \u003c n / 4 * 4; i += 4) { __m128 v_i = _mm_loadu_ps(x + i); __m128 v_o = _mm_mul_ps(v_i, v_a); _mm_storeu_ps(x + i, v_o); } } for ( ; i \u003c n; i++) x[i] = a * x[i]; } Why we get the above result, the reason is that b and b + 4 is satisfied with the data aligned requirement of _mm_load_ps and _mm_store_ps, but b + 1 isn’t satisfied with it, so we should use right load and store function for one data. simd extension 提供给用户的就是这么一条指令，但是在底层执行时，如果是确定地址对齐的数据，在load时只需要进行一次内存访问，就可以将所有数据加载到 vector register 中了。 但是如果地址不对齐的数据，这部分数据是可能跨越memory page 的，那么底层在执行时，对于这部分数据的访问就可能需要多次内存访问，最终需要将多次内存访问读取到的数据都合并到一个 vector register 中，合并数据是需要额外的操作逻辑的，所以这里又提供了一个新的函数单独做非对齐数据的加载。 实际上，从一个库的实现角度来说，这里有两种实现思路，一种是封装层次更高的，即只给上层用户提供一个简单的load函数，由函数实现本身来区分数据是否对齐，另一种就是目前的由用户来显式指定，之所以采用后者，我觉得可能是因为这些函数本身就是比较底层的概念了，没必要实现太高层次的封装，级别更高层次的封装往往都是框架来做的。 At last, we can see a further optimized version, when judge the aligned data, this code uses the pointer directly, save the data copy time from memory to vector register. void sse_sapxy_unaligned(int n, float a, float *x) { float aa[4]; aa[0] = aa[1] = aa[2] = aa[3] = a; __m128 v_a = _mm_loadu_ps(aa); int i; if (((unsigned long long)x % 16) == 0) { // check if memory is aligned. __m128 *p = (__m128 *)x; for (i = 0; i \u003c n / 4 * 4; i += 4) { *p = _mm_mul_ps(*p, v_a); p++; } } else { for (i = 0; i \u003c n / 4 * 4; i += 4) { __m128 v_i = _mm_loadu_ps(x + i); __m128 v_o = _mm_mul_ps(v_i, v_a); _mm_storeu_ps(x+i, v_o); } } for ( ; i \u003c n; i++) x[i] = a * x[i]; } ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:4:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Data process ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Vector Addition // compile with -mavx #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a[] = {1.0 , 2.0, 3.0, 4.0}; double b[] = {4.0, 3.0, 2.0, 1.0}; double dst[4]; __m256d va = _mm256_loadu_pd(a); __m256d vb = _mm256_loadu_pd(b); __m256d vdst = _mm256_add_pd(va, vb); _mm256_storeu_pd(dst, vdst); for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c dst[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:1","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Horizontal Addition The effect of this function is confusing, because it store the two array’s adjacent data sum crossly. I can not image the usage in realistic scenes. #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a[] = {1.0, 1.0, 2.0, 2.0}; double b[] = {3.0, 3.0, 4.0, 4.0}; double hsum[4]; __m256d va = _mm256_loadu_pd(a); __m256d vb = _mm256_loadu_pd(b); __m256d vhsum = _mm256_hadd_pd(va, vb); _mm256_storeu_pd(hsum, vhsum); for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c hsum[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } The result of the above code is 2 6 4 8 ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:2","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Compare __m256d _mm256_cmp_pd (__m256d a, __m256d b, const int imm8) According to the third parameter to compare the data from first and second vector, and output the result to a __m256d vector. The third parameter value and its corresponding meaning are shown in the table below. imm8[4:0] 操作符 含义 0 _CMP_EQ_OQ 比较两个操作数是否相等（Ordered, Quiet） 1 _CMP_LT_OS 比较第一个操作数是否小于第二个操作数（Ordered, Signaling） 2 _CMP_LE_OS 比较第一个操作数是否小于等于第二个操作数（Ordered, Signaling） 3 _CMP_UNORD_Q 比较两个操作数是否未排序（Unordered, Quiet） 4 _CMP_NEQ_UQ 比较两个操作数是否不相等（Unordered, Quiet） 5 _CMP_NLT_US 比较第一个操作数是否不小于第二个操作数（Unordered, Signaling） 6 _CMP_NLE_US 比较第一个操作数是否不小于等于第二个操作数（Unordered, Signaling） 7 _CMP_ORD_Q 比较两个操作数是否有序（Ordered, Quiet） 8 _CMP_EQ_UQ 比较两个操作数是否相等（Unordered, Quiet） 9 _CMP_NGE_US 比较第一个操作数是否不大于等于第二个操作数（Unordered, Signaling） 10 _CMP_NGT_US 比较第一个操作数是否不大于第二个操作数（Unordered, Signaling） 11 _CMP_FALSE_OQ 始终返回假（Ordered, Quiet） 12 _CMP_NEQ_OQ 比较两个操作数是否不相等（Ordered, Quiet） 13 _CMP_GE_OS 比较第一个操作数是否大于等于第二个操作数（Ordered, Signaling） 14 _CMP_GT_OS 比较第一个操作数是否大于第二个操作数（Ordered, Signaling） 15 _CMP_TRUE_UQ 始终返回真（Unordered, Quiet） 16 _CMP_EQ_OS 比较两个操作数是否相等（Ordered, Signaling） 17 _CMP_LT_OQ 比较第一个操作数是否小于第二个操作数（Ordered, Quiet） 18 _CMP_LE_OQ 比较第一个操作数是否小于等于第二个操作数（Ordered, Quiet） 19 _CMP_UNORD_S 比较两个操作数是否未排序（Unordered, Signaling） 20 _CMP_NEQ_US 比较两个操作数是否不相等（Unordered, Signaling） 21 _CMP_NLT_UQ 比较第一个操作数是否不小于第二个操作数（Unordered, Quiet） 22 _CMP_NLE_UQ 比较第一个操作数是否不小于等于第二个操作数（Unordered, Quiet） 23 _CMP_ORD_S 比较两个操作数是否有序（Ordered, Signaling） 24 _CMP_EQ_US 比较两个操作数是否相等（Unordered, Signaling） 25 _CMP_NGE_UQ 比较第一个操作数是否不大于等于第二个操作数（Unordered, Quiet） 26 _CMP_NGT_UQ 比较第一个操作数是否不大于第二个操作数（Unordered, Quiet） 27 _CMP_FALSE_OS 始终返回假（Ordered, Signaling） 28 _CMP_NEQ_OS 比较两个操作数是否不相等（Ordered, Signaling） 29 _CMP_GE_OQ 比较第一个操作数是否大于等于第二个操作数（Ordered, Quiet） 30 _CMP_GT_OQ 比较第一个操作数是否大于第二个操作数（Ordered, Quiet） 31 _CMP_TRUE_US 始终返回真（Unordered, Signaling） ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:3","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"set __m256d _mm256_set_pd (double e3, double e2, double e1, double e0) This funciont doesn’t have any special effect, it just set value for a vector register. What we need to pay attention to is that the order of the parameters of this function. The order of this function follows the real store order of machine, i.e. little-endian（小端序，低有效字节存储在低位，最右侧的位置就是低有效字节以及低位，所以所这种布局遵循了机器的小端序） ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:4","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"insert insert a __m128d vector data into __m256d vector data. #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a[] = {1.0 , 2.0, 3.0, 4.0}; double b[2] = {5.0, 6.0}; double dst0[4], dst1[4]; __m256d va = _mm256_loadu_pd(a); __m128d vb = _mm_loadu_pd(b); __m256d vdst0 = _mm256_insertf128_pd(va, vb, 0); __m256d vdst1 = _mm256_insertf128_pd(va, vb, 1); _mm256_storeu_pd(dst0, vdst0); _mm256_storeu_pd(dst1, vdst1); std::cout \u003c\u003c \"dst0: \"; for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c dst0[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; std::cout \u003c\u003c \"dst1: \"; for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c dst1[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } The result of the above program is that dst0: 5 6 3 4 dst1: 1 2 5 6 ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:5:5","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Permute __m256d _mm256_permute4x64_pd (__m256d a, const int imm8) According to the imm8 to select the data in a and put it into a __m256d vector register. What we should pay attention to is that imm8 is a hexadecimal data, for example, if we want to express 11111111, we should use the 0xFF. #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a[] = {1.0 , 2.0, 3.0, 4.0}; double dst[4]; __m256d va = _mm256_loadu_pd(a); __m256d vdst = _mm256_permute4x64_pd(va, 0xE4); _mm256_storeu_pd(dst, vdst); for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c dst[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } 0xE4 is 11100100, i.e. it corresponding to the order of array a. So the result is 1 2 3 4 ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:6:0","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"blend Traverse the imm from the LSB to HSB, if the bit value is 1, select b data and put it into the result vector resigter, other wise select a data. #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a[] = {1.0 , 2.0, 3.0, 4.0}; double b[] = {5.0, 6.0, 7.0, 8.0}; double dst[4]; __m256d va = _mm256_loadu_pd(a); __m256d vb = _mm256_loadu_pd(b); __m256d vdst = _mm256_blend_pd(va, vb, 0xA); // 0xA: 1010 _mm256_storeu_pd(dst, vdst); for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c dst[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } 1010 is mapping to the baba, so when we output the dst data from low byte to high byte, we will get the “a b a b”, i.e. the result of this program is “1 6 3 8”. ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:6:1","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"broadcast #include \u003cimmintrin.h\u003e #include \u003ciostream\u003e int main() { double a2[] = {1.0, 2.0}; double a4[4]; __m128d va2 = _mm_loadu_pd(a2); __m256d va4 = _mm256_broadcast_pd(\u0026va2); _mm256_storeu_pd(a4, va4); for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c a4[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } The result is 1 2 1 2 Header files for x86 SIMD intrinsics ↩︎ ","date":"2024-06-03","objectID":"/blog/posts/hpc/simd-extension/:6:2","tags":null,"title":"SIMD Extension","uri":"/blog/posts/hpc/simd-extension/"},{"categories":["HPC"],"content":"Check the OpenMP version #include \u003cstdio.h\u003e int main() { #ifdef _OPENMP printf(\"OpenMP version: %d\\n\", _OPENMP); #else printf(\"OpenMP is not supported.\\n\"); #endif return 0; } If system supports the OpenMP, you will receive similar output results OpenMP version: 201511 “201511” means that this OpenMP is released in November 2015. Next, you need to go to this official website to search the edition and the released time, you will find that OpenMP 4.5 is released in November 2015. ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:1:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Key concept in OpenMP construct（构造） construct = pragma + structural block region（区域） region = the code in structural block The end of the region has a implicit barrier, i.e. every thread has finished the executation of the code in the construct clause（子句） clause = behavior that defines or edits the construct ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:2:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Understand the pragma1 This command is the most important element for OpenMP. On the one hand, it’s called 编译制导指令，because these commands instruct the compiler to execute some particular operations when compiling. On the other hand, it’s like to the #define command, which is called 预处理指令(Preprocessor Directive). ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:3:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Discriminate parallel and for #include \u003ciostream\u003e #include \u003comp.h\u003e int main() { omp_set_num_threads(2); #pragma omp parallel { for (int i = 0; i \u003c 3; i++) { int thread_id = omp_get_thread_num(); std::cout \u003c\u003c \"thread_id: \" \u003c\u003c thread_id \u003c\u003c \" , i: \" \u003c\u003c i \u003c\u003c std::endl; } } #pragma omp barrier std::cout \u003c\u003c std::endl; // 等价于 #pragma omp parallel for #pragma omp parallel { #pragma omp for for (int i = 0; i \u003c 10; i++) { int thread_id = omp_get_thread_num(); std::cout \u003c\u003c \"thread_id: \" \u003c\u003c thread_id \u003c\u003c \" , i: \" \u003c\u003c i \u003c\u003c std::endl; } #pragma omp barrier } return 0; } 输出结果为： thread_id: 1 , i: 0 thread_id: 1 , i: 1 thread_id: 1 , i: 2 thread_id: 0 , i: 0 thread_id: 0 , i: 1 thread_id: 0 , i: 2 thread_id: 0 , i: 0 thread_id: 0 , i: 1 thread_id: 0 , i: 2 thread_id: 0 , i: 3 thread_id: 0 , i: 4 thread_id: 1 , i: 5 thread_id: 1 , i: 6 thread_id: 1 , i: 7 thread_id: 1 , i: 8 thread_id: 1 , i: 9 可见，parallel 中的代码是每个 thread 都会完整执行的，而 for 中的代码会分配给不同 thread 来执行 2 ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:4:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Fallible point 实测发现大括号不能随意添加，下方代码如果为 #pragma omp for ordered 添加一个 大括号，那么执行将报错 “‘ordered’ region must be closely nested inside a loop region with an ‘ordered’ clause“ #pragma omp for ordered for (int i = 0; i \u003c 100; i++) { #pragma omp ordered { sum += thread_id; } } ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:5:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Construct ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:6:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"sections 仅仅使用 #pragma omp parallel 所实现的并行实际是 SIMD，即在 parallel 所指定的 region 下，每个 thread 看到并且指定的代码都是相同的，只不过是通过 thredd id 实现的计算数据的不相同。 而实现并行的方式并不仅仅局限于 SIMD, 还能够通过 MIMD实现。sections 完成的就是这样一项任务，每个 section 下的代码由一个线程负责执行（注意这并不表示执行两个 section 的线程一定不会是同一个，这里实际的执行情况可能要看线程的调度策略），每个 section 下的代码是可以不同的，这也就能够实现 MIMD 了。 上述判断可以通过以下程序进行验证 #include \u003cstdio.h\u003e #include \u003comp.h\u003e #include \u003cunistd.h\u003e int main() { #pragma omp parallel { int threadid = omp_get_thread_num(); printf(\"thread %d \\n\", threadid); #pragma omp sections { #pragma omp section { printf(\"section 0 - thread %d\\n\", threadid); sleep(1); } #pragma omp section { printf(\"section 1 - thread %d\\n\", threadid); sleep(1); } #pragma omp section { printf(\"section 2 - thread %d\\n\", threadid); sleep(1); } } } return 0; } ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:6:1","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Synchronization barrier There is an implicit barrier after parallel, for, sections and single, and we can use nowati clause to cancel this implicit barrier, such as #pragma omp for nowait. ordered ordered construct 的一个使用条件就是，要求并行循环使用 ordered clause, 即下方的 #pragma omp for ordered 和 #pragma omp ordered，前者是 clause，后者是 construct. #include \u003cstdio.h\u003e #include \u003comp.h\u003e int main() { #pragma omp parallel for ordered for (int i = 0; i \u003c 10; ++i) { // Some parallel work int tid = omp_get_thread_num(); #pragma omp ordered { printf(\"Thread %d processed iteration %d\\n\", tid, i); } } return 0; } 以上程序中，循环将会顺序执行 int sum_serial = 0; #pragma omp parallel num_threads(100) { int thread_id = omp_get_thread_num(); #pragma omp for ordered for (int i = 0; i \u003c 100; i++) { #pragma omp ordered { sum_serial += thread_id; } } } std::cout \u003c\u003c sum_serial \u003c\u003c std::endl; int sum_parallel = 0; #pragma omp parallel num_threads(100) { int thread_id = omp_get_thread_num(); #pragma omp for for (int i = 0; i \u003c 100; i++) { sum_parallel += thread_id; } } std::cout \u003c\u003c sum_parallel \u003c\u003c std::endl; 需要实现的场景是，在一个大的 parallel region 中，我们希望有一小段代码是串行执行的，即严格遵循线程编号依次执行。通过 递增计数器 和 锁 可以简单实现这一点。 上方代码给了两种实现，理论上第2种实现可能出现多个 thread 同时修改 sum_parallel 变量从而导致结果出现错误，第一种实现从测试来看确实是正确的，不过令人困惑的是 #pragma omp for ordered 和 #pragma omp ordered 两个重复的 ordered。 critical critical 用于保护代码段，使得该代码段在任何时候都只能由一个线程执行，从而避免数据竞争, 当一个线程在执行 critical 指定的 region 时，其他要执行同样 region 的线程必须等待。 #include \u003cstdio.h\u003e #include \u003comp.h\u003e int main() { int sum = 0; #pragma omp parallel for for (int i = 0; i \u003c 10; ++i) { #pragma omp critical { sum += i; printf(\"Thread %d added %d, sum now is %d\\n\", omp_get_thread_num(), i, sum); } } printf(\"Final sum is %d\\n\", sum); return 0; } atomic #include \u003cstdio.h\u003e #include \u003comp.h\u003e int main() { int sum = 0; #pragma omp parallel for for (int i = 0; i \u003c 10; ++i) { #pragma omp atomic sum += i; // Note: printf is not atomic, so the output may still be interleaved printf(\"Thread %d added %d, sum now is %d\\n\", omp_get_thread_num(), i, sum); } printf(\"Final sum is %d\\n\", sum); return 0; } The logic of this program is same as the example of critical construct program. ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:6:2","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"task task 的常用执行逻辑是，由 1 个线程负责创建 task，然后每个线程会负责一个 task，具体每个线程执行哪一个 task 取决于实际场景下的调度策略。 这种 construct 类似创建了一个 task pool，thread 就是计算资源，从 task pool 中选择 task 来执行。 需要注意的是，实际测试结果显示，最初创建 task 的线程，最后也是有可能会去执行某一项 task 的 #include \u003cstdio.h\u003e #include \u003comp.h\u003e int main() { #pragma omp parallel { #pragma omp single { printf(\"Thread %d: Creating tasks\\n\", omp_get_thread_num()); #pragma omp task { printf(\"Thread %d: Executing task 1\\n\", omp_get_thread_num()); } #pragma omp task { printf(\"Thread %d: Executing task 2\\n\", omp_get_thread_num()); } } } return 0; } When we specify the thread num is 4, the result of above program is Thread 0: Creating tasks Thread 2: Executing task 1 Thread 3: Executing task 2 ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:6:3","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Clause ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:7:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Data Storage Property shared: different threads share the same data private: different threads have they own data replica firstprivate() lastprivate() Hot to handle array ? We can use array split grammar, for example [lower bound : length : stride] [lower bound : length] [: length : stride] (To be honest, I am puzzled about this which doesn’t specify the begin position) #pragma omp parallel firstprivate(vptr[0 : 1000 : 1]) ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:7:1","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":"Reference 编译制导指令 ↩︎ OpenMP并行编程笔记 ↩︎ ","date":"2024-04-30","objectID":"/blog/posts/hpc/openmp/:8:0","tags":null,"title":"OpenMP","uri":"/blog/posts/hpc/openmp/"},{"categories":["HPC"],"content":" GEMM（General Matrix Multiplication）-通用矩阵乘 BLAS (Basic Linear Algebra Subprograms) - 基本线性代数子程序 SGEMM (Single precision General Matrix Multiply) - 单精度矩阵乘法 DGEMM (Double precision General Matrix Multiply) - 双精度矩阵乘法 CGEMM (Complex single precision General Matrix Multiply) - 单精度复数矩阵乘法 ZGEMM (Complex double precision General Matrix Multiply) - 双精度复数矩阵乘法 涉及到稀疏矩阵1的缩写 CSR (Compressed Sparse Row) - 压缩稀疏行2 CSC (Compressed Sparse Column) - 压缩稀疏列 COO (Coordinate Format, also known as “ijv” or “triplet”) - 坐标格式 BSR (Block Compressed Sparse Row) - 块压缩稀疏行 ELL (Ellpack/Itpack format) - ELL压缩格式 DIA (Diagonal storage format) - 对角线存储格式 DOK (Dictionary of Keys) - 键字典格式 SPMV (Sparse Matrix-Vector multiplication) - 稀疏矩阵-向量乘法。这是指稀疏矩阵与密集向量的乘法运算。 SPMM (Sparse Matrix-Matrix multiplication) - 稀疏矩阵-矩阵乘法。这是指稀疏矩阵与稠密矩阵之间的乘法运算。 SPGEMM (Sparse General Matrix-Matrix multiplication)：稀疏一般矩阵-矩阵乘法 SPMSpv (Sparse Matrix-Sparse Vector multiplication)：稀疏矩阵-稀疏向量乘法 SDDMM (Sparse-Dense-Dense Matrix Multiplication)：稀疏-稠密-稠密矩阵乘法 稀疏矩阵存储格式总结 ↩︎ CSR存储格式 ↩︎ ","date":"2024-04-28","objectID":"/blog/posts/hpc/matrix-multiplication/:0:0","tags":null,"title":"Matrix Multiplication","uri":"/blog/posts/hpc/matrix-multiplication/"},{"categories":["Project-Experience"],"content":"整体理解 从宏观上来讲，调试程序的两大场景： 单程序写完后直接运行调试 大型项目编译完成后，需要结合源码对某一个可执行程序进行执行流分析 实际上这看似是两种，但是底层本质的执行流是相同的，只不过前者被隐藏了一些过程。 整体的过程其实就是 vscode 在 debug 时所提供的两个 配置文件 tasks.json 和 launch.json，其中前者表示编译过程，后者表示程序执行过程 最开始使用IDE，进行的其实始终就是第一种场景，但是不代表程序在没有编译的情况下就直接进入debug状态了（除非是解释形语言），一定是先编译成可执行文件后在进行debug，只不过IDE把编译这个过程给隐藏了 又一次感觉到初学者似乎不应该直接使用 IDE，IDE 把很多程序执行的关键过程都给隐藏掉了，搞得最后没有IDE都不知道这个程序该怎么跑起来，不过也可能是考虑到编译链接这些东西需要涉及到操作系统等其他方面的知识，让初学者太早接触可能会陷入过多的细节当中，使用 IDE 确实是可以让初学者只需要考虑语言本身，尽可能地隐藏掉一些底层细节 实际无论是哪种情况，debug 我们都可以直接通过命令行，利用 gdb 或 lldb 来实现，不过需要输入命令不太方便，所以考虑使用 vscode 的用户界面作为 gdb 和 lldb 的接口，而由于 vscode 只是个简单的文本编辑器，想让它对接 gdb 和 lldb，需要通过插件来实现对接（如果要要使用 lldb，需要安装 CodeLLDB 插件,官方的C/C++插件并不支持 lldb，会报错\"The debug type is not recognized. Make sure that you have a corresponding debug extension installed and that it is enabled.\"） The debug type is not recognized. Make sure that you have a corresponding debug extension installed and that it is enabled. 一旦对接上之后，只需要配置好 launch.json 就可以 debug 编译完成后的项目中的可执行文件了，而 launch.json 要编写的关键就是可执行程序的路径以及参数 ","date":"2024-04-18","objectID":"/blog/posts/project-experience/debugging-in-visual-studio-code/:1:0","tags":null,"title":"Debugging in Visual Studio Code","uri":"/blog/posts/project-experience/debugging-in-visual-studio-code/"},{"categories":["Project-Experience"],"content":"debugging process 采用 debug 选项进行编译 安装 vscode debug 所需要的插件 编写 launch.json，指明所需调试的程序以及需要的参数 ","date":"2024-04-18","objectID":"/blog/posts/project-experience/debugging-in-visual-studio-code/:2:0","tags":null,"title":"Debugging in Visual Studio Code","uri":"/blog/posts/project-experience/debugging-in-visual-studio-code/"},{"categories":["Project-Experience"],"content":"编译前 如果直接使用编译器进行编译，那么必须携带 debug 编译选项 如果使用 cmake 进行编译，那么需要添加 -DCMAKE_BUILD_TYPE=Debug（对应的是 -DCMAKE_BUILD_TYPE=Release） ","date":"2024-04-18","objectID":"/blog/posts/project-experience/debugging-in-visual-studio-code/:3:0","tags":null,"title":"Debugging in Visual Studio Code","uri":"/blog/posts/project-experience/debugging-in-visual-studio-code/"},{"categories":["Project-Experience"],"content":"编译后如何查看文件是否含有 debug 信息 通过 file 命令 如果是携带 debug 选项编译出来的可执行程序，会携带 with debug_info 选项 通过 readelf 命令 readelf -a \u003cfile name\u003e |grep debug 如果携带 debug 选项编译出来的可执行程序，以上代码会输出以下类似信息 [27] .debug_info PROGBITS 0000000000000000 00003165 [28] .debug_abbrev PROGBITS 0000000000000000 0000680a [29] .debug_line PROGBITS 0000000000000000 00006e81 [30] .debug_str PROGBITS 0000000000000000 0000728d [31] .debug_addr PROGBITS 0000000000000000 0000c533 [32] .debug_rnglists PROGBITS 0000000000000000 0000c5f3 [33] .debug_str_offset PROGBITS 0000000000000000 0000c62f [34] .debug_line_str PROGBITS 0000000000000000 0000d0e3 ","date":"2024-04-18","objectID":"/blog/posts/project-experience/debugging-in-visual-studio-code/:4:0","tags":null,"title":"Debugging in Visual Studio Code","uri":"/blog/posts/project-experience/debugging-in-visual-studio-code/"},{"categories":["Project-Experience"],"content":"常见 debug 模式 此配置项在 vscode 的 launch.json 中对应 request 字段。 Launch 模式：配置调试器启动程序，与在命令行中执行一样。可以指定程序的执行路径、命令行参数、环境变量等，并且在程序开始执行时立即开始调试。这种模式适用于想要从头开始调试整个程序的情况，或者当程序是一个独立的可执行文件时。 Attach 模式：连接到已经在运行的进程进行调试。不需要启动程序，而是等待程序运行到一定的地方，然后通过调试器连接到该进程。这种模式适用于想要在程序已经运行一段时间之后进行调试，或者当程序是一个服务器或其他类型的长时间运行的进程时。 ","date":"2024-04-18","objectID":"/blog/posts/project-experience/debugging-in-visual-studio-code/:5:0","tags":null,"title":"Debugging in Visual Studio Code","uri":"/blog/posts/project-experience/debugging-in-visual-studio-code/"},{"categories":["C-C++"],"content":"谈及多态主要是在考虑具有继承关系的多个类型之间的关系。考虑多态的核心在于引用或指针的 静态类型 与 动态类型 是可能不同的 静态多态 和 动态多态 的一个明显的区别是 是 编译时 还是 运行时 解析调用 ","date":"2024-04-15","objectID":"/blog/posts/c-c++/polymorphism/:0:0","tags":null,"title":"Polymorphism","uri":"/blog/posts/c-c++/polymorphism/"},{"categories":["C-C++"],"content":"static polymorphism CRTP 是 Curiously Recurring Template Pattern 的缩写，中文翻译为“奇特的递归模板模式”。它是一种 C++ 编程技术，通常用于实现静态多态性，即在编译期间确定调用的函数。 CRTP 的基本思想是，基类模板派生出一个子类，并将子类作为模板参数传递给基类模板。子类可以通过继承基类模板，并传递自身类型作为模板参数，从而在编译期间实现基类和子类之间的静态多态性。 下面是一个简单的示例来说明 CRTP 的使用方式： template \u003ctypename Derived\u003e class Base { public: void interface() { // 调用派生类的实现 static_cast\u003cDerived*\u003e(this)-\u003eimplementation(); } // 基类提供的默认实现 void implementation() { // 默认实现 } }; class Derived1 : public Base\u003cDerived1\u003e { public: void implementation() { // 派生类自定义的实现 } }; class Derived2 : public Base\u003cDerived2\u003e { // Derived2没有实现 implementation 函数，将使用基类提供的默认实现 }; int main() { Derived1 d1; Derived2 d2; d1.interface(); // 调用 Derived1 的实现 d2.interface(); // 调用 Derived2 的默认实现 return 0; } ","date":"2024-04-15","objectID":"/blog/posts/c-c++/polymorphism/:1:0","tags":null,"title":"Polymorphism","uri":"/blog/posts/c-c++/polymorphism/"},{"categories":["C-C++"],"content":"dynamic polymorphism 动态多态性是面向对象编程中的一个重要概念，通常通过虚函数和基类指针（或引用）实现。下面是一个简单的示例 #include \u003ciostream\u003e // 基类 class Base { public: // 虚函数 virtual void display() { std::cout \u003c\u003c \"Base::display()\" \u003c\u003c std::endl; } }; // 派生类1 class Derived1 : public Base { public: // 覆盖基类虚函数 void display() override { std::cout \u003c\u003c \"Derived1::display()\" \u003c\u003c std::endl; } }; // 派生类2 class Derived2 : public Base { public: // 覆盖基类虚函数 void display() override { std::cout \u003c\u003c \"Derived2::display()\" \u003c\u003c std::endl; } }; int main() { // 创建基类指针，并指向派生类对象 Base* ptr1 = new Derived1(); Base* ptr2 = new Derived2(); // 调用虚函数，实现动态多态 ptr1-\u003edisplay(); // 输出 Derived1::display() ptr2-\u003edisplay(); // 输出 Derived2::display() // 释放内存 delete ptr1; delete ptr2; return 0; } ","date":"2024-04-15","objectID":"/blog/posts/c-c++/polymorphism/:2:0","tags":null,"title":"Polymorphism","uri":"/blog/posts/c-c++/polymorphism/"},{"categories":["C-C++"],"content":"两种多态方式辨析 静态多态是通过编译期间的类型信息来决定调用哪个函数，通常是通过模板或函数重载来实现。在静态多态中，函数的重载解析发生在编译时期，因此调用的函数在编译时期就已经确定。 动态多态是通过运行时的类型信息来决定调用哪个函数，通常是通过虚函数来实现。在动态多态中，函数的解析发生在运行时期，通过基类指针或引用调用虚函数时，实际调用的函数在运行时期根据对象的类型动态确定。 ","date":"2024-04-15","objectID":"/blog/posts/c-c++/polymorphism/:3:0","tags":null,"title":"Polymorphism","uri":"/blog/posts/c-c++/polymorphism/"},{"categories":["Linux"],"content":"In Linux, sometimes we will face to a software which has many editions, such as gcc and java. In different scenes, maybe we need different editions of the same software, so we must save all of them. But how can we switch them? Linux uses the symlink to allow user easily switching between programs. Then, we use the gcc as an example to illustrate the principle of software version control. Hypothetically speaking, the test mechine has two gcc, gcc-9 and gcc-11. ","date":"2024-04-08","objectID":"/blog/posts/linux/principle-of-software-version-control-in-linux/:0:0","tags":null,"title":"principle of software version control in Linux","uri":"/blog/posts/linux/principle-of-software-version-control-in-linux/"},{"categories":["Linux"],"content":"Where is the gcc ? There are only one directory is related to the execution of gcc, it is /usr/bin/ In /usr/bin, we will find the following contents which are related to the gcc: gcc -\u003e gcc-11 gcc-11 -\u003e x86_64-linux-gnu-gcc-11 x86_64-linux-gnu-gcc-11 gcc-9 -\u003e x86_64-linux-gnu-gcc-9 x86_64-linux-gnu-gcc-9 We can find that only the x86_64-linux-gnu-gcc-9 and x86_64-linux-gnu-gcc-11 is the true executable file. The other files are all the symlinks. Acording to the file structure, we can know that the key factor which influences the software edition we use is the gcc symlink. If we can change the target which is pointed by it, we can switch the different editions. ","date":"2024-04-08","objectID":"/blog/posts/linux/principle-of-software-version-control-in-linux/:1:0","tags":null,"title":"principle of software version control in Linux","uri":"/blog/posts/linux/principle-of-software-version-control-in-linux/"},{"categories":["Linux"],"content":"The design idea of update-alternatives According to the above discussion, if we are the author of update-alternatives command line tools, what we need to do is just edit the gcc symlink directivity. update-alternatives lets the /usr/bin/gcc point to a symlink /etc/alternatives/gcc(at the beginning, the /usr/bin/gcc points to the /usr/bin/gcc-9 or /usr/bin/gcc-11 directly, which is created by this tool. And /etc/alternatives/gcc is also a symlink which points to the /usr/bin/gcc-9 or /usr/bin/gcc-11. When we want to use the gcc-9, /etc/alternatives/gcc will points to the /usr/bin/gcc-9, or else it will points to the /usr/bin/gcc-11. It means that update-alternatives can just edit the directivity of the /etc/alternatives/gcc to edit the edition of software. The hole flow looks like the following picture: ","date":"2024-04-08","objectID":"/blog/posts/linux/principle-of-software-version-control-in-linux/:2:0","tags":null,"title":"principle of software version control in Linux","uri":"/blog/posts/linux/principle-of-software-version-control-in-linux/"},{"categories":["Linux"],"content":"The usage method of update-alternatives The key point is to understand the relationship between the symlinks. We can get the usage method from help option: –install is the symlink pointing to /etc/alternatives/. is the master name for this link group. is the location of one of the alternative target files. is an integer; options with higher numbers have higher priority in automatic mode. The relationship between link, name and path looks like the following pictures: So the following command is an example: update-alternatives /usr/bin/gcc gcc /usr/bin/gcc-9 1 update-alternatives /usr/bin/gcc gcc /usr/bin/gcc-11 1 We can use update-alternatives --list gcc to inspect the config result, we will get the following info: /usr/bin/gcc-11 /usr/bin/gcc-9 And we can use update-alternatives --config gcc to chose an edition of gcc, it looks like ","date":"2024-04-08","objectID":"/blog/posts/linux/principle-of-software-version-control-in-linux/:3:0","tags":null,"title":"principle of software version control in Linux","uri":"/blog/posts/linux/principle-of-software-version-control-in-linux/"},{"categories":["HPC"],"content":"内存的编址单位是字节 但是内存 IO 的单位是字长，此数值应当和 数据通路 的宽度有关，当数据通路为 32 位时，那么一次内存 IO 就会读取4B数据1 对于上述内容，存在两点需要说明： 为何在编址单位之外还要设计数据读取单位？ 答：以字节为单位进行读取效率太低，这和扇区的设计理念是差不多的 关于内存存取粒度，一个更数学化以及计算机化的表述应当为: 计算机仅会从地址为内存存取粒度的整数倍的位置 进行数据读取 考虑在某种内存存取粒度下，假设并不存在内存对齐机制，那么数据将可以随意存放，但是计算机读取数据对于地址是存在要求的，那么当数据存放并不符合这种要求时，就需要进行一些额外的工作，从而降低性能 以上内容参考自C/C++内存对齐详解 我感觉理解内存对齐的难点实际在于：理解某种对齐机制到底会对访存造成什么影响，为何在这种机制下的访存性能就会更高 只有在了解现有存在的问题后才能想到优化方案 因为无论是 C++11 引入的 alignas specifier 还是 这块有一个从 C++11 发展到 C++17 的发展过程，同时涉及到对 alignas specifier，分布在栈上的struct，new分配的在堆上的struct，new分配的堆数据 这些概念的一个解读 具体内容参见 Cpp17.pdf 的 Chapter 30 使用 new 和 delete 管理超对齐数据 当提到超对齐数据时，就会涉及到同 C/C++内存对齐详解 中提到的 有效对齐值 之间的一个对比，同时有效对齐值的概念又牵扯出 Pragmas关键词 的概念 总结来说，这里涉及到两层知识的扩展，暂时不展开 他们在本质上提出的所谓对齐，从数据上来讲，就是使得 最终整个结构体的大小 或者 分配的内存空间的大小 是 要求对齐量 的整数倍，关于这一点可通过下述示例进行验证： struct XYZ{ double x; double y; double z; }; struct alignas(16) XYZ16{ double x; double y; double z; }; std::cout \u003c\u003c sizeof(XYZ) \u003c\u003c std::endl; // 24 std::cout \u003c\u003c sizeof(XYZ16) \u003c\u003c std::endl; // 32 正如前面所提到的，这个示例也仅仅能够说明内存对齐在数值上的影响，并没有体现出对齐后会对性能产生哪些影响 通过上述分析，其实不难想到，理解为什么要进行内存对齐是很重要的一个点。 其实内存对齐只是表面行为，内在机理在于局部性原理。举一个简单例子 struct A { char x1; double y1; char x2; double y2; char x3; double y3; char x4; double y4; char x5; }; ","date":"2024-03-23","objectID":"/blog/posts/hpc/memory-alignment/:0:0","tags":null,"title":"Memory Alignment","uri":"/blog/posts/hpc/memory-alignment/"},{"categories":["HPC"],"content":"内存对齐 ","date":"2024-03-23","objectID":"/blog/posts/hpc/memory-alignment/:1:0","tags":null,"title":"Memory Alignment","uri":"/blog/posts/hpc/memory-alignment/"},{"categories":["HPC"],"content":"内部对齐 对于上述结构，1B 的 char 变量后面会 padding 7B 的空间，以便和 8B 的 double 对齐 然而通过一种很简单的方式，只需要将结构体中的 char 变量聚集到一起，在内存布局上它们自然也都时相邻的了 调整后的好处在于，读取一个 char 变量时，也会将其他 char变量 一同读入 cache，充分利用局部性，从而减少了访存次数 这种顺序的调整，仅仅是对于结构体进行的内部调整，因此称之为内部对齐 ","date":"2024-03-23","objectID":"/blog/posts/hpc/memory-alignment/:1:1","tags":null,"title":"Memory Alignment","uri":"/blog/posts/hpc/memory-alignment/"},{"categories":["HPC"],"content":"外部对齐 外部对齐需要解决的是跨 cache line 的问题 如果一个结构的大小并非 cache line 的整数倍，那么中间的结构就一定会跨 cache line，那么访问这部分数据就需要发生两次 cache事务，我们可以通过padding，使其变为 cache line 的整数倍，从而避免跨 cache line 的情况发生 可以通过查询 /sys/devices/system/cpu/cpu*/cache/index*/coherency_line_size 文件获取 cache line 的大小 ","date":"2024-03-23","objectID":"/blog/posts/hpc/memory-alignment/:1:2","tags":null,"title":"Memory Alignment","uri":"/blog/posts/hpc/memory-alignment/"},{"categories":["HPC"],"content":"AoS 和 SoA 结构转换性能优化原理 关于对 AoS 和 SoA 结构的理解，首先从它们的全称来看 AoS: Array of Structure, 结构体的数组，意味着数组的元素是结构体类型 SoA: Structure of Array，数组的结构体，意味着结构体的字段是一个个的数组，那么这也就意味着结构体内不应当再嵌套结构体元素了，意味着数组元素的类型就应当是基础数据类型 无论是 AoS结构 还是 SoA结构，通过结构转换来实现性能优化的底层逻辑都是局部性原理，只是 AoS结构 和 SoA结构 局部性原理发挥作用的单位是不同的 AoS结构 局部性原理发挥作用的单位在于整个结构体，如果在实际问题中，需要访问到整个结构体的全部字段，那么更适合采用 AoS结构 如果仅需要访问一个结构体中的部分字段，并且需要频繁切换结构体，那么就更适合采用 SoA结构 采用 AoS结构 还是 SoA结构，取决于实际的访存模式，在特定的访存模式下，采用何种存储结构更能够充分利用局部性那么哪种结构的性能就更优 为什么需要内存对齐 ↩︎ ","date":"2024-03-23","objectID":"/blog/posts/hpc/memory-alignment/:2:0","tags":null,"title":"Memory Alignment","uri":"/blog/posts/hpc/memory-alignment/"},{"categories":["Graph-Computing"],"content":"目前涉及到两个关键的概念：MLIR 和 LLVM1。LLVM 通过引入 IR 的概念，减轻了传统编译器前后端之间的强耦合关系。与此同时也凸显出了模块化的概念，通过 IR 可以自由实现前后端的组合。而MLIR和IR是同一类别的事物，差别在于其更加通用可扩展，可以用于描述和表示程序的结构和语义信息。 如果想要利用MLIR实现图计算的相关编译工作，可行的思路就是将MLIR转换为LLVM IR（LLVM的中间表示形式），然后利用LLVM提供的优化器和代码生成器将LLVM IR编译成目标平台的机器代码，简单来说就是利用LLVM的后端，这样，MLIR可以利用LLVM的强大优化和代码生成能力，为不同的编程模型和应用场景提供高效的编译器支持。 Just a guess: gc: Graph Convolution（图卷积） gnn: Graph Neural Networks（图神经网络） gpm: 在了解 MLIR 过程中发现使用到了一个名为 TableGen 的工具，有一种说法是它是 一种声明式编程语言。似乎通过相关工具，可以将.td文件生成C++代码。粗浅理解似乎是为了能够运用某些公共组件 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:0:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"对于 MLIR 的理解 背景：在当前编译结构中，各种IR之间转换的效率和可迁移性不高 引入 MLIR 所期望做到的：使用一种一致性强的方式，为各种DSL提供一种中间表达形式，将他们集成为一套生态系统，编译到特定硬件平台的汇编语言上 MLIR 表达式组成: MLIR 并不是一个端到端（从计算图到最后可执行程序这个全流程）的框架，只是一个基础架构 多层次表达 是 MLIR 的优点，这有利于各种优化机制的实现（这并不难理解，中间过程越多，那么优化的入手点就越多），但是另一方面中间过程越多，出错的机会也同样越多，具体是指 compiler’s pass pipeline and toolchain are difficult to configure 中间表达的意义在于逐层解析，逐层降低抽象而偏向硬件。高级语言的 AST 到 IR 之间存在较大差距，通过在中间架设 IR 可以对高级抽象进行渐进式变换和递降，降低这种差距变化的梯度，降低阶段转换的难度，同时只要提供 IR 就相当于我们可以为任何领域的代码实现设计特定的编译器。 但是带来的一个问题就是，每当增加一种实现时都会出现一种全新的 IR，而实际上可能这些 IR 之间存在一些共性的东西，通过增设 MLIR 这一层类似标准化的层次，可以使得中间的转化流程变得更加规范 根据High Performance GPU Code Generation for Matrix-Matrix Multiplication using MLIR: Some Early Results2的说法，原有的IR基础设施并不能有效地解决自动生成特定领域库的问题。特别是，很难使用单个IR来表示和转换高，中，低级别的抽象。 MLIR 用于解决编程语言、编译器和硬件之间的交互问题，它的出现是为了应对日益复杂的编程语言和硬件架构 MLIR提供了一个统一的中间表示（IR），可以作为不同编程语言编译器和LLVM后端之间的桥梁。 通过自定义 dialect，可以实现语言扩充 和 实现特定领域的编译优化 如何评价MLIR项目中Linalg Dialect的设计思想？ 各种回答中，有两点思想对于理解 MLIR 有一定帮助： MLIR 或许可以看为一个 IR Template MLIR 的核心工作在于各种 Dialect 之间的转换。对于目前的项目，假设存在一种机制可以从 C++ 源代码转化到某种 Dialect，之后在不同 Dialect 中来回转换。不过不是很理解的是编译层到底在整体架构中处于什么地位，如果说是以第三方库的形式为框架层提供服务，那么这种服务的接口又是什么，难道就像 MLIR 中原生的这些类型一样？我们需要做的就是编写td文件创建各种 Dialect、operation等？编译层的生成物应当是 host 端和 device 端的类汇编语言，通过具体硬件平台的工具链完成执行流程 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:1:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"降级转换机制 Lowering（降级）的主要目标是将一个高级抽象表示转换为一个更低级别、更具体的表示。通常不会改变 IR 的属性，而只是将其转换为具有更具体语义的形式。例如，将高级的 vector dialect 转换为底层的 LLVM dialect，这只是对 IR 进行了降级，但它仍然是 MLIR IR，并且具有相同的属性和结构。 Translation（翻译）是将一个表示转换为另一个表示的过程，可能会改变 IR 的属性，并将其转换为不同的语言或表示形式。例如，将 MLIR IR 翻译为 LLVM IR。 无论是降级还是翻译，本质上都可以算作一种转换，都需要依托 Pass 机制来实现，只是说两个阶段在转换时用到的 Pass 并不相同 如果仅仅是用 MLIR 原生的 Dialect，那么 lowering 过程是可以直接通过 mlir-opt 来实现的，translation 过程可以直接通过 mlir-translate 来实现 但是如果说需要用到 custom dialect，这个 lowering 和 translation 过程就需要通过代码实现了，通过 MLIR 提供的接口来进行接入 2024/04/22 对上述内容进行修正： 按照最新的理解，实际上 lowering 可能并不一定仅仅表示 Dialect 之间的转化。 lowering 更核心的含义是 表示从一种抽象级别到另一种更底层的抽象级别的转换，而从高层抽象 Dialect 转换为 低层抽象 Dialect，以及从一种形式的 IR 转换到另一种更底层的 IR，这两种情况显然都是符合这种从高层到低层抽象级别的转换概念的。 所以说不必过于纠结所谓的 lowering, transformation, conversation 这些概念之间到底有什么详细的区别 因为从本质上来说，MLIR 中最核心的工作就是转换，无论是 Dialect 转换还是 IR 转换，而这些转换工具都可以抽象说为是 pass，它们在不同的层次和不同的粒度上执行转换，不同的 pass 有不同的作用范围、优化目标和实现方式，但是它们都是用于转换和优化MLIR程序的工具，简单对 pass 进行分类，如下所示（可能不全） Dialect Conversion Passes：用于在不同的Dialect之间进行转换，例如将MLIR程序转换为LLVM Dialect。 Lowering Passes：用于将高级抽象表示降低为更底层的表示，例如将高级Tensor表示降低为LLVM IR。 Backend Passes：用于生成目标代码或与特定硬件/平台相关的表示。 Transformation Passes：用于对程序进行结构上的转换，例如循环平铺、循环分块等。 Optimization Passes：用于优化MLIR程序，例如常见的优化技术包括死代码消除、常量折叠、循环优化等。 Analysis Passes：用于对程序进行静态分析，例如数据流分析、依赖分析等。 Verification Passes：用于验证程序的正确性，例如检查程序是否符合特定的规范。 Instrumentation Passes：用于在程序中插入额外的代码以收集性能数据或调试信息 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:1:1","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"MLIR 语法 MLIR 的源代码文档可见 mlir Namespace Reference，此文档是 mlir 的最外层的命名空间，因此可从此找到所有和 mlir 相关的代码 MLIR 采用类型后置表达，而且在需要用到的位置都需要注明常量或者变量的类型，例如: module { func.func @main() { %result = call @myfunc() : () -\u003e index vector.print %result : index return } func.func @myfunc() -\u003e index { %c0 = arith.constant 1 : index return %c0 : index } } 注意看上述代码中的@myfunc() : () -\u003e index（当然这里还用到了类似lambda中的后置返回值类型的表达方法），以及%result : index（虽然说目前还没有找到index代表常量的什么证据，但是可以姑且就这么认为）,以及1:index，它们都是将类型放置在了常量或者变量的后面，即类型后置表达 需要明确的是在上述的各种语法中，点运算符后的实际是一个 operation，从偏向编程语言的角度来说，它们实际上就是一个个的 function，只是表现形式上有些类似变量声明的语法 // Integer constant %1 = arith.constant 42 : i32 // Equivalent generic form %1 = \"arith.constant\"() {value = 42 : i32} : () -\u003e i32 在官方文档的 arith Dialect 中有这么一段代码，它们两个是等价的，考虑下面那一种形式 arith.constant() { value = 42 : i32 } : () -\u003e i32 考虑 MLIR 采用的后置类型表达，这实际就等价于编程语言中的 i32 arith::constant() { i32 value = 42; return value; } 不同点就在于类型以及作用域的表达方式发生了改变 MLIR 内置的数据类型：Builtin Dialect 对于 mlir-opt 命令携带的选项中那些 convert，目前的理解是代码中使用到了哪些 Dialect，如果想要利用 mlir-cpu-runner 执行，那就需要添加一个从这个 Dialect low 到 LLVM Dialect 的选项，例如： 如果代码中使用到了 vector Dialect 和 math Dialect，那么就需要添加两个选项： -convert-vector-to-llvm -convert-math-to-llvm 从 MLIR 提供的原生 Dialect convert (官方说法是 standard dialect) 到 LLVM Dialect 的相关介绍可以参考 “Conversion to the LLVM Dialect” ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:1:2","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Dialect 理解 Codegen Dialect Overview ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:1:3","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"MLIR Interface 背景问题 简单来说MLIR多层级的设计为其带来了便利，但是也同样带来了问题。 在不同的Dialect层次进行Operation转换或者做变换（Pass）的时候我们需要明确每个Dialect下的每个Operation的具体语意，否则就可能会转换或变换失败 Interface并不是Operation的核心，而是一些通用变换的核心 MLIR中的Interfaces MLIR概述 MemRef In-memory representation of a tensor The only way to access the element of a memref is through load and store operation. 使用 MLIR 实现矩阵乘法 所需的基本元素： 多维数组定义及取数操作 %v = arith.constant dense\u003c[[1, 2], [2, 3]]\u003e : vector\u003c2x2xi32\u003e vector.print %v : vector\u003c2x2xi32\u003e 循环语句 加减乘除数值运算 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:1:4","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"MLIR 编译 如果需要用到Python Bindings，在MLIR Getting Started给出的编译命令之外是需要添加额外的编译选项的，完整示例如下所示： 同时需要注意文档中提到的对于部分python包的依赖，这部分需要在编译之前进行安装 cmake -G Ninja ../llvm \\ -DLLVM_ENABLE_PROJECTS=mlir \\ -DLLVM_BUILD_EXAMPLES=ON \\ -DLLVM_TARGETS_TO_BUILD=\"Native\" \\ -DCMAKE_BUILD_TYPE=Debug \\ -DLLVM_USE_SPLIT_DWARF=ON \\ -DLLVM_ENABLE_ASSERTIONS=ON \\ -DCMAKE_C_COMPILER=clang \\ -DCMAKE_CXX_COMPILER=clang++ \\ -DLLVM_ENABLE_LLD=ON \\ -DMLIR_ENABLE_BINDINGS_PYTHON=ON \\ -DPython3_EXECUTABLE=\"/opt/homebrew/bin/python3\" compiler这个项目所包含的CMakeLists.txt中写死了一些路径，这些都需要进行修改 compiler项目在CMakeLists.txt中使用到了一些find_package()，涉及到numpy和pybind11，需要通过CMAKE_PREFIX_PATH手动指定路径 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:2:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"MLIR Tutorials 在 llvm 的项目源码中，同MLIR Tutorials相关的需要关注的是两个路径下的文件: /Users/gaohongyu/llvm/mlir/test/Examples/Toy：存放的是 toy 语言的源程序 /Users/gaohongyu/llvm/mlir/examples/toy：存放的是实现 toy 语言获取 AST，MLIR 表达式等工具的源代码 (产生的工具可执行文件在build/bin目录中) ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:3:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Chapter 1 Toy Language and AST 这一部分主要内容就是创造了一种新的语言，叫做Toy，然后实现了一个简易的语法分析器，仅仅能够获得toy源程序对应的抽象语法树。所以说这一节的重点就是抽象语法树 需要使用到的命令：~/llvm/build/bin/toyc-ch1 /Users/gaohongyu/llvm/mlir/test/Examples/Toy/Ch1/ast.toy --emit=ast 意思是通过toyc-ch1程序生成ast.toy程序的抽象语法树 实际上，这里采用 Toy 语言进行分析可能会给初学者带来一点困惑，因为这很容易让初学者陷入这个语言本身，而忽略了 MLIR 到底想做一件什么事情。 实际上，MLIR 采用一种自创的 Toy 语言，这是为了完整的展示从最开始的源程序，首先转换为 AST，然后进一步翻译为 MLIR 表达式，然后通过 lowering，逐步转换到可执行程序的全流程。而采用 Toy 并不是说 MLIR 只是应用于编译一门新的语言（当然它有这个功能），将 Toy 改为 python 或者 C++ 等其他语言也是一样的，关键并不在于 MLIR 所面对的是什么语言所形成的应用，而是 MLIR 面对的是一个应用这件事情本身，它要做的就是把这个应用通过 MLIR 的各个阶段，逐步翻译到我们所期望得到的东西，而 Chapter 1 所展现的从 源代码 转换为 AST 只是这个过程中的一环，并且这一环和 MLIR 并没有什么关系，因为 源代码 -\u003e AST 往往是语言本身所支持的。MLIR 关注的是从 AST 到 MLIR表达式的转换，以及 MLIR 表达式后续的变化。 上面提到，从 源程序 到 AST 的转换过程实际并不需要 MLIR 的介入，对于常见的编程语言，例如 python，官方是有提供 ast 包来实现这一点的。只不过由于 toy 是一个自创的语言，所以 Chapter 1 的代码主要做的就是解析抽象语法树。 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:3:1","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Chapter 2 Emitting Basic MLIR 在第一节中已经生成了 Toy 语言源程序的 AST，这一节就是要根据 AST 结合 Dialect 来生成 MLIR表达式 Ch2/toyc.cpp 相较于 Ch1/toy.cpp相比，有一个区别就是程序接收的参数多了一个： 这是Ch1/toy.cpp中和程序参数相关的内容： static cl::opt\u003cenum Action\u003e emitAction(\"emit\", cl::desc(\"Select the kind of output desired\"), cl::values(clEnumValN(DumpAST, \"ast\", \"output the AST dump\"))); 这是Ch2/toy.cpp中和程序参数相关的内容： static cl::opt\u003cenum Action\u003e emitAction( \"emit\", cl::desc(\"Select the kind of output desired\"), cl::values(clEnumValN(DumpAST, \"ast\", \"output the AST dump\")), cl::values(clEnumValN(DumpMLIR, \"mlir\", \"output the MLIR dump\"))); 区别就在于编译生成的toyc-ch2不仅能够生成toy源程序的抽象语法树，还能够生成对应的mlir表达式 关于 Ops.td 是如何同 Dialect模块（Dialect.h，Dialect.cpp）相结合的？** 通过Ops.td可以生成以下这些.inc文件: Dialect.h.inc: Dialect Declarations Dialect.cpp.inc: Dialect Definitions Ops.h.inc: Op Declarations Ops.cpp.inc: Op Definitions 而 Dialect 模块则使用到了这些文件： Dialect.h 负责引入 .h.inc，即 Declarations, 包括 Dialect.h.inc 和 Ops.h.inc Dialect.cpp 负责引入 .cpp.inc，即 Definitions，包括 Dialect.cpp.inc 和 Ops.cpp.inc 所以说，关于 dialect 本身 和 其 操作 等内容，都是在.td文件中说明，然后通过 tablegen 工具结合选项生成所需要的内容 Dialect.h 负责引入头文件这件事情并不难理解，那么如何理解 Dialect.cpp 和 Ops.cpp.inc 都具备的对于 Op Definition 功能这件事情？ 以 TransposeOp::build 为例: Ops.cpp.inc 中的相关内容为： void TransposeOp::build(::mlir::OpBuilder \u0026odsBuilder, ::mlir::OperationState \u0026odsState, ::mlir::Type resultType0, ::mlir::Value input) { odsState.addOperands(input); odsState.addTypes(resultType0); } void TransposeOp::build(::mlir::OpBuilder \u0026odsBuilder, ::mlir::OperationState \u0026odsState, ::mlir::TypeRange resultTypes, ::mlir::Value input) { odsState.addOperands(input); assert(resultTypes.size() == 1u \u0026\u0026 \"mismatched number of results\"); odsState.addTypes(resultTypes); } void TransposeOp::build(::mlir::OpBuilder \u0026, ::mlir::OperationState \u0026odsState, ::mlir::TypeRange resultTypes, ::mlir::ValueRange operands, ::llvm::ArrayRef\u003c::mlir::NamedAttribute\u003e attributes) { assert(operands.size() == 1u \u0026\u0026 \"mismatched number of parameters\"); odsState.addOperands(operands); odsState.addAttributes(attributes); assert(resultTypes.size() == 1u \u0026\u0026 \"mismatched number of return types\"); odsState.addTypes(resultTypes); } Dialect.cpp 中的相关内容为： void TransposeOp::build(mlir::OpBuilder \u0026builder, mlir::OperationState \u0026state, mlir::Value value) { state.addTypes(UnrankedTensorType::get(builder.getF64Type())); state.addOperands(value); } 目前还未搞懂这两者之间有何关联，不过 Ops.cpp.inc 还有额外的工作，就是在 Dialect.cpp 最开始的 dialect 初始化时为 dialect 指定操作： void ToyDialect::initialize() { addOperations\u003c #define GET_OP_LIST #include \"toy/Ops.cpp.inc\" \u003e(); } 关于创建一个 Op 所需要用到的类 以 Transpose Op 为例，根据 Ops.cpp.inc 的内容，和 transpose op 相关的有以下内容: TransposeOpGenericAdaptorBase TransposeOpGenericAdaptor TransposeOpAdaptor TransposeOp 随想疑问 一直在思考，toy tutorial 给出的这个示例到底对于实际的应用场景有何启发作用？ 实际上toy是一门新创造出的语言，是为了展示MLIR的各项特点而出现的，获取抽象语法树，获取MLIR表达式的工具都是项目自行实现的。 如果考虑真实的场景，例如用C++实现的代码，哪怕是框架，通过cmake都可以完成编译，引入MLIR难道就是为了替换掉整个编译流程中的前端和中端，用人工实现MLIR的方式逐层降级？首先编译层的上层是框架层，在我的理解中，我们可以把这个框架和Tensorflow或者Pytorch等价来看，但是在我看来，无论是不是新的框架，只要不是新的语言，理论上都可以用现有的编译工具完成编译，非要做这个编译层，非要用MLIR逐层降级只是为了提高性能，优化性能，使得每一层的优化都能够做到极致，而不是仅仅依靠现有编译器采用的那些优化。 那么有一个问题是：我们要站在哪个起点来分析这件事。toy是一门新的语言，所以说最基础的解析器都需要全新实现，也就是说面对toy这个场景就应当是一无所有的。但是现有项目是用C++实现的，MLIRGen这个工具对于现在的场景是存在的，肯定需要做的是写Dialect，那结合Dialect生成MLIR表达式这个过程是谁负责的？ 突然感觉我们的重点就是写Dialect，结合编程框架中的一些数据结构，在Dialect中把需要完成的内容完成，考虑一层一层是怎么降级的。我觉得像： 1.是怎么从源程序解析得到的AST？(这个问题不考虑，暂时不重要） 2.MLIRGen是怎么结合Dialect生成的一层表达（每一次Dialect的加入都会形成一层中间层），主要是类和类之间是怎么关联起来的 3. .td文件通过tablegen能生成很多东西，这些东西都怎么用？ 4. .td结合tablegen生成的一大堆东西 和 Dialect.cpp又是什么关系，或者说Dialect.cpp到底负责干什么的？ 我现在比较纠结的就是各个部分的联动关系，我不知道要写的内容到底要怎么发挥出它的作用 不太理解如果想要完成一层降级都需要做些什么，只知道要写dialect，但是这dialect是怎么对降级起到作用的？通过生成MLIR表达式或许是，所以说就是让dialect为生成MLIR表达式做出贡献 如果对toy ch2这个内容来说，是否可以假设现在有MLIRGen的工具，但是还没有相关的dialect，任务就是编写dialect实现MLIR表达式的生成。（因为后续教程的内容是例如表达式优化和降级的内容，如果让dialect在生成MLIR表达式这个过程中发挥作用我觉得是整个任务的基础） 如何理解 Dialect？ Dialects provide a grouping mechanism for abstraction under a unique namespace MLIR is designed to allow all IR elements, such as attributes, operations, and types, 自定义 Dialect 同 MLIR 结合的方式： C","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:3:2","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Chapter 3 High-level Language-Specific Analysis and Transformation 关于表达式变形消除冗余在整个流程中的位置： Chapter 3 的展开逻辑本质上是遵循了 Chapter 2 遗留下来的问题，不过其重新提出了一个 transpose(transpose(X)) -\u003e X 的问题，讲述如何解决这个问题。需要注意的是本节一共举了为两个操作添加优化方法的示例，它们采用了不同的方法， transpose操作 采用了 C++ 实现(对应ToyCombine.cpp)，reshape操作 采用了 DRR模块(对应ToyCombine.td) 这一节中，共涉及到整体架构的三部分； 这一节对应到的是 MLIR 的 Pattern Rewrite机制，用于对IR做一些通用变换优化，还负责Op的规范化以及Dialect间以及Dialect内部的Op转换，我感觉就是架构图中提到的 transformation 和 canonicalization C++ 实现 canonicalization 表达式的变形优化 在 MLIR 的场景下被称为 rewrite 想要实现 rewrite 需要进行以下几点： 实现一个 RewritePattern，即一个继承了mlir::OpRewritePattern\u003c\u003e的类 struct SimplifyRedundantTranspose : public mlir::OpRewritePattern\u003cTransposeOp\u003e 当继承这个OpRewritePattern类后，需要重写matchAndRewri方法 rewrite能够被应用，需要通过 canonicalization pass。需要做的工作一方面是让 规范化器知道有这个 rewrite 的存在，另一方面就是让其运用上这一 rewrite。所以这一步就是实现注册工作 void TransposeOp::getCanonicalizationPatterns(RewritePatternSet \u0026results, MLIRContext *context) { results.add\u003cSimplifyRedundantTranspose\u003e(context); } 不过有一点疑问是，这里只是类方法的定义，并没有找到对此方法的调用，那么是什么时候真正执行的注册? 关于这个问题，官方文档中有提到一个 canonicalization framework，虽然在第2点中说注册是为了让 规范化器 知道有这个rewrite的存在，但是本质上可能是为了让这个 优化框架 了解到这个rewrite的存在。有一种可能就是只要我们为一个操作定义了getCanonicalizationPatterns方法，那么 MLIR 在面对这个操作类的时候，就一定能检测到它是具备这个优化方法的，那么在下一步就能够真正实现这种优化。 真实的实现机制需要去看 MLIR 实现的源码是怎么处理的，我们暂且可以认为这样做就是满足 MLIR对于实现一个方法的优化 所做出的规定，也就是说 MLIR 提供了一种标准化的模版，我们只需要按照模版的要求去做，那么就可以为这个操作实现这种优化（实际上 Chapter 4 给出了支持这种看法的证据，详见Chapter 4） 规范化器 的 代码原型 就是 mlir::PassManager，即我们需要利用它来真正运用上第一步实现的 rewrite mlir::PassManager pm(module.get()-\u003egetName()); pm.addNestedPass\u003cmlir::toy::FuncOp\u003e(mlir::createCanonicalizerPass()); 使用 DRR模块 实现 transformation 相较于C++实现，使用 DRR模块 的优点似乎就在于省去了后两步的注册和应用到规范化器的两项操作，只需要实现一个继承关系即可 class Pattern\u003c dag sourcePattern, list\u003cdag\u003e resultPatterns, list\u003cdag\u003e additionalConstraints = [], dag benefitsAdded = (addBenefit 0)\u003e; def ReshapeReshapeOptPattern : Pat\u003c(ReshapeOp(ReshapeOp $arg)), (ReshapeOp $arg)\u003e; 不过教程中还额外给出了另外两种实现方式，那两种只是说在基础之上，额外添加了其他信息： 增加了参数限制：只需要实现一个Constraint类的子类，并且将该子类在创建模式时添加到模版参数之中 当限制条件比较复杂时，可以通过实现一个NativeCodeCall的子类添加原生的C++语句实现，同样在创建模式时将其添加到模版参数之中 对 Chapter 3 的理解和感悟 这样来说，是不是可以理解为 rewrite 就是一种 pass 通过这一部分内容，更加加深了对于 MLIR 似乎就和 SpringBoot 那种东西一样，我们似乎完全可以把他们当作普通的框架，为操作添加优化就是必须要为操作类定义getCanonicalizationPatterns方法，这就好像在其他那些框架中所要求做的类似 compiler pattern-match transformations 分类 local 有两种方法用于实现transformation： Imperative, C++ pattern-match and rewrite Declarative, rule-based pattern-match and rewrite(Declarative Rewrite Rules (DRR)模块)(此时要求之前的op定义是通过ods模块实现的，否则只能采用C++代码手动实现transformation了) 到这里，架构图中涉及到的两个模块就都出现了 global 关于 Pattern Rewrite机制 的疑问 在这个机制下，存在一些名称极为类似暂时还不清楚用途的类，例如 RewriterBase PatternRewriter 以上两者关系见 RewritePattern OpRewritePattern 上面这 4 个类是不同的，区别在于前者核心是 rewriter，后者核心是 pattern 这两个 pattern 之间的继承关系如下： ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:3:3","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Chapter 4 Enabling Generic Transformation with Interfaces 在 Chapter 3 的 C++ 实现 transformation 一节中留下了一个疑问，即在给一个 operation 应用一种 模式patter，或者说希望重写它时，我们是定义了TransposeOp::getCanonicalizationPatterns这一方法，当时我们疑问在于代码中只是定义了但是并没有在任何位置看到调用它的代码，那么其是如何发挥作用的？ 在 Chapter 4 开头给出，getCanonicalizationPatterns 实际是一个钩子函数，作用于operations之上，通过钩子函数实现为 operation 添加额外功能的方法并不难理解，这也是软件开发中常见的一种方法 不过钩子函数从何而来，是需要我们自行创建（如果是这样的话，又需要在哪个环节进行创建），还是 MLIR 本身对于 operation 就声明了一些固定的钩子函数？ 关于这个问题，我们进行了如下的探究： 关于 TransposeOp，源头应当位于 Ops.td，所以我们回到这一文件 文件中主要包含 2 部分内容，一是对于 Dialect 的说明，二是对于 operation 的说明 对于 Dialect 的说明： def Toy_Dialect : Dialect { let name = \"toy\"; let cppNamespace = \"::mlir::toy\"; } 对于 operation 的说明： class Toy_Op\u003cstring mnemonic, list\u003cTrait\u003e traits = []\u003e : Op\u003cToy_Dialect, mnemonic, traits\u003e; def TransposeOp : Toy_Op\u003c\"transpose\"\u003e{ } 由此可见，关于 operation 的继承关系是 TransposeOp -\u003e Toy_Op -\u003e Op 由于 td 只是声明性语言，并不代码最终的代码实现，所以我们对 cpp 文件下的实际的 TransposeOp类 进行了追踪，发现其实际声明位于 Ops.h.inc，同时声明内容为 class TransposeOp : public ::mlir::Op\u003c\u003e { static void getCanonicalizationPatterns(::mlir::RewritePatternSet \u0026results, ::mlir::MLIRContext *context); } 由于 Ops.h.inc 是有 Ops.td 生成的，但是在 Ops.td 中并没有显示给出 getCanonicalizationPatterns 的声明，说明这一方法应当是通过继承关系得到的(在llvm源码中，确实有找到 和 getCanonicalizationPatterns 相关的内容，不过还未完全分析透彻逻辑关系）,说明只要是继承了 mlir::Op 的子类，都应当是能够使用这个钩子函数的 官方定义的毕竟是有限且不够灵活的，所以 MLIR 就提出了 interface 的概念，用户可以自定义实现各种钩子函数（感觉这就是一个组件化工具正常的发展流程，官方提供一些，然后官方开放接口，第三方可自行实现接入） 本 Chapter 提及的也是 Dialect 的一个子部分 引入的情景是 tensor 的形状推导 目前感觉 Chapter 4 所介绍的 Interface 只是对于 Chapter 3 所介绍的用于表达式优化的 pattern 在功能性上的一种扩充，所以说并不需要把其当作一种新的技术点 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:3:4","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"MLIR Python Bindings MLIR 表达式的构建在此之前都是通过 C++ 代码实现的， 法斯特豪斯博客里面给的也是一个创建 operation 的流程，应该是将 c++源程序 解析为 MLIR表达式这个过程，而不是对 MLIR 表达式进行降级这个过程 按照我目前的理解，python binding 是用在 frontend 的，用在将 python源程序 解析为 MLIR表达式这个过程，就像将 C++源程序 解析为 MLIR表达式 将源程序解析为 MLIR 表达式是 frontend 的工作，而对 MLIR 表达式进行降级是 middleend 的工作 python binding 关注的是 frontend 的工作，或者说其就是用于实现 MLIRGen 模块的 只要理解了 frontend + backend 这个结构，python binding存在的意义就不难理解了，后续的关键问题就是为了实现将 python 解析为 MLIR 表达式，需要写哪些内容 而 frontend 的重点就是 MLIRGen，这包含两部分工作：一是 源代码 生成 AST，这一步和 MLIR 并没有关联；二是 AST 生成 MLIR 表达式，在这一步中 MLIR 才开始介入 因为 MLIR 本身是 C++ 实现的，tablegen 工具最终生成的也同样为 C++ 代码，所以通过 C++ 实现从一种 语言源程序 转换为 MLIR 表达式，这个过程是很自然的(C++ 代码调用 C++ 代码)。而使用 python 实现 MLIR 表达式生成，需要利用 tablegen 生成的 C++ 代码内容，但是又无法直接使用，所以就需要通过 python binding，将 C++ 内容生成 python 接口，以供 python 实现的 MLIRGen 模块使用，因此我们首先了解一下 C++ 代码实现的 MLIRGen 模块所需要进行的工作，以便更好迁移到 python 实现上。 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:4:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"生成 MLIR 表达式 所需的模块：3 TableGen模块(生产线的零件): 通过.td文件定义了各种操作的类（这部分也叫做Operation Definition Specification (ODS)框架）(我理解这部分也可以通过手动编写C++代码实现，只是说可能写起来比较繁琐，同时在不同的场景下可能存在类似的需求，如果总是手动编写会带来很大的重复工作量，所以说一般通过td文件结合TableGen工具来生成) Dialect模块(生产线的机械臂): 负责定义各种操作和分析，为操作添加相应的类型和操作数的值 MLIRGen模块(生产线履带): 遍历抽象语法树(AST)，构造 MLIR 节点 TableGen模块在编译时向Dialect模块提供支持 我理解着上述这 3 个模块之间的关系，或者说作用流程，大概是 TableGen 模块生成的是一种类似模版的东西，然后 Dialect 像是具体的适配器，为模版添加不同的属性，这样两阶段分离的设计可以做到 模版 和 数据 解耦合，同时做到 模版 的复用，最后再通过 MLIRGen 将添加了具体属性的模版 生成为 MLIR 节点 关注图中TransposeOp的指向 从项目的编译结果来看，build/python 下的文件都是通过工具生成的，那么直观来理解，我们只需要编写好 tablegen 的内容以及 pybind 所涉及到的接口，通过 pybind 提供的 cmake 即可根据 tablegen 生成的 c++ 内容生成对应的 python 内容，然后直接在 MLIRGen 模块中使用即可。 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:4:1","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"mlir “hello world” 假设现在有下面这样一段 mlir，我们的目标是让其能够在机器上跑起来 func.func @main() { %0 = \"hello.constant\"() {value = dense\u003c[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]\u003e : tensor\u003c2x3xf64\u003e} : () -\u003e tensor\u003c2x3xf64\u003e \"hello.print\"(%0) : (tensor\u003c2x3xf64\u003e) -\u003e () return } ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"定义 Dialect 这里面涉及到一个 hello Dialect，其至少需要 constant 和 print 两个 operation 从项目文件结构上来说，和目前需要的文件包含两部分：HelloDialect.[h/td] 和 HelloOps.[h/td]，前者对应 Dialect，后者对应 operation 主要需要做的是两件事：1. 创建新的 Dialect 2. 创建 operation 基类 def Hello_Dialect : Dialect { // 定义名字空间 namespace，对应 C++ 的 getDialectNamespace 方法返回值 let name = \"hello\"; ... let cppNamespace = \"::hello\"; // 该设置用于激活 materializeConstant 方法，这使得可以例如 Canonicalize 优化 } class Hello_Op\u003cstring mnemonic, list\u003cTrait\u003e traits = []\u003e : Op\u003cHello_Dialect, mnemonic, traits\u003e; ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:1","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"定义 operation 使用 mlir-tblgen 工具对 HelloOps.td 进行转换可以得到对于 operation 的声明，其中包含的类的继承关系为 constant operation ConstantOpAdaptor -\u003e ConstantOpGenericAdaptor -\u003e ConstantOpGenericAdaptorBase (前者继承后者) 核心的 ConstantOp 继承的是 ::mlir::Op，不过其会利用到上述 3 种类 print operation PrintOpAdaptor -\u003e PrintOpGenericAdaptor -\u003e PrintOpGenericAdaptorBase 新的 operation 一般至少包含 4 个元素（实际上并不知道这几种字段都负责什么） summary builders arguments results def ConstantOp : Hello_Op\u003c\"constant\", [Pure]\u003e { // 一行关于这个 Op 的介绍 let summary = \"constant\"; ... let builders = [ OpBuilder\u003c(ins \"mlir::DenseElementsAttr\":$value), [{ build($_builder, $_state, value.getType(), value); }]\u003e, OpBuilder\u003c(ins \"double\":$value)\u003e ]; ... let arguments = (ins F64ElementsAttr:$value); let results = (outs F64Tensor); } ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:2","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"创建 pass 如果只看 mlir-hello，那么 pass 实际上只用于了 lowering 的过程，但是实际上 lowering 和 transformation 两个过程使用到的都属于 pass，后续的描述由于是在看 mlir-hello 时所写，所有有可能偏向于 lowering，但是你需要知道的是 pass 也可同样应用于 transformation。简单点来理解，只要涉及到形式上的变化，都可以使用 pass 来完成。 同时 pass 的实现可以通过手写 C++ 实现，也可以通过利用 DRR（Declarative Rewrite Rule）框架来实现 降级到底在降什么？ HelloDialect 是我们自定义出的 dialect，而我们最终的目标是对接到 LLVM backend，这些自定义 dialect 显然是做不到的，但是 MLIR 本身提供的一些 dialect 可以做到，可能 LLVM 为它们提供了对接方式。 所以说我们所需要做的，一方面是在自定义 dialect 之间实现转化，另一方面是需要把 自定义dialect 转换到 MLIR提供的 dialect（可以理解为标准库）上 这部分工作除了需要用到 dialect 和 operation 作为基本原料，还需要 HelloPasses.h 来注册pass，即从一种 dialect 转换到另一种 dialect。仅注册还不行，还需要 LowerToAffine.cpp 的具体实现 以上提到了两个文件 HelloPasses.h 和 LowerToAffine.cpp，不过在实际的项目中并不一定就只有这两个文件，可能会进行很多拆分，不过我们只需要掌握这两个文件所要完成的核心工作即可适应各种项目 方法 1 - 全人工实现 此部分遵循 mlir-hello 项目的实现方式 pass 注册 std::unique_ptr\u003cmlir::Pass\u003e createLowerToAffinePass(); 所谓注册，其实就是创建了一个 pass 的函数钩子 pass实现 2.1 编写操作的 lowering class ConstantOpLowering : public mlir::OpRewritePattern\u003chello::ConstantOp\u003e { mlir::LogicalResult matchAndRewrite(hello::ConstantOp op, mlir::PatternRewriter \u0026rewriter) const final { } }; 首先不考虑具体的实现细节，观察这部分代码的核心有以下几点： 定义为 class XxxOpLowering 继承自 mlir::OpRewritePatternxxx::XxxOp 重载 matchAndRewrite 函数，做具体实现 XxxOpLowering 最终将作为模板参数传入新 pass 的 mlir::RewritePatternSet(这一点并不在此函数中实现，而实在下一部分) 2.2 实现 dialect 到 dialect 的转换（将 lowering 加入 pass） 实际项目中，这一步会划分为 声明(.h 文件中) 和 实现(.cpp 文件中) 两部分，一般 runOnOperation() 的实现会置于 cpp 文件中，这里为了描述上的简洁就合并在一起了 class HelloToAffineLowerPass : public mlir::PassWrapper\u003cHelloToAffineLowerPass, mlir::OperationPass\u003cmlir::ModuleOp\u003e\u003e { public: MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(HelloToAffineLowerPass) void getDependentDialects(mlir::DialectRegistry \u0026registry) const override { registry.insert\u003cmlir::affine::AffineDialect, mlir::func::FuncDialect, mlir::memref::MemRefDialect\u003e(); } void runOnOperation() final { mlir::RewritePatternSet patterns(\u0026getContext()); patterns.add\u003cConstantOpLowering, PrintOpLowering\u003e(\u0026getContext()); }; }; 这里的重点在于实现了 runOnOperation() 方法, 在此方法中完成上一步所提及的 lowering 作为模版参数传入 pass 2.3 完成函数钩子 std::unique_ptr\u003cmlir::Pass\u003e hello::createLowerToAffinePass() { return std::make_unique\u003cHelloToAffineLowerPass\u003e(); } 如何理解这一 function hook? 从 official website - Pass Infrastructure - Declarative Pass Specification 中可以找到在使用 td 声明 pass 时，指定 constructor 的 作用为 A constructor must be provided to specify how to create a default instance of MyPass. 而为 constructor 指定的内容就是我们创建的 function hook，因此这一 function hook 的作用即为 指出如何创建一个 pass 的实例 所以综合以上所有内容来看，创建一个 pass，其实就是 create 了一个 unique_str，这个智能指针指向了一个类，这个类实现了 runOnOperation()方法，并且在这个方法中有指定操作的匹配重写规则 方法 2 - 使用 tablegen 在人工实现中，创建 pass 时，我们是手动继承的 mlir::PassWrapper 类。 而使用 tablegen 时，首先会在 td 文件中给出一个对 pass 的继承，如以下代码所示。 def ConvertGraphToMatrix : Pass\u003c\"convert-graph-to-matrix\", \"ModuleOp\"\u003e { let summary = \"Convert Graph Ops to Matrix Ops\"; let constructor = \"compiler::createConvertGraphToMatrix()\"; let dependentDialects = [\"compiler::graph::GraphDialect\", \"compiler::matrix::MatrixDialect\"]; let options = [ ]; } 而这部分代码经过 tablegen 转换后所形成的类，以及相关的继承关系为：ConvertGraphToMatrixBase -\u003e mlir::OperationPass。 这里出现了两种不同的基类（我个人理解全人工实现下也一样可以采用 OperationPass），PassWrapper 和 OperationPass，它们二者之间也有着一定继承关系 之后的操作其实就与全人工实现的方式类似了，不同之处在于创建包含 runOnOperation() 方法的类时，不再去继承 mlir::PassWrapper 类，而是直接继承 ConvertGraphToMatrixBase。 然后其他需要做的事情并没有改变。 那么不禁让人产生一种疑问，当我们采用 tablegen 时，除了在创建包含runOnOperation() 方法的类时，多增加了编写 td 文件的一步，其他流程并没有减少，相当于使用 td 反而让流程变得更加复杂了。 实际上，如果我们在 td 中给定了 constructor，我们看 td 文件生成的内容时，就会发现其中包含着 pass 的 function hook，但是目前简单的测试下，还无法正常直接使用这些 function hook，利用的仍然是人工给出的内容，后续可以再进行其他测试，按照理解，当使用 tablegen 并且指定 constructor 时，应当就无需人工声明和定义 function hook 了，即只需要重写 matchAndRewrite() 和 runOnOperation(), 从而通过 tablegen 简化代码编写。 同时需要注意的是，mlir-hello 这里为了降低理解上的难度，并没有采用 td 文件来实现 pass 的声明，而是直接利用了 C++ 代码 方法 3 - 借助 Canonicalization Framework canonicalization function 同 pass 的关系为，canonicalization function 可以认为是一种 pass，但是 pass 所执行的并不一定是 canonicalization 功能。 以 transpose 操作为例，如果为此 operation 指定了一个消除重复转置的规范化器 canonicalization，那么在发生重复转置后可以对此操作进行规范化，以进行表达式优","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:3","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"创建 opt 分析到这里会给人一种迷惑，似乎我们已经实现了这个降级的过程。 但是仔细考虑一下，截止到目前我们都创建了什么？dialect, operation，operation重写规则 和 pass 而我们的目的是什么？将 mlir 转变为可以对接到 LLVM backend 的内容。 可以发现，我们目前创建的这些东西就像是原材料一样，我们需要一个媒介，将它们和 mlir 进行链接，实现内容转换，而 opt 起到的就是这种作用。简单来说，opt 就是利用已有的工作接口完成一个 lowering 的流程描述 如何理解 hello-opt 这类工具？ mlir 片段确实是摆在这里了，所需要的 Dialect 和 对应的 operation 也都写好了，但是问题是他们之间如何建立起联系来？ hello-opt 充当的就是这个桥梁作用，简单理解它可以将 mlir片段 作为输入，利用声明好的 Dialect 和 operation 对 mlir 进行一系列 lowering 和 transformation 操作，从而最终转化为 LLVM IR 或者其他什么格式，从而接入到 LLVM backend 中 opt 类工具采用的一般的操作流程： 向 contex 中 加载 dialect context.loadDialect\u003cmlir::func::FuncDialect\u003e(); 使用 pass 完成 lowering 和 transformation mlir::PassManager pm(\u0026context);; pm.addPass(compiler::createConvertGraphToMatrix()); pm.run(module_.get()); 对于 mlir-hello 来说，lowering 和 transformation 是两个界限清晰的过程。它使用 PassManager 仅仅完成了 lowering 的过程，transformation 的过程是通过其他 llvm 接口来实现的。不过对于 graph_compiler 来说，pass 不仅完成了 lowering，也完成了 transformation 的过程 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:4","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"CMakeLists.txt解读 – CMAKE_BINARY_DIR: 项目的 build 目录: /home/xxx/project/build – LLVM_INCLUDE_DIRS: 采用的 llvm 下的两个和 llvm 相关的 include 路径: /home/xxx/llvm/llvm/include;/home/xxx/llvm/build/include – MLIR_INCLUDE_DIRS: 采用的 llvm 下的两个和 mlir 相关的 include 路径: /home/xxx/llvm/mlir/include;/home/xxx/llvm/build/tools/mlir/include – PROJECT_SOURCE_DIR: 项目根路径: /home/xxx/project – PROJECT_BINARY_DIR: 项目 build 路径: /home/xxx/project/build ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:5","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"疑惑 在 mlir-hello 的 LowerToAffine.cpp 中，存在一个如下的方法调用 rewriter.modifyOpInPlace(op, [\u0026] { op-\u003esetOperands(adaptor.getOperands()); }); 但是编译老是报错 error: ‘class mlir::ConversionPatternRewriter’ has no member named ‘modifyOpInPlace’ 但是通过 clangd 又可以定位到此方法的位置，在 llvm 的 install 目录下，同时发现在源码中确实没有这一方法，这就非常神奇了 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:5:6","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"buddy-mlir ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"introduction 同 MLIR 的关联：reuse the MLIR infrastructure and LLVM backend tools MLIR 之外的特点： optimization tool auto-config mechanism Buddy-MLIR 包含一些基于 MLIR infrastructure 实现的算法，需要利用到 MLIR Dialect 和 Op MLIR 作为一种基础设施，实际上是不去负责端到端的这个编译流程的，那么说上层应用（例如pytorch、tensorflow等）如何对接到下层形式各样的硬件上就是目前的难题，尤其是目前形式各样的异构芯片的出现更加剧了这种问题。 关于不负责端到端的编译流程的具像化理解，从目前的使用和理解来看，MLIR 并没有提供前端，其只提供了和 MLIR 表达式相关的一些工具和一些原生的 Dialect，只用这些是不足以完成从上层应用到下层硬件之间的对接的，所以说其不负责端到端的编译流程。更多的感觉是提供了一种框架，给出了一种约束，开发者可以利用这种模式来实现各种各样的编译流程。 但是 Buddy-MLIR 对于解决这种问题提供了什么样的解决方案呢？从上图来看，如果说 MLIR 是一些积木的话，那么 Buddy-MLIR 的意图似乎是利用这些积木，搭建起一个城堡，通过为前中后端提供 Dialect，帮助上层的例如 pytorch 应用能够部署到底层具体的硬件上 但是我没太明白在 Buddy Compiler 的项目中插入如此多的 Example 是什么意思，感觉这些 Example 更多的应该是 MLIR 所提供的，用于展示其 Dialect 的用法，不知道放在这里和其本身的设计思想之间有什么关系。 不过如果你看了代码，或者说Buddy Compiler As A Service (Buddy-CAAS)，你会发现 Buddy-MLIR 项目中给出的 IR Level Examples 其实就是 MLIR 原生提供的 Dialect 的使用示例，在项目中，对应着 examples/MLIR*这些目录。这些示例是通过 mlir-opt, mlir-translate 和 mlir-cpu-runner 可以直接 lowering、translation 以及 run 的。所以我理解就是首先通过这些示例让学习者可以更好地理解 MLIR 中各种概念的存在形式，所以入门 MLIR 时不妨直接从了解 MLIR 的原生 Dialect 入手，逐渐搞懂各种概念，然后再去了解如何自行创建 Dialect 或者 operation 等。官方教程从 Toy 的示例开始，直接就自定义 Dialect，确实让人很难理解各种模块存在的内在机理 llvm-as 可以将 LLVM IR 转变为 LLVM IR bitcode llc 可以将 LLVM IR bitcode 转变为 assembler source text, ASCII text llc 也可以直接将 LLVM IR 转变为 assembler source text, ASCII text 但是并没有真正运行起来，不过就是说即便不考虑后续如何执行，翻译到 LLVM IR 这一层级也就 OK 了 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:1","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Build 在第一步构建过程中遇到几个坑点： The target building platform of MLIR is uncompleted，because MLIR Getting Started asks that we can use the build option -DLLVM_TARGETS_TO_BUILD=\"Native;NVPTX;AMDGPU\", but the buddy-mlir needs the RISCV platform data, so we need to recompile the MLIR I learn about the process of building buddy-compiler needs the mlir compiling data from the option -DMLIR_DIR=$PWD/../llvm/build/lib/cmake/mlir and -DLLVM_DIR=$PWD/../llvm/build/lib/cmake/llvm, so I think a idea that create a soft link of llvm project for the buddy-compiler. But when I build the buddy-compiler, I get the error message that cmake cannot find some files about RISCV, until I get some tips from the slack 执行之后就能够正常build了，但是里面不确定的因素有二，其一是 我手动创建软链接确实也起到了增加submodule的功能，因为执行 git submodule update –init 之后并没有重复 git clone llvm- project，但是不太清楚执行之后到底产生了什么其他的额外影响(主要怀疑会不会执行后修改了什么变量），使得 cmake 就能够找到相关文件了；其二是 submodule 并不仅仅只有 llvm 这一个，还存在另外一个，不确定是不是因为之前缺少这个子模块从而导致build失败（不过这一点是可以验证的，只需要注释掉这部分，只 git submodule llvm-project 那部分，查看是否可以完成 build 就可以，按理说应该不太行） ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:2","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Structure 目前的困惑在于 buddy-mlir 是否可以看为是对 mlir 的一种封装，如果是的话，封装了啥，如果不是，那它相较于 mlir 又有何区别或者说设计的意义在哪里 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:3","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"source code structure ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:4","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"understanding Bud Dialect 展示了自定义 Dialect，并降级到 MLIR提供的基础设施上（从代码来看就是一些 llvm 项目下的 Dialect） include目录下包含了.td，lib下的 conversion 中实现了降级的代码 pass 机制，pattern rewrite机制，interface 目前粗浅的理解就是 pattern rewrite 就是所谓表达式优化和降级的过程（即无论是表达式优化还是降级，都是通过rewrite实现的），这个过程中使用到的东西从概念上来讲就是各种 pass，而各种 pass 在实际命名上就是各种 dialect。而operation的概念在整个流程中是一直存在的。每一个 dialect 或许就可以看为是一个层次，每个层次下都有不同抽象级别的，与当前层次对应的 operation 表述 （这篇文章如何在MLIR里面写Pass 从 examples 下的 IR Level Examples 了解到了通过 MLIR tool chain 可以直接执行 MLIR 表达式 才领悟到我们似乎可以将 MLIR 当作一门普通的语言，其同样具备相关的语法，我们可以借助它的语法实现一些算法，但是带来的疑问是如果仅仅通过 MLIR 就能够完成所有操作，那我们为什么不直接写 MLIR 了，而是还需要去写 C++ 代码，那些 operation 又要起到什么作用。 关于这个疑问，我们大概可以从 mlir-opt --help 命令的输出结果中得到一点启发，其中 --convert-vector-to-llvm 选项的内容是 –convert-vector-to-llvm - Lower the operations from the vector dialect into the LLVM dialect 注意上面提到两个 dialect：vector dialect 和 LLVM dialect 同时在命令输出中还包含了以下内容： Available Dialects: acc, affine, amdgpu, amx, arith, arm_neon, arm_sme, arm_sve, async, bufferization, builtin, cf, complex, dlti, emitc, func, gpu, index, irdl, linalg, llvm, math, memref, mesh, ml_program, mpi, nvgpu, nvvm, omp, pdl, pdl_interp, quant, rocdl, scf, shape, sparse_tensor, spirv, tensor, test, test_dyn, tosa, transform, ub, vector, x86vector, xegpu 那么也就是说上面这些以及mlir-opt命令能够携带的参数中使用到的dialect，实际都是 MLIR 项目中自带的一些 dialect，或者说是原生的 但是，在实际的应用场景下，我们所需要用到的 dialect 并不仅仅是这些，我们往往需要用到其他类型的，结合实际场景的，所以这就是我们为什么需要自己编写 dialect 的原因 所以首先通过直接借用 mlir 的相关工具和原生的 dialect，直接编写 MLIR 代码，能够帮助我们了解 Buddy-MLIR 提供的 IR Level Examples，主要包含三部分： low translate run 在降级环节(low)中，始终都是 MLIR，即便是 mlir-opt 应用了例如 --convert-func-to-llvm 这类选项，但是也只是说用 llvm dialect 进行了降级，但是其属于 MLIR 的本质并没有改变，证据可见 –convert-func-to-llvm - Convert from the Func dialect to the LLVM dialect 然而在翻译环节(translate)，注意是translate而非transformation，才是真正完成从 MLIR 到 其他 IR 的转变，证据可见 mlir-translate 采用的选项 --mlir-to-llvmir –mlir-to-llvmir - Translate MLIR to LLVMIR 而在运行环节，由于 mlir-cpu-runner JIT 实际运行的是 MLIR，所以其只能处理 这里给出的这些 example，利用到的 Dialect 都是 LLVM 项目，准确地说是 MLIR 中预置的，所以可以通过各种 mlir 工具来实现降级和翻译。如果想要实现自定义的Dialect，那就和创建一个例如 compiler 的项目相同了。 Buddy-MLIR 项目框架重点 include下的td文件负责给出 Dialect 和 Operation 的说明，后续在编译过程中通过 llvm-tblgen 生成所需的各种文件 lib 下的 Conversion 负责给出 lowering pipeline，将 custom dialect’s operation lowering 到 MLIR’s standard dialect，从而将 custom dialect 接入 MLIR ecosystem example 下给出的实际就是如何使用 buddy-mlir 的示例。Buddy-MLIR 为使用者在frontend中提供了上层应用和 buddy-mlir 进行交互的接口数据结构，然后Buddy-MLIR 应用了MLIR 提供的一个 C/C++ 的前端接口功能，完成了端到端的应用构建 不过有一个疑问是，buddy-mlir 向上层提供接口的方式是提供了一个 Memref 数据结构，难道通过这一个数据结构就能够完成 简单来说就是 buddy-mlir 向上层提供了C函数接口，上层C应用只需要直接调用函数即可（不过在 ConvOpt/edge-detection.cpp 的示例中使用到了_mlir_ciface_conv_2d函数，但是此函数并没有找到相关定义，不过它利用到了buddy-opt以及llvm的相关工具，可能和它们有关，具体的实现机制还有待商榷）。所以说项目需要做的就是提供好相关 dialect、operation，为上层应用提供好调用接口 从 Buddy-MLIR 提供的 BudDialect example 就可以看出，在 examples/BudDialect 提供的是一些 mlir 文件，其中用到的一些 mlir 语法实际上都是属于 BudDialect 的。但是通过 buddy-opt 就可以降级到 MLIR，这里涉及到两个问题： buddy-opt 哪里来？ 为什么 buddy-opt 可以把自定义的 BudDialect 降级到 MLIR？ buddy-opt 是在 tools 中实现的一个工具，我们可以先简单认为它利用了在 midend 中给出的和 BudDialect 相关的内容，这其中就包含不同 dialect 转换所需要用到的内容。也就是说我们只需要实现了 dialect 体系中的相关内容，通过利用 MLIR 提供的接口就可以简单创建出相关的工具，从而实现 lowering 或者 transformation 的过程 对于 BudDialect 的构建过程，理论上在不添加 buddy-opt 的情况下，虽然什么都做不了，但是也应当可以正常通过编译，只是说没有 buddy-opt 确实没办法做出什么效果。然后再加入 buddy-opt 完成编译。 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:5","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Examples Introductoin 4 ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:6:6","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"Reference LLVM ↩︎ High Performance GPU Code Generation for Matrix-Matrix Multiplication using MLIR: Some Early Results ↩︎ MLIR的生产线 ↩︎ buddy-mlir Examples ↩︎ ","date":"2024-03-07","objectID":"/blog/posts/graph-computing/mlir/:7:0","tags":null,"title":"MLIR","uri":"/blog/posts/graph-computing/mlir/"},{"categories":["Graph-Computing"],"content":"项目文件分类 ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:1:0","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"Storage GPU_Graph_Storage.[cuh] GPUGraphStore.[cu/cuh] 这两个的区别可能在于下面的是图的逻辑存储结构，上面的是物理存储结构(因为涉及到了CSR) GPU_Memory_Graph_Storage.[cu] GPU_Node_Storage.[cuh] ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:1:1","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"Cache GPUCache.[cu/cuh] GPU_IPC_Service.[cu/h] GPUMemoryPool.[cu/cuh] hashmap.[h] helper_multiprocess.[cpp/h] Kernels.[cu/cuh] Operator.[cu/h] Server.[cu/h] ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:1:2","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"初始化 GPUServer-\u003eInitialize 获取了性能计数器以便获取 $N_{TSUM}$ , 供 Cost Model 使用 cpp monitor_ = new PCM_Monitor(); // PCM:Performance Counter Monitor,性能计数器监视器 monitor_-\u003eInit(); GPUGraphStore-\u003eInitialize 数据集的初始化 1.1 把数据集分为训练、验证 和 测试 集 1.2 把数据加载到 GPU 的显存中 Cache 部分的初始化 GPURunner-\u003eInitialize 执行器初始化，没个gpu都对应一个执行器 创建了2个gpu stream ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:2:0","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"系统执行参数 在main.cpp的server-\u003eInitialize(atoi(argv[1]));环节，会执行GPUGraphStore.cu中定义的void GPUGraphStore::Initialze()，其中包含一个步骤ReadMetaFIle()，这个步骤读取了./meta_config文件中提前写入的以下参数： Dataset path Raw Batchsize Graph nodes num Graph edges num Feature dim Training set num Validation set num Testing set num Cache memory Train epoch Partition? ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:3:0","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"训练、验证、测试集大小和批次确定 在main.cpp的server-\u003eInitialize(atoi(argv[1]));环节，会执行GPUGraphStore.cu中定义的void GPUGraphStore::Initialze()，其中包含两个步骤 env_ = NewIPCEnv(shard_count); env_ -\u003e Coordinate(info); 关于IPC的内容可以追溯到CUDA_IPC_Service.cu，在Coordinate()中实现了对于train_step、train_batch_size、valid_step、valid_batch_size、test_step 和 test_batch_size的更新 ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:4:0","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["Graph-Computing"],"content":"函数调用流程 main.cpp调用Server-\u003eRun()，目标位于Server.cu Run()调用RunnerLoop，目标仍位于Server.cu RunnerLoop调用Runner-\u003eRunOnce()，目标仍位于Server.cu RunOnce()中的关键在于一个类型为IPCEnv的变量env调用的方法IPCPost，定义env的是RunOnce()中的参数params，往回捯到Server-\u003eRun，发现定义params的是params_容器，发现它是Server.cu-\u003eclass GPUServer中的一个私有容器，其中元素的类型为RunnerParams，此类型声明位于Server.h。想要定位IPCPost，需要找到params_初始化的内容。params_在Server.cu-\u003eGPUServer-\u003eInitialize()中被初始化为gpu_ipc_env_，这同样是一个Server.cu-\u003eclass GPUServer的私有变量，类型为IPCEnv*，而gpu_ipc_env_与params_在同样的位置被初始化为gpu_graph_store-\u003eGetIPCEnv()，其中有GPUGraphStore* gpu_graph_store = new GPUGraphStore();，于是定位到GPUGraphStore.cuh文件 在GPUGraphStore.cuh中发现了IPCEnv的结构存在于CUDA_IPC_Service.h(Inter-Process Communication,IPC,进程间通信）。截止到目前不确定作用的函数调用包括IPCPost和GetIPCEnv，前者是IPCEnv类的方法，后者是GPUGraphStore类的方法 考虑到关键仍然在于第3点中的RunOnce()，所以优先去看IPCPost()到底做了什么。在IPCPost中，根据设备id和现在的管道拿到一个信号量，然后将此信号量加1表示代表资源被释放，即指定设备id和指定管道资源被释放（这是什么资源？） 根据上述分析，再往下走是和信号量相关的内容，分析这么多完全没看到和图划分相关的内容，于是将视线回归到main.cpp中server-\u003eRun()的前一步server-\u003ePreSc()（主要是考虑到Initialize无非做的是一些数据初始化的工作，应该不太会涉及到具体的任务代码） 于是转到Server.cu，PreSc是GPUServer类的一个方法，根据ChatGPT的说法，PreSc很可能是preprocess scheduler的缩写，即预处理调度器。在其中不难发现包含调用CandidateSelection和CostModel的内容，根据论文，这部分已经是图划分的下一个cache构建阶段的工作了，所以代码中如果包括图划分就应该在调用CandidateSelection之前就出现了，之前是一个构建线程的工作，线程所需要执行的操作是PreSCLoop 在PreSCLoop中，一个似乎是关键的函数调用是runner-\u003eRunPreSc(params); 考虑到runner是一个Runner*类型的指针（实际上，runner是由GPUServer的一个私有数据runner_初始化得到的，而runner_虽然是Runner类型，但是却被初始化了GPURunner类型（这里存在一个类的多态机制），所以可以定位到GPURunner的RunPreSc方法 在RunPreSc中，关键操作是op_factory_[i]-\u003erun(op_params_[i]);，其中op_factory_是GPURunner中的一个私有包含Operator*类型变量的容器，因此定位到Operator.h/cu 对于Operator的设计思想是，首先我们仅阐述一下它是怎么做的，至于为何采用这种方式暂时还不太清楚。它创建了一个操作类，对于操作这个对象来说，run就是它的一个方法。然后去创建了不同的操作，都继承这个原始操作类。关于这一点，可以从Server.cu的Initialize()对op_factory_进行初始化的代码中可以看出 开始探究涉及到的几个操作的作用，首先是Batch_Generator。从Operator.cu中看到Batch_Generator重写的run方法中关键操作是batch_generator_kernel，由此定位到Kernel.cu 进行到这一步，很难再继续往下走了，因为都是具体函数的实现。我们从函数追踪这个思路中跳出来，回到Server.cu-\u003ePreSc-\u003ePreSCLoop-\u003eRunPreSc-\u003eop_factory_[i]-\u003erun(op_params_[i]);,然后回到op_factory_的初始化上，发现它初始化时的操作顺序是BatchGenerator-\u003eFeatureExtractor-\u003e(RandomSampler-\u003eFeatureExtractor-\u003eRandomSampler-\u003eFeatureExtractor-\u003e … -\u003eRandomSampler-\u003eFeatureExtractor)-\u003eCachePlanner-\u003eCacheUpdater 在RunPreSc中，从第0个操作开始执行，然后每次递增2，所以对应到的操作依次是BatchGenerator-\u003eRandomSampler-\u003eRandomSampler-\u003e … -\u003e CachePlanner-\u003eCacheUpdater。在看论文时，理解的是在每次采样之前都会进行一次shuffle从而生成一个batch，如果真的是按照上面这个执行流，那有可能是在BatchGenerate阶段把后续所需要使用的batch都一同生成了 项目源码中的pcm文件夹就是intel开源的pcm项目，代码中所需的性能监控由pcm提供 ","date":"2024-03-05","objectID":"/blog/posts/graph-computing/legion-source-code-analysis/:5:0","tags":null,"title":"Legion Source Code Analysis","uri":"/blog/posts/graph-computing/legion-source-code-analysis/"},{"categories":["C-C++"],"content":"Embellish Raw Pointer The collocation between const and original pointer is confused to many people. There are two usages of it. The key difference is that if the pointer is prohibited to modify or the data which is pointed by pointer is prohibited to modify. ","date":"2024-02-27","objectID":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/:1:0","tags":null,"title":"C C++ Const Keyword Unscramble","uri":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/"},{"categories":["C-C++"],"content":"Pointer To Const(指向常量的指针) The first one is a variable pointer that points a constant data. i.e. const int* p #include \u003ciostream\u003e int main() { int a = 1, b = 2; const int *p = \u0026a; p = \u0026b; // true *p = 3; // false return 0; } ","date":"2024-02-27","objectID":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/:1:1","tags":null,"title":"C C++ Const Keyword Unscramble","uri":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/"},{"categories":["C-C++"],"content":"Const Pointer(常量指针) The second one is a contant pointer that points a variable data. i.e. int* const p #include \u003ciostream\u003e int main() { int a = 1, b = 2; int* const p = \u0026a; p = \u0026b; // false *p = 3; // true return 0; } There is a good way to distinguish these two usages. You can judge them by the position of const and *. If the const locates the left of the *, it means that the const keyword modifies the data *p, i.e. a constant data. If the const locates the right of the *, it means that the const keyword modifies the data p, i.e. a constant pointer. ","date":"2024-02-27","objectID":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/:1:2","tags":null,"title":"C C++ Const Keyword Unscramble","uri":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/"},{"categories":["C-C++"],"content":"Embellish C++ Reference In addition, const can also collocates with C++ reference. But there is a litter difference between them. That is because the difference between pointer and reference, which is that you can modify pointer pointing later, but you can’t modify a reference pointing, which is decided by C++ grammar. A reference must be initialize when we declare it, we can’t declare it firstly and then define it, e.g. we can’t modify a reference pointing later. So there is no such situation that we modify the reference. We can just modify the data which is pointed by the reference. Therefore, there is only one usage of reference, that is the const locates the left of the \u0026. i.e. const int \u0026p or int const \u0026p, which means we can’t modify the data which pointed by the reference. ","date":"2024-02-27","objectID":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/:2:0","tags":null,"title":"C C++ Const Keyword Unscramble","uri":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/"},{"categories":["C-C++"],"content":"Embellish Member Function Of Class Although we say the const is used to embellish the mumber function of class, in essence, it embellish the this pointer of this class. There is a tacit fact, this is a const pointer. For example, the this pointer of class Animal is Animal* const. We can’t let a non-const pointer to point to a const data, so some const object can’t invoke some non-const member functions, so we add a const qualifier after the parameter list to edit the this pointer to become a pointer to const. e.g. const Animal* const. Class Animal { public: int get_number() const { } }; ","date":"2024-02-27","objectID":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/:3:0","tags":null,"title":"C C++ Const Keyword Unscramble","uri":"/blog/posts/c-c++/c-c++-const-keyword-unscramble/"},{"categories":["HPC"],"content":"Law 并行计算领域的两个关键定律就是 Amdahl 和 Gustafson，从不同角度诠释了 加速比 与 系统串行化程度、CPU核心数 之间的关系 ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:1:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"The difference between Amdahl’s Law and Gustafson’s Law The reason for the discrepancy between the speed up predictions by the two laws is that1: Gustafson’s Law assumes that the amount of work to be done increases as the number of processor increases! Amdahl’s Law, on the other hand, assumes the amount of work to be done is static no matter how much parallelization is available. 简单来说，就是 Amdahl 认为工作负载是不变的，但是 Gustafson 认为工作负载是变化的。 由于在 Amdahl 的假设中，工作负载不变，那么在计算加速比时就可以以加速前的时间处于加速后的时间 由于在 Gustafson 的观点中，工作负载是变化的，所以计算加速比更好的方法是通过比较相同时间处理的数据量 假设基准工作量是 1，并行比例是 f，串行比例是 1-f，则加速前并行部分工作量为 f，串行部分工作量为 1-f，加速后并行部分工作量为 f * p（p是处理器数量，因为是并行，所以不同处理器可以同时完成工作），串行部分工作量不变仍为 1-f（由于是串行，即使处理器增多也需要逐一执行，所以完成的工作量不变） 因此 Gustafson 定律得出的加速比为 $speedup = \\frac{(1-f) + f \\times p}{(1 -f) + f}$ ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:1:1","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Contradiction 根据 Amdahl，即使处理器数量无限增大，加速比是存在一个上限的。但是 Gustafson 得出的结论却是 随着处理器数量增大，加速比可以无限增大。 两个定律的结论不同，这是不是说两个定律中有一个是错误的呢，其实不然，两者的差异其实是因为这两个定律对一个客观事实从不同角度去审视的后果，他们的侧重点不同。2 Amdahl强调，当串行化比例一定时，加速比是有上限的，不管你堆叠多少个CPU参与计算，都不能突破上限。 而Gustafson 定律的出发点不同，对Gustafson定律来说，如果可被并行化的代码所占比例足够大，那么加速比就能随着CPU的数量线性增长。 所以这两者并不矛盾，从极端的角度来说，如果系统中没有可以被并行化的代码，那么对于两个定律，其 加速比是1，反之，如果系统中可被并行化的代码比例100%，那么两个定律得到的加速比都是处理器个数。 ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:1:2","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Motivation Moores’s Law states that, when the price remains constant, the number of components per chip that can be accommodated approximately doubles every 18-24 months, leading to a corresponding doubling of performance. The phenomenon of failure of Moores’s Law means that now we use more transistors to increse core number instead of frequency per chip(performance per chip). So it is the developing tendency that how to use multi-cores to complete the computation tasks now, which is called parallel-computing. ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:2:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Classification ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:3:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Shared Memory Parallel Programming Manual: multi-threading Automatic: OpenMP ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:3:1","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Distributed Memory Parallel Programming Message passing: e.g. MPI 并行编程模型和并行计算机的底层硬件结构是相互对应的，是有一种硬件结构从而对应到一种并行编程模型，对应关系如下： 如何理解编程模型所处的层次结构 以下图多线程编程模型为例，编程模型层或者说抽象层给使用者提供的接口就是“线程”，向底层则对应到pthread等多种类型的多线程库实现，再向下则是OS系统调用API，然后到达硬件层 ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:3:2","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Programming model Definition It is made of languages and libraries that create abstract view of the machine. The key concepts for creating a parallel programming model: ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:4:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Performance Evaluation Two important factor: what needs to be done what it costs to do it ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:5:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Data Parallel 一般认为，向量化 和 并行 还是有一点差别的，并行更多强调的是线程级或者说核一级的并行，向量化指代的更多是在一个核心上通过向量化指令和底层支持向量化的硬件结构实现的SIMD ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:6:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Example High-Performance Matrix Multiplication AMDAHL VS. GUSTAFSON ↩︎ Whether the Amdahl’s law and Gustafon’s law contradict each other? ↩︎ ","date":"2024-01-29","objectID":"/blog/posts/hpc/parallel-computing/:7:0","tags":null,"title":"Parallel Computing","uri":"/blog/posts/hpc/parallel-computing/"},{"categories":["HPC"],"content":"Usage ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:1:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Install \u0026 CMake cd some_software-1.4.2 mkdir build cd build cmake .. cmake --build . # It is equivalent to make cmake --build . --target install # It is equivalent to make install After the above flow, we can use Kokkos by CMake directly. ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:1:1","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Source Code \u0026 CMake1 file sturcture: . ├── CMakeLists.txt ├── kokkos-4.1.2 ├── main.cpp └── Makefile # CMakeLists.txt 内容 cmake_minimum_required(VERSION 3.16) project(Example CXX) # add_subdirectory(/home/hongyu_gao2001/kokkos/kokkos-tutorials/Exercises/01/My/kokkos /home/hongyu_gao2001/kokkos/kokkos-tutorials/Exercises/01/My/build/kokkos) add_subdirectory(/home/hongyu_gao2001/kokkos/kokkos-tutorials/Exercises/01/My/kokkos-4.1.2) add_executable(example main.cpp) target_link_libraries(example kokkos) 有几个注意事项： add_subdirectory有两个形式。这两个形式有两个关键的不同点，一是第一个参数不同，二是是否存在第二个参数。第二个参数的作用是指明输出的路径，如果没有此参数，则输出的名称和第一个参数相同。关于这个名称，我以为会和target_link_libraries的第2个参数相关，但是即使不同也可以正常编译 正如上面所提到的，target_link_libraries的第2个参数，目前不知道是和什么相关的，不知道是写明在项目哪里的 在官方给出的指示中，提到了另一个语句include_directories(${Kokkos_INCLUDE_DIRS_RET})，但是我通过MESSAGE( STATUS \"${Kokkos_INCLUDE_DIRS_RET}\")发现此变量为空，但是编译并没有报错，在一篇博客中发现一个可能的原因是target_link_directories链接的库包含了头文件，所以这里不添加也可以2 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:1:2","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Source Code \u0026 Raw Makefile There is a confused point: How to chose the right backend? If we use the makefile which is provided by Kokkos-tutorials we can edit the KOKKOS_DEVICES. But we don’t know what does this option do. When we use g++ -I -L -l to compile code, even though we can get the executable file, but we can’t get the ideal execute performance. 目前对于 Kokkos 是如何调用 backend 的接口这件事情存有疑问，尚不明确 kokkos-tutorials/Exercises 中给出的各个示例中的 Makefile 具体都做了哪些工作，从而使得可以正常使用各种 hetetogenous backends(因为他们都包含一个include $(KOKKOS_PATH)/Makefile.kokkos, 目前还不太清楚这个文件具体都完成了什么工作). 因为直接使用 g++ 进行编译似乎无法达到这种效果。 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:1:3","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Initialization An important thing which initialization progress does is initializing Kokkos::DefaultExecutionSpace; and Kokkos::DefaultHostExecutionSpace;. 3 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:2:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"对于Kokkos-core源代码结构的理解 注意只是对core这一部分的理解，从项目结构上可以看出，除了core这一部分外，还存在着例如algorithm, containers 和 simd等其他部分，其他部分也存在相关的代码。 在core/src下有一部分独立的文件，其中包含了最核心的Kokkos_Core core/src下的文件夹，每个都对应了一个目标平台，起点是core/src/fwd文件夹，里面包含了涉及到不同目标平台的一些前向声明内容，主要是不同目标平台类的声明 “Fwd” 在这里通常是\"forward\"的缩写，用于表示前向声明（forward declaration）。在C++中，前向声明是一种声明但不定义实体的技术。这通常用于避免引入完整的定义，从而提高编译速度和减少依赖关系。 以Kokkos::Serial为例, 前向声明内容为： namespace Kokkos { class Serial; ///\u003c Execution space main process on CPU. } // namespace Kokkos 然后各个同名文件夹的则是对不同目标平台下涉及到的内容的具体定义 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:3:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"DefaultExecutionSpace 关于DefaultExecutionSpace的定义：在core/src/Kokkos_Core_fwd.hpp中，需要根据编译选项来确定 和宏定义相关的一个文件: Kokkos_Macros.hpp 关于文档中，下面这句话的代码表述如以下代码所示Kokkos::DefaultExecutionSpace is an alias of ExecutionSpace() type pointing to an ExecutionSpace based on the current configuration of Kokkos. DefaultExecutionSpace是具体目标平台的别名，通过配置项结合预编译指令实现到具体平台的映射。 DefaultExecutionSpace还影响到了默认的memory space。在KokkosTutorial_02_ViewsAndSpaces.pdf中给出了如下观点 Each execution space has a default memory space 使用默认memory space等价于指定memory space为Kokkos::DefaultExecutionSpace::memory_space(这一点在API文档的View中给出的，这是合理的，因为就是在创建View时才需要指定memory space) 初次看到Kokkos::DefaultExecutionSpace::memory_space来指定默认memory space是有些疑惑的，想象中的做法是应该像execution space一样存在一个Kokkos::DefaultMemorySpace，但是memory的属性却是放在execution属性下面的。结合前面所说的，这样做是合理的，之前说每一个execution space都对应一个默认的memory space，就是通过这种方式实现的。 #if defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_CUDA) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Cuda; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_OPENMPTARGET) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Experimental::OpenMPTarget; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_HIP) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = HIP; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_SYCL) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Experimental::SYCL; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_OPENACC) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Experimental::OpenACC; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_OPENMP) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = OpenMP; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_THREADS) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Threads; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_HPX) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Kokkos::Experimental::HPX; #elif defined(KOKKOS_ENABLE_DEFAULT_DEVICE_TYPE_SERIAL) using DefaultExecutionSpace KOKKOS_IMPL_DEFAULT_EXEC_SPACE_ANNOTATION = Serial; ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:4:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"KOKKOS_DEVICES的内容到底影响了什么 以Serial为例，如果在KOKKOS_DEVICES中未添加Serial，但是在代码中使用了Kokkos::Serial会报错 加上之后，编译包含main的文件的编译命令的-I选项并没有发生变化，只是多编译了2个和Serial有关的cpp文件。 所以只是影响了链接过程，但是头文件的问题是如何解决的 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:5:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Parallel Loop Body ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:6:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Functor A functor is one way to define the body of a parallel loop. It is a class or struct1 with a public operator() instance method. Use the KOKKOS_INLINE_FUNCTION or KOKKOS_INLINE macro to mark a functor’s methods that Kokkos will call in parallel 在Kokkos_Macros.hpp中 #define KOKKOS_INLINE_FUNCTION KOKKOS_IMPL_INLINE_FUNCTION #if !defined(KOKKOS_IMPL_INLINE_FUNCTION) #define KOKKOS_IMPL_INLINE_FUNCTION inline #endif 在KokkosTutorial_02_ViewsAndSpaces.pdf中有一点介绍，上面的代码找的应该是不全，实际会根据其他宏的内容还存在修改 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:6:1","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Lambda Use the KOKKOS_LAMBDA macro to replace a lambda’s capture clause when giving the lambda to Kokkos for parallel execution. KOKKOS_LAMBDA is the same as [=] 体现在Kokkos_Macros.hpp 中 #if !defined(KOKKOS_LAMBDA) #define KOKKOS_LAMBDA [=] #endif ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:6:2","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Lambda 为何采用 value-copy4 portability In particular, the functor might need to be copied to a different execution space than the host. For this reason, it is generally not valid to have any pointer or reference members in the functor. correctness Capturing by reference allows the programmer to violate the const semantics of the lambda. // TODO // 如何理解? Capturing by reference enables many more possibilities of writing non-threads-safe code int val = 0; Kokkos::parallel_for(\"for\", 10, [\u0026](const int i) -\u003e void { val += i; }); std::cout \u003c\u003c val \u003c\u003c std::endl; The right result is $55$, because parallel_for is asynchronous, so the val += i is non-thread-safe. ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:6:3","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"parallel_reduce 根据目前的理解，parallel_reduce可以解决在parallel_for中需要使用 capture-by-reference 但是又存在 non-thread-safe 的问题。 核心执行方式为：each iteration produces a value and these iteration values are accumulated into a single value with a user-specified associative binary operation5 这句话中有两个重点： “a single value”，这代表着 parallel_reduce 参数中的 result，也就是最后结果存储的位置 “a user-specified associative binary operation”，这代表着 parallel_reduce 参数中的 reducer，目前理解就是表示执行方式 相较于 paralle_for，lambda 中参数发生了变化:6 The first argument is the parallel loop “index”，这点没变化 The second argument is a non-const reference to a thread-local variable of the same type as the reduction result. （其中的重点已经加粗） 这是一段计算 $A * x * y$ 的代码，其中 $A$ 是 $N * M$ 的矩阵，$x$ 是 $M * 1$ 的矩阵，$y$ 是长度为 $N$ 的系数矩阵 for ( int i = 0; i \u003c N; ++i ) { double temp2 = 0; for ( int j = 0; j \u003c M; ++j ) { temp2 += A[ i * M + j ] * x[ j ]; } result += y[ i ] * temp2; } 当采用 parallel_for 时，需要采用 capture-by-reference，这将会导致 non-thread-safe问题，最终的结果会出现错误，代码如下所示 Kokkos::parallel_for(\"compute\", N, [\u0026](const int j) -\u003e void { double temp2 = 0; for (int i = 0; i \u003c M; i++) { temp2 += A[j * M + i] * x[i]; } result += y[j] * temp2; }); 得到正确结果的方案是采用 parallel_reduce，代码如下所示 Kokkos::parallel_reduce(\"matrix multiplication\", N, KOKKOS_LAMBDA (const int j, double \u0026update) -\u003e void { double temp2 = 0.0; for (int i = 0; i \u003c M; i++) { temp2 += A[j * M + i] * x[i]; } update += y[j] * temp2; }, result); ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:7:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"parallel_reduce thread-safe 的实现机理 The source code is located in core/src/Kokkos_Parallel_Reduce.hpp ParallelReduceReturnValue相关声明和定义（为了便于区分不同类型，将结构体内容删除，仅留下模版参数）： template \u003cclass T, class ReturnType, class ValueTraits\u003e struct ParallelReduceReturnValue; template \u003cclass ReturnType, class FunctorType\u003e struct ParallelReduceReturnValue\u003c std::enable_if_t\u003cKokkos::is_view\u003cReturnType\u003e::value\u003e, ReturnType, FunctorType\u003e {}; template \u003cclass ReturnType, class FunctorType\u003e struct ParallelReduceReturnValue\u003c std::enable_if_t\u003c!Kokkos::is_view\u003cReturnType\u003e::value \u0026\u0026 (!std::is_array\u003cReturnType\u003e::value \u0026\u0026 !std::is_pointer\u003cReturnType\u003e::value) \u0026\u0026 !Kokkos::is_reducer\u003cReturnType\u003e::value\u003e, ReturnType, FunctorType\u003e {}; template \u003cclass ReturnType, class FunctorType\u003e struct ParallelReduceReturnValue\u003c std::enable_if_t\u003c(std::is_array\u003cReturnType\u003e::value || std::is_pointer\u003cReturnType\u003e::value)\u003e, ReturnType, FunctorType\u003e {}; template \u003cclass ReturnType, class FunctorType\u003e struct ParallelReduceReturnValue\u003c std::enable_if_t\u003cKokkos::is_reducer\u003cReturnType\u003e::value\u003e, ReturnType, FunctorType\u003e {}; 从后续函数模版parallel_reduce的实现中，不难看出，parallel_reduce去调用了两个函数: Impl::ParallelReduceAdaptor\u003cpolicy_type, FunctorType, ReturnType\u003e::execute() Impl::ParallelReduceAdaptor是一个struct,其中包含了 template \u003ctypename Dummy = ReturnType\u003e static inline std::enable_if_t\u003c!(is_array_reduction \u0026\u0026 std::is_pointer\u003cDummy\u003e::value)\u003e execute(const std::string\u0026 label, const PolicyType\u0026 policy, const FunctorType\u0026 functor, ReturnType\u0026 return_value) { execute_impl(label, policy, functor, return_value); } std:;enable_if_t作用为条件编译，大致可以理解为只有在满足条件时才会示例化此函数模版，主要用于为函数重载提供便利 从execute_impl会导向具体 backend 的 Impl::ParallelReduce 的实现 以上整体的调用流程如下： Kokkos_Parallel_Reduce.hpp 的 parallel_reduce （入口） Kokkos_Parallel_Reduce.hpp 的 Impl::ParallelReduceAdaptor::execute() (看为execute的声明) 2.1 Kokkos_Parallel_Reduce.hpp 的 Impl::ParallelReduceAdaptor::execute_impl() (看为execute的定义) 2.1.1 不同 backend 下的 Impl::ParallelReduce (从 execute_impl 到不同的 backend 实现机理？依靠模版类中模版参数不同对应到不同的模版类中？) Impl::ParallelReduceFence::fence() 从 Impl::ParallelReduceAdaptor::execute_impl() 转到正确 backend 下的 Impl::ParallelReduce，在模版参数上有一个关键点是 Impl::FunctorPolicyExecutionSpace\u003cFunctorType, PolicyType\u003e::execution_space 这一内容位于 Kokkos_Parallel.hpp 中的 struct FunctorPolicyExecutionSpace，其中包含对于 execution_space 的下述表述 using execution_space = detected_or_t\u003c detected_or_t\u003c std::conditional_t\u003c is_detected\u003cdevice_type_t, Functor\u003e::value, detected_t\u003cexecution_space_t, detected_t\u003cdevice_type_t, Functor\u003e\u003e, Kokkos::DefaultExecutionSpace\u003e, execution_space_t, Functor\u003e, execution_space_t, Policy\u003e; 我们最后可以得到一个结论：kokkos的规范侧重于声明和定义分离。parallel_reduce的实现中包含一个 ParallelReduceAdaptor 和 ParallelReduce，之所以叫为 Adaptor，现在看来是实现了一个任务分发的工作，先把任务集中于此，然后派发到不同的 backend 下 Impl::ParallelReduceFence\u003ctypename policy_type::execution_space, ReturnType\u003e::fence() ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:7:1","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"疑惑/可能的改进点 Kokkos代码中存在着大量的例如#ifdef这类的预处指令，Kokkos本身的可移植恰恰是通过这一点实现的（想要做到可移植，抽象是必须的，要在多种不同的硬件之上构建起一个逻辑层，在抽象层之下，需要解决的就是编译问题，例如使用Openmp和使用Cuda，编译器和编译选项显然是存在区别的，Kokkos解决这个问题的方法就是通过各种宏，首先通过配置项生成宏，然后宏会渗入到cpp代码当中，根据宏对类型等内容进行选择）。问题在于很多代码的宏定义之间甚至存在逻辑关系，这这给代码带来的极大的不易读性，因为代码的真实执行逻辑取决于宏的定义，在没有执行的情况下想要理清逻辑，甚至需要手动推导宏。 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:8:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"关于异步机制的疑问 遇到问题的场景是这样的： 正在尝试使用View和Mirror，下述代码可以正常编译，但是运行时会报错 terminate called after throwing an instance of ‘std::runtime_error’ what(): Kokkos allocation “d_x” is being deallocated after Kokkos::finalize was called Aborted (core dumped) 意思就是，在Kokkos::finalize调用之后，又去销毁d_x对应的存储空间。很自然就能够想到是同步的问题，因此查询文档，找到Kokkos::fence()同步函数。 但是使用函数之后，依然会报这个错误 文档中这样描述这个函数 Blocks on completion of all outstanding asynchronous Kokkos operations. 后来想明白之后，猜测它这个同步，只是保证了在其他设备中的操作完成了，但是同步之后存储资源仍然是没有销毁的，所以仍然会导致上述问题。 想要解决，就需要保证在Kokkos::fence()之前把对应的存储资源销毁，但是从示例代码中并没有看到相关的API，那么这个过程应当是自动完成的。所以就可以利用作用域这个机制来实现了。 #include \u003cKokkos_Core.hpp\u003e int main(int argc, char **argv) { Kokkos::initialize( argc, argv ); { int N = 2; Kokkos::View\u003cint *, Kokkos::Cuda::memory_space\u003e d_x(\"d_x\", N); Kokkos::View\u003cint *, Kokkos::Cuda::memory_space\u003e::HostMirror h_x = Kokkos::create_mirror_view(d_x); Kokkos::parallel_for( \"Loop in CPU\", Kokkos::RangePolicy\u003cKokkos::Serial\u003e( Kokkos::Serial(), 0, N ), KOKKOS_LAMBDA(int i) { h_x(i) = 1; } ); Kokkos::deep_copy(d_x, h_x); Kokkos::parallel_for( \"Loop in GPU\", Kokkos::RangePolicy\u003cKokkos::Cuda\u003e( Kokkos::Cuda(), 0, N ), KOKKOS_LAMBDA(int i) { d_x(i) = 1; printf(\"%d \", d_x(i)); } ); std::printf(\"\\n\"); // Kokkos::fence(); // 同步 } Kokkos::finalize(); return 0; } 在Kokkos中哪些操作是异步的，在fence这里有提到一些 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:9:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"deep_copy core/src/Kokkos_CopyViews.hpp下包含多种inline void deep_copy(){} 部分deep_copy(){}调用了Kokkos::Impl::DeepCopy DeepCopy似乎是一个struct，可查询struct DeepCopy 此结构体的声明和定义出现在Kokkos_Core_fwd.hpp以及不同目标平台文件夹下的xxx_DeepCopy.hpp中 ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:10:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["HPC"],"content":"Reference Using Kokkos in-tree build ↩︎ 为何不用显示调用target_include_directories ↩︎ initialization aliases ↩︎ Kokkos semantics to capture by value [=] ↩︎ Parallel_reduce执行方式 ↩︎ two arguments of lambda ↩︎ ","date":"2024-01-05","objectID":"/blog/posts/hpc/kokkos-source-code-analysis/:11:0","tags":null,"title":"Kokkos Source Code Analysis","uri":"/blog/posts/hpc/kokkos-source-code-analysis/"},{"categories":["Compile-Link"],"content":"名词辨析 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:0","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"GNU GNU’s Not Unix!的递归缩写 一个自由的操作系统,起源于GNU计划,希望发展出一套完整的开放源代码操作系统来取代Unix 基本组成包括： GNU编译器套装（GCC） GNU的C库（glibc） GNU核心工具组（coreutils） ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:1","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"GCC GNU Compiler Collection, GNU编译器套装，最初是为了GNU操作系统而编写的编译器。 有多种语言前端，可用于解析不同的编程语言、操作系统、计算机系统结构，是GNU计划的关键部分，也是GNU工具链的主要组成部分之一 可以编译C、C++、JAV、Fortran、Pascal、Object-C、Ada，Go等语言 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:2","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"gcc/g++/MinGW gcc: GCC中的GUN C Compiler（C 编译器） g++: GUN C++ Compiler（C++编译器） MinGW: Minimalist GNU for Windows，是将GCC编译器和GNU Binutils移植到Win32平台下的产物 但根据GCC的gcc和g++区别的说法，gcc和g++并不是编译器，它们只是一种驱动器1，它们会根据参数中要编译的文件的类型，调用对应的GUN编译器。以编译C语言为例，包含以下过程。 Step1：Call a preprocessor, like cpp. Step2：Call an actual compiler, like cc or cc1. Step3：Call an assembler, like as. Step4：Call a linker, like ld 因此gcc命令只是上述后台程序的包装，根据不同的参数调用不同的程序，例如预编译程序、编译器、汇编器和链接器 两者的联系和区别2 对于 *.c文件，gcc当做c文件看待，g++当做cpp文件看待 虽然gcc和g++都可以编译*.c文件，但是二者会以不同的语言来对待c文件，而C++ 标准和 C 语言标准的语法要求是有区别的。 #include \u003cstdio.h\u003e int main() { const char * a = \"abc\"; printStr(a); return; } int printStr(const char* str) { printf(str); } 以上代码使用gcc进行编译，其会看为c语言，编译结果为 以上代码使用g++进行编译，其会看为c++，编译结果为 由此可见，c++的语言要求会更高一些 对于 *.cpp文件，gcc当做cpp文件看待，g++当做cpp文件看待 虽然二者都会以cpp文件来对待，但是对于调用某些标准库中现有的函数或者类对象的c++程序，而单纯的 gcc 命令无法自动链接这些标准库文件，无法完成编译，需要手动链接 C++ 标准库，例如 gcc -lstdc++ ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:3","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"MSVC Microsoft Visual C++，is a compiler for the C, C++ and C++/CX programming languages by Microsoft ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:4","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"LLVM LLVM最初是指Low Level Virtual Machine，是类似但不同于jvm的一种虚拟机，现在来说，有很多理解方式，可以说LLVM是编译器的工具链的集合，Clang是使用LLVM的编译器；又或者说LLVM是一个优秀的编译器框架，它也采用经典的三段式设计 根据编译原理可以了解到，在GCC中前端和后端的分界并非明显，这就导致出现下面的情况，一种语言的前端对对应多个后端 而LLVM架构通过引入LLVM IR(Intermediate Representation)解决了这一问题，形成的LLVM架构如下图所示 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:5","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"clang/clang++ 是LLVM项目中的一个子项目，是基于LLVM架构的轻量级编译器，属于整个LLVM架构中的编译器前端(由LLVM架构图可得知) 创造目的是为了替代GCC，提供更快的编译速度 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:6","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"Make make工具可以看成是一个智能的批处理工具，它本身并没有编译和链接的功能，而是用类似于批处理的方式—通过调用makefile文件中用户指定的命令利用gcc(或g++)来进行编译和链接。当程序只有一个源文件时，可以直接使用用gcc(或g++)命令进行编译。但当程序包含多个源文件时，逐文件去编译，编译顺序可能出现混乱同时工作量较大 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:7","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"CMake makefile在一些简单的工程中可以人工书写，但当工程较大时，手写makefile较为麻烦，同时更换平台需要修改makefile,cmake工具可以根据CMakeLists.txt文件去生成makefile，过程如下图所示 More details can be found in CMake Knowledges Summary 参考 [1] GNU的发展史 [2] GCC的gcc和g++区别 [3] 编译器 cc、gcc、g++、CC 的区别 [4] Linux环境中gcc和g++的区别详解 [5] GCC、LLVM、Clang区别 [6] 业界主流3大编译器 [7] 区分gnu的gcc/g++, mingw/msvc, llvm的clang/clang++, make,cmake [8] LLVM架构(相关资料) [9] CMake入门 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:8","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"Ninja Ninja 同 Make 一样都属于构建系统，最大的特点是构建速度快。同时其也可与CMake结合使用，使用流程如下图所示: ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:1:9","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"编译流程 以gcc为例 集成开发环境一键式完成的过程，将编译和链接进行合并，此过程称为构建（Build） 关于编译选项的详细解释见 GCC online documentation -\u003e GCC Manual -\u003e GCC Command Options 实际上，对于实际流程而言，在链接之后还需要进行加载，将可执行文件放置到内存以执行，完整流程如下图所示 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:0","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"预处理(预编译) 头文件包含: 处理 #include 条件编译: 处理 #if, #else, #endif 等等条件编译指令 宏替换: 处理#define, 将宏展开 删除注释 cpp hello.c \u003e hello.i gcc -E hello.c -o hello.i 若要检查宏定义或头文件包含是否正确时，可查看预编译后的文件 使用file命令可以查看预处理后文件类型如下： main.i: C source, ASCII text ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:1","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"编译 词法，语法，语义分析，生成汇编代码 gcc -S hello.i -o hello.s gcc -S hello.c -o hello.s 使用file命令可以查看编译后文件类型如下： main.s: assembler source, ASCII text ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:2","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"汇编 将汇编语言转化为相应的机器语言(二进制目标文件) as hello.s -o hello.o gcc -c hello.s -o hello.o gcc -c hello.c -o hello.o 使用file命令可以查看汇编后文件类型如下： main.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped 注：关于\"not stripped\"，和strip命令有关，表示没有Removes symbols and sections of files. ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:3","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"链接 Due to the complexity of the process of program linking, we will introduct it in a separate article. ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:4","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"加载 加载器（loader）把所有的可执行文件放到内存中执行 对于静态链接生成的可执行文件，shell 首先会通过 execve 启动程序，然后由操作系统内核将执行所需的数据加载到内存中。 对于动态链接生成可执行文件，似乎链接和加载是分界并非很明确的两个环节，从 man ld-linux 的结果来看： ld.so, ld-linux.so - dynamic linker/loader ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:2:5","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"Heterogeneous Compilation ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:3:0","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"ELF Structure .text: 源语⾔编译后形成的成机器代码 .data: ⼰初始化的全局变量和局部静态变量 .bss: 末初始化的全局变量和局部静态变量 .rodata: 只读数据段 .comment: 注释信息段 .note.GNU-stack: 堆栈提示段 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:3:1","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"Bundler The clang-offload-bundler tool may be used as part of the tool chain to combine these multiple code objects into a single bundled code object. ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:3:2","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"Reference [1] Clang vs Other Open Source Compilers [2] LLVM整体设计 [3] GCC vs. Clang/LLVM: An In-Depth Comparison of C/C++ Compilers [4] gcc Optimize Options [5] Linux下编译Opencv(备份) 关于驱动器的说法，目前只在gcc/g++链接选项一文中看到相关说法 ↩︎ 理清gcc、libc、libstdc++的关系 ↩︎ ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-compile/:4:0","tags":null,"title":"C C++ Compile","uri":"/blog/posts/compile-link/c-c++-compile/"},{"categories":["Compile-Link"],"content":"链接，将多个可重定位目标文件和标准库函数合并为可执行目标文件的过程，为了解决外部内存地址的依赖问题 在链接之前，各个程序模块都是相互独立的，模块A所使用到的模块B的内容，在模块A的视角下仅仅是一个符号，并不清楚其具体内容。链接过程可以理解为把模块B的内容结合到A中。整个过程类似搭积木最后的模块拼接过程。而这一拼接过程，采用专业术语来表达，即重定向。 静态链接 -\u003e 静态地址重定位， 地址在链接时就已经确定 动态链接 -\u003e 装载时地址重定位，地址在编译时是相对地址，具体的绝对地址在加载时由装载器（Loader）进行计算和修改 显示运行时链接 -\u003e 运行时地址重定位 需要注意的是，Windows 下的链接过程涉及的知识和 Linux 下并不完全相同，本文仅面向 Linux 下的链接过程 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:0:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Introduce to ELF ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:1:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"What is ELF ? ELF: Executable and Linkable Format, 可执行与可链接格式 ELF格式文件分类 文件类型 说明 实例 可重定位文件(Relocatable File) Linux的.o (对应Windows的.obj) 共享目标文件(Shared Object File) Linux的.so (对应Windows的.dll) 可执行文件(Executable File) Linux的/bin目录下的程序 (对应Windows的.exe) 核心转储文件(Core Dump File) 当进程意外终止时，系统将进程的地址空间的内容及终止时的信息转储到该文件中 Linux的core dump Note: The ELF (Executable and Linkable Format) file format corresponds to Linux, the PE (Portable Executable) file format corresponds to Windows and the Mach-O (Mach Object) corresponds to macOS. ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:1:1","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"How can we understand ELF ? A file A data structure which describes the initial state of state machine ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:1:2","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"What are the more important things in ELF ? When we use the static library, there are three important things in ELF we care: 1 code（代码） symbol（符号） relocate（重定位） When we use the dynamic library, in addition to the above content, there are two other important things in ELF. GOT(Global Offset Table) PLT(Procedure Linkage Table) ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:1:3","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Concept Ayalyze ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:2:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Library Classification 静态链接库：static library, 一种文件归档(archive). relocatable Files + 索引(index) -\u003e static library 静态链接库(libadd.a)的文件格式: libadd.a: current ar archive 动态链接库：shared library(Linux) / dynamic link library(Windows) 动态链接库(libadd.so)的文件格式： libadd.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=644e95c7d3f9bd18796622c3041e7653e402d179, not stripped 从本质上来说就是以上这两种，但是如果采用的链接方式是显示运行时链接，那么利用到的library又被称作dynamic loading library，使用的仍然是xxx.so文件，只是换了一种使用方式 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:2:1","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Linking Mode 静态链接：使用-static选项，仅使用静态链接器，在编译链接过程中就将其他模块装入可执行文件中 静态链接生成的可执行目标文件的文件格式： main: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, for GNU/Linux 3.2.0, BuildID[sha1]=65422291d167d002123191a5f63d9a5503d6d670, not stripped 动态链接：默认的链接方式, 同时使用静态链接器和动态链接器，动态链接器在运行前将共享模块装载进内存并进行重定位操作 动态链接生成的可执行目标文件的文件格式： main: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=3e226365a1d11bf52e8c7f5b4b9a72bbecbd7007, not stripped 显示运行时链接(Explicit Run-time Linking): 通过某些机制在运行时将共享模块装载进内存并进行重定位操作，让程序在运行时加载或卸载共享模块 关于library种类和链接方式之间的关系，容易产生的一个误解 静态链接库，动态链接库 和 静态链接，动态链接，这些名称很容易带给人一种误解: 采用静态链接库时采用的就是静态链接，使用动态链接库时采用的就是动态链接。 首先从链接方式的分类来说，静态还是动态链接是由编译选项-static决定的，并不是采用了静态链接库还是动态链接库决定的。 但是它们之间并不是没有关系，从另一个角度来说，根据GNU文档Options for Linking - static对于static选项的描述 prevents linking with the shared libraries 可以看出，当我们使用static选项进行静态链接时，使用的只能是静态链接库。 所以，关于库和链接方式的对应关系，需要从两个方向进行讲述： 使用静态链接库时，进行的可以是静态链接 或 动态链接； 使用动态链接库，只能进行动态链接 进行静态链接时，只能使用静态链接库；进行动态链接时，可以使用静态链接库或动态链接库 i.e. 使用静态链接库是进行静态链接的必要不充分条件, 使用动态链接库是进行动态链接的充分不必要条件 注：后半句的表述并不是非常准确，因为在现行系统下，进行动态链接都会利用到一个特殊的动态链接库-动态链接器，同时C/C++程序无论是否调用一些函数，都会链接libc.so(这一点判断还没有寻找确切的证据，仅是根据实际测试结果)，从这个角度来说，使用动态链接库是进行动态链接的充要条件，而上面的表述仅仅是为了表述库和链接方式的那2点对应关系，所以给出的是充分不必要条件 重新分析上述给出的那种误解，采用静态链接库时，如果没有给出-static选项，那么这时候进行的是动态链接，这正验证了使用静态链接库对于进行静态链接的不充分性 除了上述提出的各类问题，还会涉及到一个比较隐含的问题。上面提到使用静态链接库可以进行静态链接，但是在注中又提到一个事实，即虽然我们人为仅仅指定了一些静态链接库，但是背后会隐含利用一些特殊的动态链接库。动态链接库是不可以进行静态链接的，但是为何在进行静态链接时，这些特殊的动态链接库并没有报错。 事实上，这些动态链接库，都存在着与之对应的静态链接库，在我们添加-static选项后，链接使用的就是这些静态链接库。e.g. libc.so就存在一个libc.a的静态链接库（可通过命令find /usr/lib /usr/local/lib -name \"libc.a\"查找到） ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:2:2","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Static Library 静态链接是可执行目标文件在构建过程中完成的，使用链接器将多个.o可重定位目标文件结合（实际上也可以将.so动态链接库结合进来，在动态链接部分详细说明），生成可执行目标文件。 静态链接库：Windows平台.lib (library)，Linux平台.a (archive) 假设编写一个包含加法运算的静态链接库，供main函数调用 // add.cpp int fun(int a, int b) { return a + b; } // main.cpp #include \u003ciostream\u003e int fun(int, int); int main() { std::cout \u003c\u003c fun(1, 2) \u003c\u003c std::endl; return 0; } 使用ar命令将汇编过程生成的.o可重定位目标文件生成静态链接库 g++ -c add.cpp -o add.o ar -rsv libadd.a add.o ar -rsv: 以输出较多信息的方式，完成下述任务：创建归档文件的同时，创建归档索引 使用file命令可以查看生成的文件类型如下： libadd.a: current ar archive 在链接环节链接该静态链接库（假设libadd.o和main.cpp在同一路径下) g++ main.cpp -L. -ladd 以上就是一个创建及使用静态链接库的全流程。 值得注意的是Linux下静态链接库的本质，查询一下ar命令会发现，其不过是一个创建归档文件的命令，和目前的tar作用是类似的。 因此，所谓静态链接库不过是把一些.o可重定位目标文件集中起来放置到一个文件中，以便链接环节将各模块结合在一起。 不过tar和ar创建的归档格式并不相同，仅ar才能用于创建静态链接库。 为何要用.a这种归档格式作为静态链接库？ 把这些零散的目标文件直接提供给库的使用者，很大程度上会造成文件传输、管理和组织方面的不便，于是通常人们使用“ar”压缩程序将这些目标文件压缩到一起，并且对其进行编号和索引，以便于查找和检索，就形成了.a这种归档格式的静态库文件 tar创建的归档格式如下： libadd.a: POSIX tar archive (GNU) 静态链接库在构建过程中的参与情况示意图： 注：从图中也可以看出.a文件本身只是.o文件的一个容器，实际参与链接过程的仍然是.o可重定位目标文件 静态链接的缺点 静态链接是将所需的所有库文件内容进行整合，全部装入到可执行文件中，这种方式会带来以下两种问题： 内存和磁盘空间浪费严重：共用相同库文件的，不同的可执行程序中都存在着相同的库文件，如下图所示 程序更新不便：更新可执行程序所用的其中一个库文件需要重新下载整个可执行程序 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:3:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Shared / Dynamic Library 动态链接的动态指的是哪个环节是动态的？/ 什么是动态链接库？ 所谓动态链接，这里有两种不同的描述，在《程序员的自我修养-链接、装载与库》中的说法大概描述是：不在编译链接环节对那些组成程序的目标文件进行链接，而是等到程序运行时才进行链接“。但是根据下面的动态链接流程图，动态链接大致可以理解为：动态链接 = 编译链接环节的部分链接 + 程序运行时的完全链接。 我目前对这一点的理解是，编译链接环节的输出结果只是保存了程序需要使用到哪些库（也就是ldd能够查询到的那些），然后在程序运行过程中由动态链接器来完成实际的链接过程。所以说以上两种说法其实都没什么问题，真实链接的过程确实是在运行阶段由动态链接器完成的，但是编译链接环节确实也使用到链接器经历了一次链接环节，所以说成部分链接倒是也合理 动态链接库：Windows平台动态链接库.dll (dynamic link library)，Linux平台共享对象文件.so (shared object file) 仍然采用静态链接库的场景，构建动态链接库。 // add.cpp int fun(int a, int b) { return a + b; } // main.cpp #include \u003ciostream\u003e int fun(int, int); int main() { std::cout \u003c\u003c fun(1, 2) \u003c\u003c std::endl; return 0; } 创建动态链接库： 与创建静态链接库不同，由于静态链接库本质上就是可执行重定位文件的一个归档，因此必须首先生成.o。 动态链接库似乎经历了完整的构建流程，所以是对add.cpp还是对add.o都是可以的 g++ add.cpp -fpic -shared -o libadd.so 在链接环节链接该动态链接库（假设libadd.so和main.cpp在同一路径下) g++ main.cpp -L. -ladd ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:4:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Two linking processes 使用动态链接库和静态链接库的一个显著区别在于：使用静态链接库时，程序构建完成了就可以直接执行了，但是使用动态链接库，程序构建完成并不一定表示可以正常执行。 In other words, 程序构建和程序执行是两个显著分离的过程。 在静态链接库的链接过程中，使用的的命令是g++ main.cpp -L. -ladd。 同样的，在使用动态链接库时也一样可以使用这一条命令，程序可以正常构建。但是一旦执行程序，会报以下错误： ./main: error while loading shared libraries: libadd.so: cannot open shared object file: No such file or directory 通过ldd命令(MacOS下可以使用otool -L)检查可执行目标文件所需的动态链接库： linux-vdso.so.1 (0x00007ffe113c2000) libadd.so =\u003e not found libstdc++.so.6 =\u003e /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f4aa5de5000) libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007f4aa59f4000) libm.so.6 =\u003e /lib/x86_64-linux-gnu/libm.so.6 (0x00007f4aa5656000) /lib64/ld-linux-x86-64.so.2 (0x00007f4aa6370000) libgcc_s.so.1 =\u003e /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f4aa543e000) 可以发现，程序找不到libadd.so这一动态链接库。 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:4:1","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Why can’t dynamic linker find the library We have specify the search path of library using the option -L. when compiling, why does this error still occur? We mentioned above that using dynamic libraries is divided into two stages: the first is using static linker, the second is using dynamic linker. The compile command option -L. -ladd helps the static linker to find the libraries file, but it doesn’t work for dynamic linker. So, the first linking stage can complete successfully and the second linking stage will encounter “No such file or directory” error. ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:4:2","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"How dynamic linker find the library2 动态链接器搜索库文件的顺序如下： 1. 使用指定的路径名 对于最开始引入的动态链接库的应用示例，修改编译命令g++ main.cpp ./libadd.so -o main，此时在和libadd.so相同路径下即可正常执行可执行目标文件。通过ldd命令可以发现内容有所改变 linux-vdso.so.1 (0x00007fff8a570000) ./libadd_dynamic.so (0x00007f5421cea000) libstdc++.so.6 =\u003e /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f5421961000) libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007f5421570000) libm.so.6 =\u003e /lib/x86_64-linux-gnu/libm.so.6 (0x00007f54211d2000) /lib64/ld-linux-x86-64.so.2 (0x00007f54220ee000) libgcc_s.so.1 =\u003e /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f5420fba000) 关于这种方式的实现机理，通过 readelf -d main 命令可以查询到 ELF 文件的 .dynamic section 内容， 同 g++ main.cpp -o main 编译得到的文件的 readelf 命令的执行结果的关键差别如下所示： # g++ main.cpp -o main 结果 Tag Type Name/Value 0x0000000000000001 (NEEDED) Shared library: [libadd.so] # g++ main.cpp ./libadd.so -o main Tag Type Name/Value 0x0000000000000001 (NEEDED) Shared library: [./libadd.so] 2. 使用 DT_RPATH 中指定的目录 We can use compile option -Wl,-rpath,/custom/rpath/ to specify the path in the executable file for the dynamic linker. It is similar to the first method, because it affects the dynamic linker also with the help of ELF file format’s .dynamic section. We can use the command readelf -d \u003cbinary_name\u003e | grep 'R.*PATH' to verify it. 3. 使用环境变量 LD_LIBRARY_PATH 修改环境变量LD_LIBRARY_PATH（macOS下为DYLD_LIBRARY_PATH），将libadd.so所在路径添加到环境变量中 有几点注意事项： 根据Comparison of Shell Script Execution Modes的知识，可执行文件的执行会在子进程中进行，因此此处的变量需要设置为Environment/Global Variables以便子进程可以访问到。 在 macOS 下，DYLD_LIBRARY_PATH 无法被设置为环境变量，即执行env | grep DYLD_LIBRARY_PATH结果为空。对于这个奇怪的现象，在man dyld中有下面一则提示 Note: If System Integrity Protection is enabled, these environment variables are ignored when executing binaries protected by System Integrity Protection. 截止到更新此处内容时，还并没有尝试关闭 System Integrity Protection 来测试是否是这种安全机制导致的这种奇怪现象，目前暂且认为是如此。 4. 使用 DT_RUNPATH 中指定的目录 这种方式和滴2种方法有着一定联系，暂时没有遇到相关应用场景，暂时按下不表待后续完善 如果二进制文件中存在 DT_RUNPATH 动态段属性，则动态链接器会搜索这些目录。这些目录仅用于查找 DT_NEEDED（直接依赖项）条目所需的对象，不适用于这些对象的子对象，这些子对象必须自己有自己的 DT_RUNPATH 条目。这与 DT_RPATH 不同，后者适用于依赖树中所有子对象的搜索。 5. 从缓存文件 /etc/ld.so.cache 中搜索 按照目前理解，如果期望使用这种方式，需要首先将期望被搜索的路径添加到 /etc/ld.so.conf 文件中，然后通过 sudo ldconfig 构建出新的 /etc/ld.so.cache，然后 dynamic linker 就会根据 ld.so.cache 来进行搜索 由于未涉及到相关应用常见，此方法还未经测试，等待后续测试完善 6. 在默认路径中搜索 默认路径包括 /lib 和 /usr/lib（某些 64 位架构中，默认路径为 /lib64 和 /usr/lib64） 在上述示例中，把生成的libadd.so移动到/usr/local/lib等默认搜索路径（根据现有理解，make install所做的工作就是将相关文件复制到这些默认的搜索路径当中，但是个人并不是很推荐这种做法，因为直接采用默认搜索路径就类似黑盒，在不同设备中默认设置并不一定相同，显式给出各种信息会使得编译链接过程更加清晰明了） ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:4:3","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Summary 注：从图上也可以验证上述的说法，相较于静态链接库，动态链接库在构建过程和执行过程中都会发挥作用 静态链接器和动态链接器都分别完成了哪些工作 / 从动态链接的流程图中可以看出，xxx.so文件同时参与静态链接库和动态链接库两个链接过程，在这两个过程中这个library分别起到了什么作用? 答：假设程序P.cpp使用到了一个其他库中定义的函数fun()。当程序P.cpp被编译为P.o之后，编译器是不知道fun()函数的地址的。如果fun()是static library中的函数，那么静态链接器会根据所用的static library，直接将P.o中的fun()函数的地址进行重定位。如果fun()是shared library中的，那么静态链接器会将其标记为动态链接的符号，等到装载时由动态链接器完成重定位。可见，xxx.so需要被用到两次 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:4:4","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Archive [1] ELF文件格式解析(备份) [2] How to create and use program libraries on Linux [3] 一文读懂Linux下动态链接库版本管理及查找加载方式 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:5:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"Reference 静态链接和加载 | 南京大学操作系统设计与实现（蒋炎岩） ↩︎ Linux / Unix Command: ld.so ↩︎ ","date":"2023-12-31","objectID":"/blog/posts/compile-link/c-c++-link/:6:0","tags":null,"title":"C C++ Link","uri":"/blog/posts/compile-link/c-c++-link/"},{"categories":["Compile-Link"],"content":"What does compiler do ? Map the source program to a semantically equivalent target program. There are two stages in this mapping process: analysis: the frontend of compiler synthesis: the backend of compiler ","date":"2023-12-31","objectID":"/blog/posts/compile-link/compiler-principle/:1:0","tags":null,"title":"Compiler Principle","uri":"/blog/posts/compile-link/compiler-principle/"},{"categories":["Compile-Link"],"content":"词法分析（Lexical Analysis）： 将源代码转换为标记（token）序列，识别出代码中的基本单位（如关键字、标识符、常量、运算符等），并移除注释和不必要的空白字符。此过程可通过构造有限自动机来实现。 \u003ctoken-name, attribute-value\u003e example: 对赋值语句 position = initial + rate * 64 进行词法分析，形成词法单元序列 \u003cid, 1\u003e \u003c = \u003e \u003cid, 2\u003e \u003c + \u003e \u003cid, 3\u003e \u003c * \u003e \u003c64\u003e ","date":"2023-12-31","objectID":"/blog/posts/compile-link/compiler-principle/:2:0","tags":null,"title":"Compiler Principle","uri":"/blog/posts/compile-link/compiler-principle/"},{"categories":["Compile-Link"],"content":"语法分析（Syntax Analysis）： 根据语法规则检查标记序列是否符合编程语言的语法结构。将标记序列转换为语法树（Parse Tree）或者抽象语法树（Abstract Syntax Tree），以便后续阶段的处理。此过程可通过递归下降算法实现。 关于 AST 的一个生活化示例： 表达式：“我喜欢又聪明又勇敢的你”，语法分析的结果如下图所示： 对于词法分析一节给出的表达式，语法分析的结果如下图所示 从上图不难看出，AST 对应的就是中缀表达式，转换为这种格式更加便于计算机进行处理。 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/compiler-principle/:3:0","tags":null,"title":"Compiler Principle","uri":"/blog/posts/compile-link/compiler-principle/"},{"categories":["Compile-Link"],"content":"语义分析（Semantic Analysis）： 检查代码中的语义是否合法，即代码是否符合语言的语义规则。这包括类型检查、作用域检查、语义错误检查等，以确保代码在逻辑上是正确的。 消除语义模糊，生成属性信息标注在 AST 中，以便后续生成目标代码。 ","date":"2023-12-31","objectID":"/blog/posts/compile-link/compiler-principle/:4:0","tags":null,"title":"Compiler Principle","uri":"/blog/posts/compile-link/compiler-principle/"},{"categories":["Algorithm"],"content":"分类 队列式分支限界 优先队列式分支限界 ","date":"2023-12-26","objectID":"/blog/posts/algorithm/branch-bound-algorithm/:1:0","tags":null,"title":"Branch Bound Algorithm","uri":"/blog/posts/algorithm/branch-bound-algorithm/"},{"categories":["Algorithm"],"content":"定义状态转移方程的关键在于对状态做出完整表示，举个例子，最长上升子序列问题中，不同的状态是一些子序列，以子序列的最后一项作为划分依据就可以完整表示不同的状态 当然二维结构的理解起来不会这么直观，例如0/1背包，f[i][c]前i个物品且背包容量为c时的物品选择，不如一维结构的定义明了 ","date":"2023-12-26","objectID":"/blog/posts/algorithm/dynamic-programming/:0:0","tags":null,"title":"Dynamic Programming","uri":"/blog/posts/algorithm/dynamic-programming/"},{"categories":["Algorithm"],"content":"最优子结构证明 考虑解的形式 给出一个原问题的最优解，给出一个比原问题小一级问题的子问题，以及这个子问题的最优解 反证法，假设上面提到的这个子问题的解并非最优，存在一个更优的解 说明使用这个更优的子问题的解可以构造出一个更优的原问题的解，和最初的假设原问题的最优解矛盾,从而说明上面给出的子问题的解是最优的 ","date":"2023-12-26","objectID":"/blog/posts/algorithm/dynamic-programming/:1:0","tags":null,"title":"Dynamic Programming","uri":"/blog/posts/algorithm/dynamic-programming/"},{"categories":["Algorithm"],"content":"贪心策略正确性证明 ","date":"2023-12-24","objectID":"/blog/posts/algorithm/greedy-algorithm/:1:0","tags":null,"title":"Greedy Algorithm","uri":"/blog/posts/algorithm/greedy-algorithm/"},{"categories":["Algorithm"],"content":"归纳法 归纳法证明的核心逻辑：证明采用贪心策略执行到任意步数时获得的解都是最优解的一部分 数学表达: 算法执行到第k步时$(k \\in N^+)$，一定存在一个最优解包含这k步按照贪心策略选择的解 证明 k = 1时，一定存在一个最优解包含算法第一步的选择 假设存在一个最优解，其中第一步的选择与贪心算法的选择不同，然后根据题目条件证明将第一步的选择替换为算法的选择依然是一个最优解，这样就证明一定存在一个最优解包含了算法第一步的选择 k = m 时，假设命题成立，要证明 k = m + 1 时，命题成立 k = m 时，命题成立，那么可以得到一个包含贪心算法前 k 步选择的一个最优解，并且通过反证法可以证明当前解中剩余步骤得到的结果也是最优的 根据归纳假设，对于剩余的问题，一定存在一个最优解会包含贪心算法在第 m + 1 步的选择 对于剩余问题来说，上述得到的两个解都是最优解，因为可以用第2个包含贪心算法第m+1步选择的最优解去替换第一个最优解，这样就可以得到一个包含贪心算法在前m+1步选择的一个最优解，从而命题得证 形式化表达就是 $$ T = {贪心算法前m步的选择} \\cup T’ \\ T^* = {贪心算法第m+1步的选择} \\cup T’' $$ T’是剩余问题的一个最优解，$T^*$也是剩余问题的一个最优解，不过其包含了贪心算法在第m+1步的选择 既然都是最优解，那么就可以用$T^*$替换T‘，得到${贪心算法前m步的选择} \\cup {贪心算法第m+1步的选择} \\cup T’$这样一个包含贪心算法前m+1步选择的一个最优解，从而命题得证 ","date":"2023-12-24","objectID":"/blog/posts/algorithm/greedy-algorithm/:1:1","tags":null,"title":"Greedy Algorithm","uri":"/blog/posts/algorithm/greedy-algorithm/"},{"categories":["Algorithm"],"content":"交换论证法 证明的逻辑在于：要证明贪心策略是正确的，首先给出不符合贪心策略的解，通过交换某些元素使得解变得更优，说明重复操作下去最终得到的形式和贪心策略相符就证明了贪心策略是正确的 首先给出解的形式，以及最优化的度量值公式（例如要求最短时间，那么时间就是度量值） 给出一个非最优解的形式，计算非最优解的度量 交换非最优解中的某些元素，得到一个新的解，再次计算度量值 计算新的解和非最优解之间度量值的差值，说明新的解是更优的 说明如果可以进行这种交换，那么只要重复交换下去最终得到的最优解的形式和贪心策略相同 ","date":"2023-12-24","objectID":"/blog/posts/algorithm/greedy-algorithm/:1:2","tags":null,"title":"Greedy Algorithm","uri":"/blog/posts/algorithm/greedy-algorithm/"},{"categories":["Algorithm"],"content":"4 种递归式求解方法 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:0","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"代入法 猜测一个界，然后用数学归纳法证明这个界是正确的。 猜测解的形式 用数学归纳法求出解中的常数，并证明解是正确的 猜测解这个难度还是比较大的，所以从题目的角度来说，一般会设直接给出解，要求证明，例如下题 证明： $T(n) =2T(\\lfloor \\frac{n}{2} \\rfloor + 17) + n$ 的解为 $O(nlgn)$ 所以说，代入法更侧重是一种证明方法，而非求解方法 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:1","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"递归树法 将递归式转换为一棵树，其结点表示不同层次的递归调用产生的代价。然后采用边界和技术来求解递归式。 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:2","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"迭代法 本质上来说，迭代法可以看为一种特殊的递归树形式，求解过程并不会把树画出来，而是直接在公式推导中进行计算 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:3","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"主定理 求解形如 $T(n) = aT(\\frac{n}{b}) + f(n)$ 的递归式的界 在给出它的计算方法之前，首先对这一递归式的含义进行简要介绍: 规模为 n 的问题分解为 a 个子问题， 每个子问题规模为 $\\frac{n}{b}$, 其中 a 和 b 都是正常数。 a 个子问题递归地进行求解，每个花费时间 $T(\\frac{n}{b})$ 。函数 f(n) 包含了问题分解和子间题解合并的代价。 主定理： $$ T(n) = \\left{ \\begin{align} \u0026 \\Theta(n^{log_ba}), \u0026 \\exists \\ 常数 \\ \\varepsilon \u003e 0, 有f(n) = O(n^{log_ba - \\varepsilon}) \\ \u0026 \\Theta(n^{log_ba}lgn), \u0026 f(n) = \\Theta(n^{log_ba}) \\ \u0026 \\Theta(f(n)), \u0026 \\exists \\ 常数 \\ \\varepsilon \u003e 0, 有f(n) = \\Omega(n^{log_ba + \\varepsilon}), \\exists \\ c \u003c 1 有 af(\\frac{n}{b}) \\le cf(n) \\end{align} \\right. $$ 从上述内容不难看出，$f(n)$ 和 $n^{log_ba}$中的较大者决定了递归式的值。上述公式从上至下依次表示$f(n)$ \u003c, =, \u003e 三种情况 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:4","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"不同方法常用适用类型 使用代入法，则递归式一般是包含难以手工计算的因素，直接计算相对困难。 e.g. $T(n) =2T(\\lfloor \\frac{n}{2} \\rfloor + 17) + n$。携带下取整，这很难通过人工计算求解出一个具有固定形式的解 使用递归树，则递归式一般是会分出多个分支，一方面不适用于主定理，另一方面迭代法不便处理多个分支，因此通过树形来处理这种多分支。e.g. $T(n) = T(\\frac{n}{2}) + T(\\frac{n}{4}) + cn$ 使用迭代法，则递归式中子问题的规模一般呈常数量级减小，且不存在多个分支。e.g. $T(n) = T(n - 1) + \\frac{1}{n}$ 使用主定理，则递归式中子问题的规模一般呈倍数量级减小，且不存在多个分支。e.g. $T(n) = 2T(\\frac{n}{2}) + n^2logn$ 对于方法的选择，总结如下 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/divide-and-conquer-algorithm/:1:5","tags":null,"title":"Divide and Conquer Algorithm","uri":"/blog/posts/algorithm/divide-and-conquer-algorithm/"},{"categories":["Algorithm"],"content":"渐进符号及相应定理 $O$ $f(n)=O(g(n))$ 称 g(n)是 f(n)的一个渐近上界 当且仅当存在正的常数 c 和 $n_0$，使得对于所有的 $n \\ge n_0$， 有 $f(n) \\le cg(n)$。 $O$比率定理：对于函数 $f(n)$ 和 $g(n)$，如果极限 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)}$存在，则$f(n) = O(g(n))$ 当且仅当存在正的常数 c，使得 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)} \\le c$ $\\Omega$ $f(n)=\\Omega(g(n))$ 称 g(n)是 f(n)的一个渐进下界 当且仅当存在正的常数 c 和 $n_0$，使得对于所有的 $n \\ge n_0$， 有 $f(n) \\ge cg(n)$。 $\\Omega$比率定理：对于函数 $f(n)$ 和 $g(n)$，如果极限 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)}$存在，则$f(n) = \\Omega(g(n))$ 当且仅当存在正的常数 c，使得 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)} \\ge c$ $\\Theta$ $f(n)=\\Theta(g(n))$ 称 g(n) 和 f(n) 同阶 当且仅当存在正的常数 $c_1$, $c_2$ 和 $n_0$，使得对于所有的 $n \\ge n_0$， 有 $c_1g(n) \\le f(n) \\le c_2g(n)$。 $\\Theta$比率定理：对于函数 $f(n)$ 和 $g(n)$，如果极限 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)}$ 和 $\\lim \\limits_{n \\to \\infty}\\frac{g(n)}{f(n)}$ 均存在，则$f(n) = \\Theta(g(n))$ 当且仅当存在正的常数 $c_1$, $c_2$，使得 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)} \\le c_1$, $\\lim \\limits_{n \\to \\infty}\\frac{g(n)}{f(n)} \\le c_2$ $o$ $f(n) = o(g(n)) 当且仅当 $f(n) = O(g(n))$ 和 $g(n) \\ne O(f(n))$, 即$g(n)$是$f(n)$的上界，但反之不成立 一般情况下，$f(n) = o(g(n))$ 的充要条件为 $\\lim \\limits_{n \\to \\infty}\\frac{f(n)}{g(n)} = 0$ ","date":"2023-12-22","objectID":"/blog/posts/algorithm/programming-complexity/:1:0","tags":null,"title":"Programming Complexity","uri":"/blog/posts/algorithm/programming-complexity/"},{"categories":["Algorithm"],"content":"常用渐进函数阶的比较 对于$\\forall$ 给定正实数 c, p, 和 $\\varepsilon$，满足以下不等式 $\\exists \\ n_0$, s.t. $\\forall \\ n \u003e n_0$, $(c \\cdot logn)^p \u003c (logn)^{p + \\varepsilon}$ 幂函数底数扩大系数使函数增大的速度不如扩大指数，不管系数扩大多少倍 $\\exists \\ n_0$, s.t. $\\forall \\ n \u003e n_0$, $(c + n)^p \u003c n^{p + \\varepsilon}$ 和1类似 $\\forall$ 实数 $y$, $\\exists \\ n_0$, s.t. $\\forall \\ n \u003e n_0$, $n^p(logn)^y \u003c n^{p + \\varepsilon}$ 引申一下就是 $\\forall$ 实数 $y$, $\\exists \\ n_0$, s.t. $\\forall \\ n \u003e n_0$, $(logn)^y \u003c n^{\\varepsilon}$ $\\exists \\ n_0$, s.t. $\\forall \\ n \u003e n_0$, $n^p \u003c 2^n$ 幂函数不论指数多大，增长速度都不及指数函数 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/programming-complexity/:2:0","tags":null,"title":"Programming Complexity","uri":"/blog/posts/algorithm/programming-complexity/"},{"categories":["Algorithm"],"content":"基本概念 近似比 近似算法产生解的代价：C， 最优解产生解的代价：$C^*$ $max(\\frac{C}{C^*}, \\frac{C^*}{C}) \\le \\rho(n)$ \u003c=\u003e 近似算法有近似比 $\\rho(n)$, 近似算法是一个相对近似算法 特别的，如果算法近似比达到$\\rho(n)$，则该算法为$\\rho(n)$近似算法 $\\left| C - C^* \\right| \\le k$, k是一个常数 \u003c=\u003e 近似算法是一个绝对近似算法 上面取max和绝对值，是因为面对的可能是一个最大化问题，也可能是一个最小化问题 近似模式(approximation scheme) 一个最优化问题的一种近似模式实际就是指的一种近似算法，这种近似算法满足如下条件： 输入除了该问题的实例外，还有一个值$\\varepsilon \u003e 0$, s.t. 对任何固定的$\\varepsilon$, 该模式是一个$(1 + \\varepsilon)$近似算法 在众多近似模式中，有两种特殊的，分别是：多项式时间近似模式 和 完全多项式时间近似模式。它们二者在近似模式要求的基础上，对近似算法的时间复杂度做了进一步的要求。 多项式时间近似模式除近似模式本身对于近似比的要求外，还要求近似算法的时间复杂度是n的多项式。 完全多项式时间近似模式除近似模式本身对于近似比的要求外，还要求近似算法的时间复杂度既是$\\frac{1}{\\varepsilon}$的多项式，又是n的多项式 如果看待多项式时间近似模式和完全多项式时间近似模式的区别？ 二者都一定是满足近似算法的基本要求的，除此以外，区别进在于时间复杂度。显然的是，近似比越接近接近于1 / $\\varepsilon$越接近于0，说明近似结果同最优解越接近，近似效果越小。 多项式时间近似模式仅要求复杂度是n的多项式，这并不排除$\\frac{1}{\\varepsilon}$成为n的指数。当$\\varepsilon$减少时，指数位置会使得时间复杂度迅速增长，而系数位置则确保了$\\varepsilon$的常数倍减小只会使得时间常数倍增大。 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:1:0","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"常见问题的近似算法及对应可近似性结论 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:0","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"多机调度问题(Multiprocessor scheduling) 贪心法（G-MPS, greedy multi-processor scheduling） 贪心策略：按输人的顺序分配作业，把每一项作业分配给当前负载最小的机器。如果当前负载最小的机器有 2 台或 2 台以上,则分配给其中的任意一台。 近似比：2近似算法, $G-MPS(I) \\le (2 - \\frac{1}{m}) OPT(I)$ 证明: 1.最小化问题找最优解的下界 2.考虑算法的最终结果等于最终负载最大的机器，考虑最后一项分配到该机器上的作业，分配之前此台机器是负载最小的机器，从而时间小于等于均值 递降贪心法（DG-MPS） 贪心策略：首先按处理时间从大到小重新排列作业,然后运用 G-MPS 近似比：$\\frac{3}{2}$近似算法，$DG-MPS(I) \\le (\\frac{3}{2} - \\frac{1}{2m})OPT(I)$ ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:1","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"顶点覆盖问题 2近似算法：从边集中取边，将边的两个端点加入结果点集，删除和两个端点相关联的所有边，重复以上过程，直至边集为空 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:2","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"旅行商问题 若假设代价函数满足三角不等式则2近似算法 若代价函数不满足三角不等式，则在$P \\ne NP$前提下，不存在$\\rho (\\rho \u003e 1)$近似算法，$\\varepsilon$-近似旅行商问题是NP难问题 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:3","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"0/1背包问题 0/1背包问题的贪心算法不是绝对近似算法, 绝对近似解是NP难问题 2近似算法：按单位重量价值从大到小排序，顺序判断，能装下物品就装下 $(1 + \\varepsilon)$完全多项式时间近似算法：似乎存在两种方式，1个是贪心的优化，还有一个是通过价值的放缩 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:4","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"最多程序存储问题 1-近似算法：将程序按照所需存储空间由小到大编号，然后逐一向第一个磁盘存储，第一个磁盘不能存储时，再将剩下的程序逐一向第二个磁盘存储，直至第二个磁盘也不能存储为止。 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:5","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["Algorithm"],"content":"最小集合覆盖问题 $lnn + 1$近似算法：从F中优先选择与待覆盖集合交集最大的子集 ","date":"2023-12-22","objectID":"/blog/posts/algorithm/approximation-algorithm/:2:6","tags":null,"title":"Approximation Algorithm","uri":"/blog/posts/algorithm/approximation-algorithm/"},{"categories":["HPC"],"content":"mpicc, mpic++, mpicxx mpiexec, mpirun mpichversion mpicc 仅可编译 .c 文件，编译 .cpp文件会报错 mpic++ 编译 .cpp 文件 MPI标准的不同实现：MPICH、MVAPICH、MVAPICH2、Open MPI MPI编译器mpicc只是对于普通c/c++编译器的封装，在普通编译器的基础上添加了MPI相关文件的路径便于进行头文件引入和链接 mpiexec is a direct link to mpiexec.hydra mpirun is a wrapper script that determines your batch system and simplifies the launch for the user, but eventually also calls mpiexec.hydra 通信子 \u003c=\u003e 进程集合 MPI_Init 会初始化一个通信子communicator MPI_COMM_WORLD ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:0:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"MPI Introduce All parallel in MPI is explicit. MPI implementation version: MVAPICH MPICH Inter MPI Open MPI Microsoft MPI ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:1:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"MPI Install ./configure -prefix=/home/hongyu_gao2001/mpi/mpi-install --disable-fortran make make install If we execute the command man mpicc or man mpicxx, we can get two command line arguments -compile_info and -link_info, which are used to show the steps for compiling a program(what options and include paths are used) and show the steps for linking a program(what options and libraries are used). If we use the mpicc -compile_info or mpicc -link_info, we can get the following compile options: -I/home/hongyu_gao2001/mpi/mpi-install/include -L/home/hongyu_gao2001/mpi/mpi-install/lib -Wl,-rpath -Wl,/home/hongyu_gao2001/mpi/mpi-install/lib -Wl,--enable-new-dtags -lmpi For a detailed explanation of the above options, please refer to the C C++ Compile Link. Acording to the result of the option mpicc -compile_info or the mpicc -link_info, we can learn about that the mpicc and mpicxx is just a wrapper of gcc and g++, them add extra options for gcc and g++. And -prefix= option and make install make the mpicc and mpicxx carry the compile option according to the content of the -prefix=, which is equal to the gcc or g++ which carry these optinos manually. According to the rpath | wikipedia, we can use the readelf -d \u003cbinary_name\u003e | grep 'R.*PATH' to verify the role of the compile option -Wl. $ gcc mpi_hello_world.c -I/home/hongyu_gao2001/mpi/mpi-install/include -L/home/hongyu_gao2001/mpi/mpi-install/lib -lmpi -o mpi_hello_world_norpath $ ./mpi_hello_world_norpath ./mpi_hello_world_norpath: error while loading shared libraries: libmpi.so.12: cannot open shared object file: No such file or directory $ readelf -d mpi_hello_world_norpath | grep 'R.*PATH $ mpicc mpi_hello_world.c -o mpi_hello_world $ ./mpi_hello_world ./mpi_hello_world: error while loading shared libraries: libmpi.so.12: cannot open shared object file: No such file or directory $ readelf -d mpi_hello_world | grep 'R.*PATH 0x000000000000001d (RUNPATH) Library runpath: [/home/hongyu_gao2001/mpi/mpi-install/lib] The GNU Linker (GNU ld) implements a feature which it calls “new-dtags”, which can be used to insert an rpath that has lower precedence than the LD_LIBRARY_PATH environment variable.1 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:2:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Hello World MPI_Init(NULL, NULL); // Get the number of processes int world_size; MPI_Comm_size(MPI_COMM_WORLD, \u0026world_size); // Get the rank of the process int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, \u0026world_rank); MPI_Finalize(); ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:3:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"MPI Environment Management int MPI_Init(int *argc, char ***argv) When we call this function, system will generate a communicator called MPI_COMM_WORLD ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:4:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Naming Style If all the letters are the capital letters, it always be a constant, such as MPI_AINT. It is like the MPI_INT. If the letters contains the capital letters and lowercase letters, it always be a type, such as MPI_Aint. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:5:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Datatype ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:6:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"contiguous 用于连续的数据 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:6:1","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"vector 数据块的大小 和 两个数据块之间的距离 均为常数 Please note that vector is not only used for one dimension scene，it can also used for two dimension matrix. One or two dimension is just a concept of programming language. For MPI, no matter what types of matrix, it all sees as the one dimension in memory, e.g. it only cares about the structure of memory. So, if we want to describe a submatrix, we can also use the MPI_Type_vector(), just edit the input matrix structure. In my opinion, upper bound and lower bound are just memory addresses, ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:6:2","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"index 与 vector 类似，但数据块大小和两个数据块之间的距离均不是常数，用于补充 vector 的应用场景 MPI 发送和接收数据并不是要求派生数据类型必须相同，而是要保证发送和接收数据之间能够匹配上，发送时使用派生数据类型，接收时是可以使用原生数据类型的，参考MPI_Type_indexed。 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:6:3","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"struct 最灵活的一种，灵活性来源于可配置项的增加。In fact, the most important configuration items are block_lengths[], displacements[] and block_types[]. vector: these three configuration items are immobilized. index: can specify the block_length and displacement respectivly. struct: can specify these three configuration items respectivly. Please note that, the number of block_length corresponds to the block_types. Although the name of this type is struct, we not only treat it as a true C struct, but also mix of any other data types. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:6:4","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"MPI Execution Mode If we create some arrays in main function and execute the MPI program with many processes. These arrays in different processes are private datas. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:7:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Communication MPI use the Point-to-Point(P2P, 点对点通信), 显式采用双边通信，需要进程双方的参与，在 MPI 2.0 中提出了单边通信的概念。 P2P 的两种具体实现协议：(所谓实现协议，是指这部分内容并不属于 MPI Standard) Eager Rendezvous ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"阻塞式 MPI 提供了一些数据结构，对应C/C++中的基础数据结构，用于在更高层次指定消息结构 Receiver 如果收不到消息会一直阻塞等待。 Sender 是否会阻塞取决于 MPI 的具体实现，某些实现下，在没有对应的 Receiver 时，Sender 会阻塞；在某些实现下，Sender会将数据存储到 send buffer 中，然后直接返回，并不会阻塞。这一点区别会影响到对于 MPI deadlock 情况的分析。 int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, \u0026world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, \u0026world_size); int number; if (world_rank == 0) { number = -1; MPI_Send(\u0026number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); } else if (world_rank == 1) { MPI_Recv(\u0026number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(\"Process 1 received number %d from process 0\\n\", number); } Please note that, the count field in MPI_Send means the number of data which will be send, but it means the max capacity of receive buffer. 我们称 MPI_Send 和 MPI_Recv 是阻塞式的，这一说法来源于MPI Document，然后它们的 actual performance is maybe different from what we understand. Before we talk about some situations which can explain this statement, we need to discriminate some concepts: MPI is a standard, it contains many rules to tell us what should MPI do and how it do. MPICH and OpenMPI are implementation of MPI In MPI standard, MPI_Send is a blocking function. But in MPICH MPI_Send doc, we can see the following statement: This routine may block until the message is received by the destination process. How can we understand this “may” ? Answer: In MPICH, when the MPI_Send can’t find the enough send buffer, it will block. or else, it will return. There is an example 2 to elaborate this viewpoint If we follow the rule of MPI standard, MPI_Send will block entil MPI_Recv is executed. But the following example doesn’t follow this rules #include \u003ciostream\u003e #include \u003cmpi.h\u003e int main() { MPI_Init(NULL, NULL); int size, rank; MPI_Comm_size(MPI_COMM_WORLD, \u0026size); MPI_Comm_rank(MPI_COMM_WORLD, \u0026rank); if (rank == 0) { int buffer = 0; int msg; std::cout \u003c\u003c \"process 0: \"; MPI_Send(\u0026buffer, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); MPI_Recv(\u0026msg, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u003c\u003c msg \u003c\u003c std::endl; } else { int buffer = 1; int msg; std::cout \u003c\u003c \"process 1: \"; MPI_Send(\u0026buffer, 1, MPI_INT, 0, 0, MPI_COMM_WORLD); MPI_Recv(\u0026msg, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u003c\u003c msg \u003c\u003c std::endl; } MPI_Finalize(); return 0; } The output of program is: process 0: 1 process 1: 0 According to the rule of MPI standard, this program can’t execute, but it get the right result now. There is a precondition of this program can get the right result is that MPI_Send can return normally before the corresponding MPI_Recv function completes execution. So, we can use the following program to verify this guess. #include \u003ciostream\u003e #include \u003cmpi.h\u003e #include \u003cunistd.h\u003e int main() { MPI_Init(NULL, NULL); int size, rank; MPI_Comm_size(MPI_COMM_WORLD, \u0026size); MPI_Comm_rank(MPI_COMM_WORLD, \u0026rank); if (rank == 0) { int buffer1 = 1; int buffer2 = 2; MPI_Send(\u0026buffer1, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); std::cout \u003c\u003c \"MPI_Send returns\" \u003c\u003c std::endl; MPI_Send(\u0026buffer2, 1, MPI_INT, 2, 0, MPI_COMM_WORLD); } else if (rank == 1) { int msg; sleep(10); MPI_Recv(\u0026msg, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u003c\u003c \"process 1 receives the msg: \" \u003c\u003c msg \u003c\u003c std::endl; } else if (rank == 2) { int msg; sleep(5); MPI_Recv(\u0026msg, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u003c\u003c \"process 2 receives the msg: \" \u003c\u003c msg \u003c\u003c std::endl; } MPI_Finalize(); return 0; } This program will get the following result: MPI_Send returns process 2 receives the msg: 2 process 1 receives the msg: 1 And we can also use the following extreme example #include \u003ciostream\u003e #include \u003cmpi.h\u003e #include \u003cunistd.h\u003e int main() { MPI_Init(NULL, NULL); int size, rank; MPI_Comm_size(MPI_COMM_WORLD, \u0026size); MPI_Comm_rank(MPI_COMM_WORLD, \u0026rank); if (rank == 0) { int buffer1 = 1; int buffer2 = 2; MPI_Send(\u0026buffer1, 1, MPI_INT, 1, 0, MPI_COMM_WORLD); std::cout \u003c\u003c \"MPI_Send returns\" \u003c\u003c std::endl; MPI_Send(\u0026buffer2, 1, MPI_INT, 2, 0, MPI_COMM_WORLD); } MPI_Finalize(); return","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:1","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"非阻塞式 Because non-blocking function will return immediately after calling. So the data in buffer is maybe not received by receiver process. So, MPI provides the MPI_Request, MPI_Wait() and MPI_Test() to address this problem. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:2","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Deadlock ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:3","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"消息查询 Dynamic Receiving 利用MPI_Recv的最后一个 MPI_Status 参数来获取接受到的消息的信息，以便应对动态长度的传输数据 The data structure of MPI_Status: typedef struct MPI_Status { int count_lo; int count_hi_and_cancelled; int MPI_SOURCE; int MPI_TAG; int MPI_ERROR; } MPI_Status; An example of using status, but MPI_Recv的问题在于只能提前开辟尽可能大的store buffer，在接受完消息后再通过status得知消息长度 #define MAX_NUMBERS 100 int numbers[MAX_NUMBERS]; if (world_rank == 0) { MPI_Send(numbers, 3, MPI_INT, 1, 0, MPI_COMM_WORLD); } else { int number_amount; MPI_Status status; MPI_Recv(numbers, MAX_NUMBERS, MPI_INT, 0, 0, MPI_COMM_WORLD, \u0026status); MPI_Get_count(\u0026status, MPI_INT, \u0026number_amount); printf(\"%d\\n%d\\n%d\\n%d\\n\", number_amount, status.MPI_SOURCE, status. MPI_TAG, status.MPI_ERROR); } 替代方案是首先使用 MPI_Probe 获取消息长度，然后根据消息长度开辟存储空间，再使用 MPI_Recv 接收消息，避免空间浪费（不过这只是逻辑说法，实际连接起这些概念的都是status，MPI_Probe也是将即将接收到的消息状态存储到status数据结构中） #define MAX_NUMBERS 100 int numbers[MAX_NUMBERS]; if (world_rank == 0) { MPI_Send(numbers, 3, MPI_INT, 1, 0, MPI_COMM_WORLD); } else { int number_count; MPI_Status status; MPI_Probe(0, 0, MPI_COMM_WORLD, \u0026status); MPI_Get_count(\u0026status, MPI_INT, \u0026number_count); int *number_buf = (int *)malloc(sizeof(int) * number_count); MPI_Recv(number_buf, number_count, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(\"%d\\n%d\\n%d\\n%d\\n\", number_count, status.MPI_SOURCE, status. MPI_TAG, status.MPI_ERROR); free(number_buf); } ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:4","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Communicator Hign Dimension Communicator 这里其实就涉及到我们对于通信子的理解了，如果从计算机网络的角度来说，通信子可以理解为一个广播域（从通信子的使用方式来看，确实也比较符合这种理解方式） 所谓高维通信子，不过是把进程按照一种新的方式进行分组 在 MPI 中，我们需要 MPI_Comm_split 实现对现有进程重新分组，我们需要考虑重新分组需要指定哪些内容： process 将位于哪个组别 process 在新的组别中的编号（这里的编号指的就是在 1 维下的编号了） 以上两项内容分别由函数参数中的 color 和 key 实现 color 相同的被分到同一个组中，也就是同一个通信子中，key 的相对大小关系将决定了 process 在新的通信子内的 rank 排序方式（这里按照目前我的理解，只需要关注 rank 的相对大小，实际编号仍然是从 0 开始，遵循 rank 所指示的相对大小关系） 实际上我们所说的几维通信子，这里的维度只是人为附加的一种认知信息，所谓认知信息是我们通过分组，为每个进程都添加了额外的分组信息，我们可以通过这些分组信息抽象出高维结构，或者说通过这些分组更好地映射到某些计算任务上，但是这并不代表实际真的存在这样一个高维结构，不过是人为附加的信息罢了。 需要注意的是，我们一般在划分完高维通讯子后会去获取一下进程在自己的 行通讯子 和 列通讯子中的 rank。 int row, col; MPI_Comm_rank(rowcomm, \u0026row); MPI_Comm_rank(colcomm, \u0026col); 这里要格外小心，上述代码中的 row 和 col 并不等价于逻辑布局中的行号和列号，以 3 x 2 的布局为例，代码中的 row 和 col 对应到逻辑布局上如下图所示 在上图中，我们用第一个数值表示 process 所在行通讯子中的 rank 值，第二个数值表示 process 所在列通讯子中的 rank 值 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:5","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Broadcast 收发双发都调用 MPI_Bcast 函数，参数也是相同的。(这一点很重要，因为在实际编程时我们很容易就理解成只需要让发生 broadcast 的通讯子内部的 root node 调用即可，但是实际上需要这一通讯子内部的所有 process 都调用此函数) 那么很神奇的就是函数如何判断函数调用者是发送方还是接收方,我觉得这应该是在函数实现中会对调用 process 的 rank 进行判断，无论是发送方还是接收方调用函数，函数参数中的 root 表示的都是发送方，那么函数在实现时只需要判断 root 值是否等于调用者的 rank 即可。 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:6","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Gather MPI_Gather() 一个函数既负责发送，也负责接收，通过参数中的 root 指定 gather 操作的信息接受者 There are some important things which are described in official document3. The root receives the messages and stores them in rank order Note that the recvcount argument at the root indicates the number of items it receives from each MPI process, not the total number of items it receives. According to the second item above, MPI_Gather() can only solve the situation that all the processes send the same of data to the root process. Thinking about why this function parameter recvcount is defined in this way. In fact, the effect of MPI_Gather is similar with each non root node calls the MPI_Send to send they own data to root node, so this viewpoint can explain the two phenomenons: why each process need to call the MPI_Gather why the meaing of recvcount parameter is the number of items that is received by root node from each process instead of all processes If we want to gather data more flexibly, we can use MPI_Gatherv. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:7","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Scatter 其实 MPI_Scatter 是 MPI_Gather 的逆过程，但是 scatter 的实际应用过程更容易出现错误。为了便于叙述，我们假定负责进行 gather 和 scatter 的进程均为 0 号进程。在 Gather 过程中，process 0 会汇集其他 process 所传递的数据进行合并，那么 MPI_Gather 将作为一个统一的入口点，在此函数参数中我们无法单独指定每块数据的长度，因此很自然就理解了 MPI_Gather只能处理不同 process 下长度相等的数据块。但是MPI_Scatter` 实际的分发过程是在各个接收 process 中完成的，我们很容易就会理解为让每个 process 接收自定义长度的数据。但是显然这对于 gather 来说，并非严格的逆过程，实际上，scatter 必须在每个 process 中都处理相同长度的数据，即不同 process 中处理的数据长度相等。 scatter 的 sendcount 指的是发送给一个 process 的数据量，而不是参与 scatter 的全部数据量，那么很容易产生一个疑问，即此时 sendcount 和 recvcount 又有什么区别，既然都是发送给 receiver process 的数据量，为什么不合并为一个 count，还要分为两个参量。产生这个疑问我们可能忽略了 sendtype 和 recvtype 的存在，发送 1 个 4B 的 int，接收 4 个 1B 的 char 是一个合理的需求，此时 sendcount 和 recvcount 并不相等。 There is an example that can explain this design. Firstly, we need explain some pre-infomations, the binary expression of char $A$ is $1000001$, we use the binary expression $1000001010000010100000101000001$ (decimal number $1094795585$) to express the $AAAA$. So, if we use four 1 byte char to receive this decimal number, we will get four $A$. Now, we use MPI to verify this judgement. if (rank == 0) { int number = 1094795585; char msg[4]; MPI_Scatter(\u0026number, 1, MPI_INT, msg, 4, MPI_CHAR, root, MPI_COMM_WORLD); std::cout \u003c\u003c \"process 0: \"; for (int i = 0; i \u003c 4; i++) { std::cout \u003c\u003c msg[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } The result of the above code is: process 0: A A A A 不过在这里例子中，我们仅使用到了一个 process，当参与过程的进程不止一个时，这里仍然会让人感到困惑，这是因为我们总是将 MPI_Gather 和 MPI_Scatter 的执行模式看为主从式，即在 gather 中，root 节点负责接收，其他节点负责发送，或者在 scatter 中，root 节点负责发送，其他节点负责接收。然而实际上并非如此，以 root 节点为例，它自己既是发送方又是接收方，to be honest, I don’t understand the design idea of scatter, expecially when I need to fill the parameter sendcount of MPI_Scatter, but we can follow a simple rule that $sendcount * sizeof(sendtype) == recvcount * sizeof(recvtype)$。 Maybe we can understand sendcount and sendtype in this way: when this progress includes multiple processes, we can think that root node need to send the message to other nodes one by one with rank order. So the sendcount and sendtype mean what needs to be sent from root node to an another node. Now, we use an example to illustrate the usage of MPI_Scatter for multiple processes: Following the above implementation method, we change the data from AAAA to AABB to verify the effect of scatter. 01000001 01000001 01000010 01000010 (1094795842) A A B B if (rank == 0) { int number = 1094795842; char msg[2]; MPI_Scatter(\u0026number, 2, MPI_CHAR, msg, 2, MPI_CHAR, root, MPI_COMM_WORLD); std::cout \u003c\u003c \"process 0: \"; for (int i = 0; i \u003c 2; i++) { std::cout \u003c\u003c msg[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } else if (rank == 1) { char msg[2]; MPI_Scatter(NULL, 2, MPI_CHAR, msg, 2, MPI_CHAR, root, MPI_COMM_WORLD); std::cout \u003c\u003c \"process 1: \"; for (int i = 0; i \u003c 2; i++) { std::cout \u003c\u003c msg[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } The result of the above code is: process 0: B B process 1: A A What we need to notice is that both MPI_Gatherv and MPI_Scatterv use the number of element for displacement, they do not use the byte displacement like some creating data type function, such as MPI_Type_create struct. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:8","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"AlltoAll The principle of MPI_Alltoall is execute multiple times MPI_Send and MPI_Recv, so the parameter sendcount and recvcount in MPI_Alltoall means the message number from sender to receiver instead of total message volume. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:8:9","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Parallel Calculation Mode ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:9:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Reduce 对多个元素进行 reduce 时，不同元素 reduce 的结果是分离的，有几个元素进行 reduce 结果就有几个 值得注意的是，传递给 MPI_Reduce 和 MPI_Allreduce 的 recvbuf 的初始值并不重要，假设进行的 reduce 是求和操作，那么直观感觉上最终的结果应该会累加到 recvbuf 中，但是实际测试结果并非如此，recvbuf 只是承担了存储最终结果的角色，求和并没有在其原始数值上进行 if (rank == 0) { int buffer = 0; int sum; MPI_Reduce(\u0026buffer, \u0026sum, 1, MPI_INT, MPI_SUM, root, comm); std::cout \u003c\u003c sum \u003c\u003c std::endl; } else if (rank == 1) { int buffer = 1; MPI_Reduce(\u0026buffer, nullptr, 1, MPI_INT, MPI_SUM, root, comm); } else if (rank == 2) { int buffer = 2; MPI_Reduce(\u0026buffer, nullptr, 1, MPI_INT, MPI_SUM, root, comm); } 在上述程序中，我们并没有对 sum 赋初值 0，但程序依然得到了正确结果 3 MPI_Allreduce 可以理解为两步操作：broadcast + reduce Every process broadcasts they onw data to other processes. Every process reduce all data and save the result to they own local result buffer. Compare with MPI_Reduce，there is only a change in MPI_Allreduce program that MPI_Allreduce don’t need the root parameter, because every process is the root node. if (rank == 0) { int buffer = 0; int sum; MPI_Allreduce(\u0026buffer, \u0026sum, 1, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 0: \" \u003c\u003c sum \u003c\u003c std::endl; } else if (rank == 1) { int buffer = 1; int sum; MPI_Allreduce(\u0026buffer, \u0026sum, 1, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 1: \" \u003c\u003c sum \u003c\u003c std::endl; } else if (rank == 2) { int buffer = 2; int sum; MPI_Allreduce(\u0026buffer, \u0026sum, 1, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 2: \" \u003c\u003c sum \u003c\u003c std::endl; } This program will get the following result: process 0: 3 process 1: 3 process 2: 3 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:9:1","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Scan When judge the multiple channels input data，MPI_Scan 与 MPI_Reduce 的实现方式相同，都是对每个输入通道单独进行 scan 操作，如以下代码所示 if (rank == 0) { int buffer[] = {1, 2}; int prefix[2]; MPI_Scan(buffer, prefix, 2, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 0: \"; for (int i = 0; i \u003c 2; i++) { std::cout \u003c\u003c prefix[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } else if (rank == 1) { int buffer[] = {2, 3}; int prefix[2]; MPI_Scan(buffer, prefix, 2, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 1: \"; for (int i = 0; i \u003c 2; i++) { std::cout \u003c\u003c prefix[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } else if (rank == 2) { int buffer[] = {3, 4}; int prefix[2]; MPI_Scan(buffer, prefix, 2, MPI_INT, MPI_SUM, comm); std::cout \u003c\u003c \"process 2: \"; for (int i = 0; i \u003c 2; i++) { std::cout \u003c\u003c prefix[i] \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; } The program will get the following result: process 0: 1 2 process 1: 3 5 process 2: 6 9 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:9:2","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Reduce_scatter The “reduce” is similar with MPI_Reduce, but the “scatter” is similar with MPI_Scatterv that it can specify the number of elements for every process. ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:9:3","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"user define operation 首先从调用形式上来说，由于 user define operatoin 是直接作用于现有的 MPI_Reduce 和 MPI_Scan 等计算函数的，所以函数接口的形式是可以确定的，不能确定的是 user define operation 的具体代码实现，而这个实现一定是对照实际需求的，如果想要在实际需求和代码实现之间建立起联系，我们必须要考虑的是 MPI_Reduce 以及 MPI_Scan 是以何种方式来调用这个 user define operation 的，只有在了解了执行模型后，我们才能编写出对照实际需求的代码实现。 在此前分析 MPI_Reduce 和 MPI_Scan 时，我们说法这两个函数在处理多通道数据时，处理逻辑是逐个通道来处理的，这里从定义 operation 时给定的 len parameter 可以看出，实际运算在处理时确实是逐个通道来处理的。 为了便于阐述，这里以 MPI_Reduce 使用 user define operation 为例 这里需要区分清几个概念： process 调用 MPI_Reduce 时的 sendBuffer 和 recvBuffer operation 所面对的 inputBuffer 和 outputBuffer inputBuffer 对应非 root node 的 sendBuf，outputBuffer 对应 root node 的 sendBuf。（这里面没有涉及到的是非 root node 和 root node 的recvBuf，对于前者，并不需要提供这个参数，对于后者，只是负责存储最终的结果，中间数据是通过 root node 的 sendBuf 来负责存储的） 对于 MPI_Reduce 和 MPI_Scan 对于 operation 执行模式的了解有助于帮助我们解决之前所遇到的两个疑问： MPI_Reduce 并不关心非 root node 的 recvBuf parameter root node 在没有初始化 recvBuf 时，最终依然能够得到正确结果（我们可以理解为中间的运算数据都是 root node 的 sendBuf 在存储，最后直接将运算结果存储到 root node 的 recvBuf 中，不过最终结果存储这个过程无法从现有测试中得到验证，只是我们对于实现机制的一种猜测） 只看上面的内容，依然会对整个过程比较模糊，我们结合下面的图来理解 如果有 3 个 process 参与整个过程，那么只有非 root node 会调用 operation，即上图中 call 的两部分，他们会通过蓝色框标识的参数直接与 root node 的数值进行交互，从而获得最终结果，中间运算数据都存储在 root node 的数值中，最终存储到 root node 的 recvBuf 中。 ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:9:4","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"CUDA-Aware MPI An Introduction to CUDA-Aware MPI ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:10:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Network RDMA（Remote Direct Memory Access，远程内存直接访问）技术 让数据能够在不同服务器内存间直接传输， 而不经过 CPU 和操作系统（简单理解就是网卡需要承担 CPU 的部分计算任务） MPI 和 RDMA 之间有何种联系 ？ 因为 MPI 需要发生多节点之间的通信，而这个数据传输过程如果发生在传统的 TCP/IP 网络中，必然要经过 己方CPU -\u003e 己方网卡NIC -\u003e 对方NIC -\u003e 对方CPU 这样一个过程，这无疑会给 CPU 带来一定计算开销，然而在网络通信中所涉及的计算无非就是一些路由信息的计算，这些工作完全可以交由 NIC 来处理，所以可以通过增强 NIC 的计算能力，让 CPU 从这一通信过程中摘离，即实现 RDMA。 目前 3 种 RDMA 网络： Infiniband RoCE iWARP (传输层之上） ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:11:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["HPC"],"content":"Reference [1] MPI Tutorial [2] MPICH API Document [3] 一切靠自己的 MPI 框架 The role of GNU ld ↩︎ MPI Standard | 3.5 Semantics of Point-to-Point Communication | Example 3.10 ↩︎ MPI Docs ↩︎ ","date":"2023-12-12","objectID":"/blog/posts/hpc/mpi/:12:0","tags":null,"title":"MPI","uri":"/blog/posts/hpc/mpi/"},{"categories":["Computer-Architecture"],"content":"解决 Branch Hazards 的n种方法 ","date":"2023-12-01","objectID":"/blog/posts/computer-architecture/computer-architecture/:1:0","tags":null,"title":"Computer Architecture","uri":"/blog/posts/computer-architecture/computer-architecture/"},{"categories":["Computer-Architecture"],"content":"static branch prediction freeze of flush the pipeline (predicted-not-taken) treat every branch as not taken treat every branch as taken This buys us a one-cycle improvement when the branch is actually taken, because we know the target address at the end of ID, one cycle before we know whether the branch condition is satisfied in the ALU stage. 三种方式下一个非常重要的问题就是在哪个阶段确定的是分支指令? 在哪个阶段确定的分支指令的目标地址? 这个问题有点影响因素： 指令类型不同 硬件的设计方式不同 选择的预测机制不同 无条件分支指令在ID阶段就可以确定是分支指令以及目标地址, 这个不需要看硬件设计和预测机制 有条件分支指令在一般设计需要到EX阶段结束后能够确定目标地址，如果是高级设计则可以提前到ID阶段确定目标地址。注意说的是可以，在采用预测未选中机制时，还是采用EX阶段确定目标地址的方式，在采用预测选中机制时，需要在ID阶段完成 delayed branch 一个很重要的情况是: 这种技术手段主要用在早期没有分支预测的流水线 RISC 上，现代 RISC 实现早就可以在流水线的第 2 级利用分支预测确定跳转的目标，分支延迟槽也就失去了原来的价值, 所以说在考虑分支延迟的时候，应该是不用考虑分支预测的方式的 分支延迟槽的作用机理就是把无论分支最终是否选中后续都会执行的指令放到分支指令之后，使得当这部分指令执行结束后恰好就能确定分支指令的目标地址了，然后就可以顺次执行下去，使用这部分指令掩盖或者代替了确定分支指令目标地址之前停顿的时间 branch delay slot will contains the instructions which are executed whether or not the branch is taken. architectures with delay branches often disallow putting a branch in the delay slot. ","date":"2023-12-01","objectID":"/blog/posts/computer-architecture/computer-architecture/:1:1","tags":null,"title":"Computer Architecture","uri":"/blog/posts/computer-architecture/computer-architecture/"},{"categories":["Computer-Architecture"],"content":"VLIW loop unroll 和 software pipelining 是 VLIW 实际应用时采用的两种常见技术 而 pipelining 的核心就是各种指令之间的 overlap ","date":"2023-12-01","objectID":"/blog/posts/computer-architecture/computer-architecture/:2:0","tags":null,"title":"Computer Architecture","uri":"/blog/posts/computer-architecture/computer-architecture/"},{"categories":["Algorithm"],"content":"NP完全性的核心逻辑 NP完全问题是为了反映一个问题有多难，而不是为了反应它有多简单 有多项式时间算法的问题称为易解的，不存在多项式时间算法的问题成为难解的（这里的多项式时间算法包含确定型图灵机多项式时间算法，也包含非确定性图灵机多项式算法） ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:1:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"性质 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:2:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"问题的分类 最优化问题(optimization problem) 判定问题(decision problem) 两类问题的关联在于：通常，通过对待优化的值强加一个界，就可以将一个给定的最优化问题转化为一个相关的判定问题了。同时从直观上来看，如果最优化问题容易，则对应的判定问题也是容易的。换言之，如果我们能够证明判定问题是困难的，则相当于也说明了对应的最优化问题是困难的. ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:3:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"NPC问题 相关问题描述 问题描述三部曲：1.有什么 2.找什么 3.目的是什么 顶点覆盖 存在一个顶点集包含所有边中的至少一个顶点 V, E, k, 找V' 给定图G=(V, E), 正整数$K \\le \\left| V \\right|$ 是否存在V的一个子集V’, $\\left| V’ \\right| \\le K$ s.t. V’包含图G任何一条边中至少一个顶点 相遇集 存在一个集合的子集包含原集合的子集族中每一个子集中的至少一个元素 S, C, K, 找S' 给定集合S, S的子集族C, 正胜数$K \\le \\left| S \\right|$ 是否存在S的一个子集S’, $\\left| S’ \\right| \\le K$ s.t. S’与C中任何一个子集的交集非空 划分问题 集合划分成两部分，两部分元素的权值和相等 01整数规划问题 关键是记住 $$ Ax \\le b \\ C^Tx \\ge D $$ 独立集 / 团 无需记忆问题描述，只需要知道独立集和团都是点集。 独立集这个点集中，任意两个顶点均不相邻 团这个点集中，任意两个顶点均相邻 补图和原图的顶点没变，补图中两个顶点之间有边（相邻）当且仅当原图中这两个顶点之间没边（不相邻） 哈密顿回路问题 给定图G=(V, E) 是否存在节点的一个排列 s.t. 存在包含全部节点的一条回路 旅行商判定问题 给定一个城市集合C, 每对城市之间的距离d，正整数D 是否存在一个C中城市的排列 s.t. 排列形成一个回路，距离和$\\le D$ 0/1背包判定问题 总容量不超过某值情况下，总价值能否超过一个值 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:3:1","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"NPH问题 旅行商问题（TSP） 0/1背包问题 为什么如何重视判定问题 ？ 无论是何种问题，关于P,NP,NPC,NPH都是在考虑如何描述解决问题的难易程度，这是这一章的核心逻辑 最优化问题或者说搜索问题，都可以比较简单的对应到一个判定问题，因此最优化问题易解-\u003e判定问题易解，逆反命题自然成立。而这种所谓的对应，专业的描述就是多项式时间变换，或者说属于归约操作 关于这一内容，出自《算法设计与分析（第2版）》屈老师的那一本书，由最优化问题-\u003e对应的判定问题是最开始讲述这类问题时进行的一种操作，这个准确来说叫做归约。而多项式时间变化是证明NPC或者NPH时的说法，不过多项式时间变换也是归约的一种 简单来说，判定问题的定义是明确且易表达易理解的，同时最优化问题是容易转换为判定问题的。 不过有一个疑问是为何只考虑最优化问题，在课程中提及的问题都是最优化问题，而是书籍中给出的示例一般也是最优化问题，但是一半问题中并非仅仅是最优化问题，不过似乎都是易转换为判定问题的 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:3:2","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"计算复杂度 两个重要工作： 确定问题计算复杂度的一个上界 确定问题计算复杂度的一个下界 以比较为基础的检索问题的时间下界$\\Omega(logn)$ 以比较为基础的排序问题时间下界$\\Omega(nlogn)$ 找最大值时间下界$\\Omega(n-1)$ 找最大值和最小值时间下界$\\Omega(\\lceil \\frac{3n}{2} \\rceil - 2)$ (分治) 找次大值时间下界$\\Omega(n + \\lceil logn \\rceil - 2)$ （锦标赛算法，首先找最大值下界为$n - 1$，树形结构中在输于最大值的元素中找次大值时间下界$\\lceil logn \\rceil - 1$） 找中位数时间下界$\\Omega(\\frac{3n}{2} - \\frac{3}{2})$ 找第k小值时间下界$\\Omega(n + min(k, n - k +1) - 2)$ ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:4:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"证明 所有多项式时间内可验证的问题组成了NP类问题，其中能够在多项式时间内求解的为P类问题，能够由其他NPC问题归约得到的是NPC问题 P : 多项式时间内可求解，存在确定型多项式时间算法 NP：多项式时间内可验证，存在非确定型多项式时间算法（随便猜一种情况然后验证，把所有情况猜完一定可以找到解） 证明问题是NP的，根本上来说就是判断是否存在一种非确定型多项式时间算法能够求解出答案，对于这种算法的描述可以用猜想和验证两个阶段来表述。而这种算法是多项式时间的等价于猜想和验证环节都是多项式时间的，而且猜想和验证都只是需要考虑一个实例要如何处理。如果说总共需要猜想和验证的实例数是指数级($2^n$)，但是一个实例的猜想和验证都只是需要多项式时间，那么这种算法依然是多项式时间的，因为非确定型多项式时间算法是跑在NDTM非确定型图灵机上的，是可以并行的。举一个验证阶段无法在多项式时间内完成的例子，旅行商问题，对于旅行商问题的一个实例（注意是旅行商问题，不是旅行商的判定问题），验证环节需要和其他所有回路进行比较，而其他回路数量是指数级的，所以验证环节是无法在多项式时间内完成的（如果是旅行商的判定问题，验证环节是可以在多项式时间内完成的）。 NPC: 首先需要是NP，然后找到另一种NPC问题可以转化到当前问题 为什么需要保证是NP？因为如果当前问题可以从另外一种NPC多项式时间内变换得到，只能说明当前问题不比那个NPC问题简单，有两种可能：1.NPC，2.非NPC的NPH，只有当时NP时才能保证是前者而非后者 给出已知NPC问题实例 给出待证明问题示例 说明最优化问题的原问题是NP的(存在一种多项式时间内猜想和多项式时间的验证方法可以得到问题的解，即存在非确定型多项式时间算法，其中非确定型是指需要猜想这个环节) 说明从一个已知的 NPC 问题的判定问题可以多项式时间归约到原问题的判定问题 4.1 构造一个待证明问题的示例 4.2 假设前一个问题可取得解，证明后一个问题同样存在解 4.3 假设后一个问题可取得解，证明前一个问题同样存在解 4.4 说明一下变换可以在多项式时间内完成 NPH: 首先判断是否为NP问题，如果是NP问题同时还是NPH问题那就只能是NPC问题，如果不是NP问题那就是非NPC的NPH问题，需要保证任意一个NP能够转化到当前问题(显然这是困难的，需要用到NPC的定义来实现) 说明问题不是NP的（验证环节无法在多项式时间内完成） 说明问题的难度不低于NPC 第2步的具体方法目前考虑到的可能有2种： 原问题的判定问题是NPC的，则说明原问题难度不低于NPC 存在一个已知的NPC问题可以多项式时间变换到当前问题 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:5:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"如何解决 NPC 问题 如果实际输入数据规模较小，则 指数级运行时间的算法 可解决问题 对于一些能在多项式时间内解决的特殊情况，可以单独求解 寻找一些能够在多项式时间内得到 近似最优解 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:6:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Algorithm"],"content":"证明问题是 NPC 问题的关键步骤 判定问题与最优化问题 NP 完全性不适合直接应用于最优化问题，但适合应用于判定问题 关于这一点最直观的理解方式就是看NPC问题的证明 假设现在要证明一个最优化问题是NPC的，那么第1步中会证明该问题是NP的，此时存在一种非确定型多项式时间算法可以在多项式时间内完成猜想，以及多项式时间内完成验证，从而确定猜想到的解是不是一个合法解。在这一步中，无论是算法还是验证过程，都像是在处理原问题的判定问题。但是不要忽略了，只要我们可以在多项式时间内验证一个解，那么只要所有可能猜到的解中包含最终答案，理论上我们就可以得到这个最终答案并且完成验证过程，这个时候原问题就已经得到解了，那这种猜想验证的算法实际就已经解决了原问题。（回过头来看，在这一部分最后一般会添加一句话“能猜到一个xxx当且仅当yyy中存在一个xxx“，这句话并不是废话，它保证了这种算法在理论上是可以在所有可能的情况中找到一个解的） 第2步会去证明是一个NPC问题，这里证明的并不是原问题那个最优化问题，而是最优化问题对应的判定问题，最后通过判定问题和原问题的难度关系，由于判定问题是NPC，那么原问题是不比NPC简单的问题，结合上述是NP问题，就能够说明是NPC问题了。 根据上述分析，虽然我们要证明的是最优化问题是NPC问题，但是完全可以看为要证明的是最优化问题的判定问题是NPC问题。因为第2步证明的确实就是判定问题是NPC问题，第1步给出的算法本身也是判定问题的形式（判定问题的形式，但是结合上猜想可以解决最优化问题本身）。所以只需要关注判定问题是什么即可。 归约 a.实例的概念: 实例是指某一特定问题的输入 b.多项式时间归约算法：一个多项式归约算法可以在多项式时间内，将A的任何实例a转化为B的实例b，a和b是相同(a为“是”时，b也为“是”) c.多项式时间归约的目的：A 和 B 之间的 ”易求解性“ 或 ”难求解性“ 是相同的，可通过一个问题的性质推导另一个问题的性质 第一个 NPC 问题 ","date":"2023-11-26","objectID":"/blog/posts/algorithm/np-completeness/:7:0","tags":null,"title":"NP Completeness","uri":"/blog/posts/algorithm/np-completeness/"},{"categories":["Linux"],"content":"Types of variables Environment/Global Variables Shell/Local Variables The difference between these two variables is that environment variables can be interviewed by child processes, i.e. the so-called global variables are only shared within the process hierarchy of the current process（进程链）, existing only between the current process and its child processes. Environment variables of other processes and those of the current process are not shared. But Shell variables can only be interviewed by current process. ","date":"2023-11-24","objectID":"/blog/posts/linux/variables-in-linux/:1:0","tags":null,"title":"Variables in Linux","uri":"/blog/posts/linux/variables-in-linux/"},{"categories":["Linux"],"content":"Related commands env set export declare ","date":"2023-11-24","objectID":"/blog/posts/linux/variables-in-linux/:2:0","tags":null,"title":"Variables in Linux","uri":"/blog/posts/linux/variables-in-linux/"},{"categories":["Linux"],"content":"View variables env is used to print the Environment Variables. set/declare is used to print the Shell Variables and Environment. echo $\u003cvariable name\u003e is used to print any single variables. There is a fallible point, set is only used to view the variables, if we want to create a variable, we can use export \u003cvariable-name\u003e=\u003cvariable-value\u003e, declare -x \u003cvariable-name\u003e=\u003cvariable-value\u003e or use \u003cvariable-name\u003e=\u003cvariable-value\u003e directly. ","date":"2023-11-24","objectID":"/blog/posts/linux/variables-in-linux/:2:1","tags":null,"title":"Variables in Linux","uri":"/blog/posts/linux/variables-in-linux/"},{"categories":["Linux"],"content":"Edit variables export is used to transform a Shell Variable to a Environment Variable so that child processes can inhert the environment of parent process. declare -x is used to transform a Shell Variable to a Environment Variable, it is like export command. The following picture summaries the usages of all commands mentioned above well. Note: The red words represent the command, the dotted lines represent the access to the variables. Since we have learned about the usages and meanings of all these commands, so let us try to understand the difference between environment variables and shell variables with the picture. How can we verify the sentence “environment variables can be interviewed by child processes but Shell variables can only be interviewed by current process” ? Referring to the Comparison of Shell Script Execution Modes, we can use shell script to verify it. # a.sh name=\"file a\" bash b.sh # b.sh echo \"b out: $(set | grep name)\" # result % bash a.sh According to the Comparison of Shell Script Execution Modes, becauce a.sh use the bash, so a.sh is in the parent process and b.sh is in the child process and the name variable is just a shell variable which is a private data in process where a.sh locates in. So b.sh can’t access this variable. # a.sh name=\"file a\" export name bash b.sh # b.sh echo \"b out: $(set | grep name)\" # result % bash a.sh b out: name='file a' Because a.sh use the export, so the name variable becomes to a environment variable, althought b.sh is in the child progress, it can access this variable. ","date":"2023-11-24","objectID":"/blog/posts/linux/variables-in-linux/:2:2","tags":null,"title":"Variables in Linux","uri":"/blog/posts/linux/variables-in-linux/"},{"categories":["Linux"],"content":"Reference [1] The Bash environment | The Linux Documentation Project [2] 第十一章、认识与学习 BASH | 鸟哥的Linux私房菜 ","date":"2023-11-24","objectID":"/blog/posts/linux/variables-in-linux/:3:0","tags":null,"title":"Variables in Linux","uri":"/blog/posts/linux/variables-in-linux/"},{"categories":["Compile-Link"],"content":"variables1 It should be noted that the usage of site a variable in makefile is different from using it in shell. In makefile, we use $() to site a variable, which is means that command substitution in shll2 There are three ways to assign for a variable: =: It allows that the subsquent variable uses the following variable. :=: It is same with the assignment symbol in programming language. ?=: If the varible has value, it will do nothing. ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:1:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Wildcard The wildcard in makefile is similar with macro in C/C++, it isn’t similar with wildcard in linux shell, so it doesn’t expend automatically. object1 = *.c // *.c object2 = $(wildcard *.cpp) // main.cpp t1.cpp t2.cpp ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:2:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Automatically generate dependencies Utilizing the -M and -MM options to get the dependencies of source code from gcc/g++. These options’ document can be found at Preprocessor-Options. (About why these option in the preprocessor options, it is easy to understand. In the state of preprocessor, the preprocessor will judge the header file, so it knows which files are dependented by current file.) ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:3:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Hide commands themself Place @ front of the command, e.g. If you use echo \"compiling...\" in makefile, you will get the output echo \"compiling...\" compiling... If you use @echo \"compiling...\", you will get the output compiling... ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:4:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Function ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:5:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Automation variables $@ : 表示规则中的目标文件集 $% : 仅当目标是函数库文件中，表示规则中的目标成员名 $\u003c : 依赖目标中的第一个目标名字 $? : 所有比目标新的依赖目标的集合 $^ : 所有的依赖目标的集合 $+ : 这个变量很像 $^ ，也是所有依赖目标的集合。只是它不去除重复的依赖目标 ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:6:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Example Advanced makefile usage example code # 编译工具信息 CXX = g++ CFLAGS = -std=c++11 -Wall # 目录信息 SRC_DIR = src BUILD_DIR = build # 源文件列表 SRCS = $(wildcard $(SRC_DIR)/*.cpp) # 生成目标文件列表(目标文件.o和源文件.cpp一一对应) OBJS = $(patsubst $(SRC_DIR)/%.cpp,$(BUILD_DIR)/%.o,$(SRCS)) # 最终目标文件 TARGET = $(BUILD_DIR)/main .PHONY: all clean all: $(TARGET) $(TARGET): $(OBJS) @mkdir -p $(dir $@) # $(dir $@) = $(BUILD_DIR) @$(CXX) $(CFLAGS) $^ -o $@ $(BUILD_DIR)/%.o: $(SRC_DIR)/%.cpp @mkdir -p $(dir $@) @$(CXX) $(CFLAGS) -c $\u003c -o $@ clean: rm -rf $(BUILD_DIR) The above makefile can judge the source code which locates in src directory, and output the object file into the build directory. The following image shows the project file structure. % tree . ├── Makefile └── src ├── funcs.cpp └── main.cpp 2 directories, 3 files After compiling, we will get the following file structure. % tree . ├── Makefile ├── build │ ├── funcs.o │ ├── main │ └── main.o └── src ├── funcs.cpp └── main.cpp 3 directories, 6 files There are some noteworthy points. $^ and $\u003c Using the same file structure and editing the makefile, we can understand the difference between these two automation variables. # 编译工具信息 CXX = g++ CFLAGS = -std=c++11 -Wall # 目录信息 SRC_DIR = src BUILD_DIR = build # 源文件列表 SRCS = $(wildcard $(SRC_DIR)/*.cpp) # 生成目标文件列表(目标文件.o和源文件.cpp一一对应) OBJS = $(patsubst $(SRC_DIR)/%.cpp,$(BUILD_DIR)/%.o,$(SRCS)) # 最终目标文件 TARGET = $(BUILD_DIR)/main .PHONY: all clean all: $(TARGET) $(TARGET): $(OBJS) @echo \"\\n\" @echo $^ $(BUILD_DIR)/%.o: $(SRC_DIR)/%.cpp @ echo $\u003c clean: rm -rf $(BUILD_DIR) After we excute the make command, we will get the result. src/funcs.cpp src/main.cpp build/funcs.o build/main.o Based on the project file structure, we can understand the difference between them. ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:7:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Pattern-specific Variable Values The most obvious and easy example is distinguishing the difference between $\u003c and $^ in Automation variables. i.e. the difference between $(BUILD_DIR)/%.o: $(SRC_DIR)/%.cpp and $(OBJS): $(SRCS) Although we know the $\u003c is the name of the first prerequisite and $^ is the names of all the prerequisites, if we don’t know the difference of the above expression of target: prerequisites, we can’t understand the result of the g++ $(CFLAGS) -c $\u003c -o $@. In short, if we still use the above file structure, when using $(OBJS): $(SRCS), the $(OBJS) is the build/funcs.o build/main.o, they are one expression, but using $(BUILD_DIR)/%.o: $(SRC_DIR)/%.cpp, the $(BUILD_DIR)/%.o is build/funcs.o and build/main.o, they are two expressions, it looks like a enumation, so we can use this to generate the corresponding .o object file and .c source file. ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:8:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["Compile-Link"],"content":"Reference [1] GNU Make Manual [2] What does ‘make install’ do? 使用变量 | 跟我一起写Makefile ↩︎ 命令替换 ↩︎ ","date":"2023-09-16","objectID":"/blog/posts/compile-link/makefile/:9:0","tags":null,"title":"Makefile","uri":"/blog/posts/compile-link/makefile/"},{"categories":["C-C++","HPC"],"content":"Asynchronization (Multithreading) The first thing we need to do is understanding the correlations between multithreading and parallel computing. Multithreading is one of the many ways to implement parallel computing. Why do we need asynchronous mechanisms ? If we excute some time-consuming operations in main thread, they will block main thread which causes the bad user experience. An effective way to solve this problem is to use asynchronous mechanisms. Creating a child thread that is asynchronous with main thread and the time-consuming operation can be done by child thread, main thread can continue do its work. The asynchronous mechanisms between main thread and child thread can improve parallelism and performance. But we need some mechanisms to adjust execution orders of multiple child threads to solve the resource competition issues and avoid data access conflict. That is synchronous mechanisms, it ensures the correctness of programs execution results by adjusting the exection order of multiple threads. How do we implement asynchronous mechanisms std::thread C++11 provides thread support in language level, std::thread example code #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cfunctional\u003e #include \u003cchrono\u003e void func2() { std::this_thread::sleep_for(std::chrono::seconds(2)); std::cout \u003c\u003c \"func2\" \u003c\u003c std::endl; } int main() { std::function\u003cvoid()\u003e func1 = []() -\u003e void { std::this_thread::sleep_for(std::chrono::seconds(1)); std::cout \u003c\u003c \"func1\" \u003c\u003c std::endl; }; std::thread t1(func1); std::thread t2(func2); std::cout \u003c\u003c \"thread executing\" \u003c\u003c std::endl; t1.join(); t2.join(); return 0; } Why C++ use term “join” to represent blocking the current thread until the thread identified by *this finishes its execution ? The term “join” in the context of threading comes from the concept of joining or combining the execution of multiple threads back into a single flow of control. When you call join() on a thread object, you are essentially saying that you want to wait for that thread to complete its execution before the current thread continues. The above is the official explanation for term “join”. But according to this statement, in my opinion, the usage main_thread.join(son_thread) is more resonable. So we can explain it from another aspect, i.e. visualization: Imagine threads as separate paths or streams of execution in a program. When you “join” a thread, it’s as if you are waiting for that thread to merge or combine its results or progress with the current thread. This visual analogy helps in understanding the purpose of the function. std::promise、std::packaged_task 、std::async They all can create an asynchronous operation. std::future: std::future can help us to solve this problem, it has three states and three ways to get its state. std::promise: It looks like the code promises it will provide a result in the future, at that time, you can get a result. std::packaged_task: It looks like the code promise it will do something in the future, at that time, you can get a result. We can note that the promise and packaged_task both mentions future, in fact, you both use std::future to provide a result. std::promise example code #include \u003cthread\u003e #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::vector\u003cint\u003e numbers = { 1, 2, 3, 4, 5, 6 }; std::promise\u003cint\u003e accumulate_promise; std::thread child_thread([\u0026]() { int sum = 0; for (std::vector\u003cint\u003e::iterator pointer = numbers.begin(); pointer \u003c numbers.end(); pointer++) { sum += *pointer; } accumulate_promise.set_value(sum); }); std::future\u003cint\u003e accumulate_future = accumulate_promise.get_future(); // get() function only ensures that future has a valid result, but child thread maybe don't finish at this time. So we also need to use join() function std::cout \u003c\u003c \"result=\" \u003c\u003c accumulate_future.get() \u003c\u003c std::endl; child_thread.join(); // wait for thread completion return 0; } std::packaged_task example code #include \u003ciostream\u003e #include \u003cfuture\u003e #include \u003cfunctional\u003e int main() { // auto sum = []","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:1:0","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["C-C++","HPC"],"content":"Synchronization There are some common approaches to implement the synchronous mechanisms, they are semaphore mutex condition variable atomic What is the relationship between semaphore、mutex and condition value ? semaphore -\u003e mutex mutex + semaphore -\u003e condition variable condition variable + mutex -\u003e semaphore Why we need to use the synchronous mechanisms ? When multiple threads or processes use the shared variables, writing at the same time will cause the wrong result. We need to use the synchronous mechanisms to adjust different execution index of threads and processes. How can we understand the role of mutex and atmotic ? We can use mutex to wrap many statements and use atmotic to implement one operation. And mutex is a heavy operation and atomic is a light operation, we ought to select the suitable tool to finish our work. ","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:2:0","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["C-C++","HPC"],"content":"Locking (Mutex) Using common-style locks, which ought to be released manually by this.lock() and this.unlock() std::mutex std::recursive_mutex std::timed_mutex std::recursive_timed_mutex These common-style locks have disadvantages, they must be released manually, if we forget this process, program will appear problems. So we can use the second type of locks. Using RAII-style locks, which can manage locks automatically. They like a package for common-style locks. std::lock_guard std::scoped_lock std::unique_lock The simplest way Using std::mutex to create a lock object, this.lock() to lock this mutex, this.unlock() to unlock this mutex. ","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:2:1","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["C-C++","HPC"],"content":"Atomic What we need to do to get an atomic is just finish this subsitutation int counter = 0 -\u003e std::atomic\u003cint\u003e counter = 0. Then we can use the counter as a ordinary variable. It look like the following code. #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003catomic\u003e int main() { //int counter{0}; std::atomic\u003cint\u003e counter{0}; std::thread t1([\u0026]() -\u003e void { for (size_t i = 0; i \u003c 10000; i++) counter += 1; }); std::thread t2([\u0026]() -\u003e void { for (size_t i = 0; i \u003c 10000; i++) counter += 1; }); t1.join(); t2.join(); std::cout \u003c\u003c \"counter = \" \u003c\u003c counter \u003c\u003c std::endl; return 0; } Which operators does atomic support ? Another two important functions are compare_exchange_weak and compare_exchange_strong, which are abbreviated as CAS(Compare And Swap) in many places. We can use them to implement above any one fetch_xxx functions. ","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:2:2","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["C-C++","HPC"],"content":"Note The performance of compiling programs in Linux and macOS is different, e.g. in Linux, we need to use the -pthread option when preprocessing and linking. But in macOS, we needn’t use this option. The reason is that Linux uses the POSIX thread library and macOS uses the Grand Central Dispatch（GCD）. The compiler in macOS will link GCD automatically, so we needn’t link it manually. ","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:3:0","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["C-C++","HPC"],"content":"Reference [1] 如何理解std::async、std::future、std::promise、std::packaged_task [2] Concurrency support library - cppreference a development process: use std::thread directly（when main thread ends, although son thread is excuting, it also ends） use std::thread::join to command main thread to wait for son thread when son thread is used in function, if function ends, the thread object as a class, it has a deconstruction function, it will destruction the son thread, so you can use detach to avoid thread object to control the excution of son thread use global variable to store son thread created by function, and at the last of the main thread, use std::thread::join to block the main thread until all son threads finish their execution. a problem of the forth way is that we need to excute the std::thread::join manually. In the final analysis, thread is also a type of resource, so we can refer to the RAII thought, use a class to control this resource. ","date":"2023-09-10","objectID":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/:4:0","tags":null,"title":"C++ asynchronous and synchronous mechanisms","uri":"/blog/posts/c-c++/c++-asynchronous-and-synchronous-mechanisms/"},{"categories":["Git"],"content":"Data Model The following pseudo code can explain the git data model clearly. Firstly, we will talk about the three models in git. // a file is a set of data type blob = array\u003cbyte\u003e // a directory which concludes files and directories type tree = map\u003cstring, tree | blob\u003e // every commit concludes a parent, metadata and top tree type commit = struct { parent: array\u003ccommit\u003e author: string message: string snapshot: tree } How should we understand the bolb, tree and commit? In my opinion, the best way to understand these three data models in git is to follow the tutorial or experiment of the offical website(中文版). I will introduce this tutorial from a macro perspective. The experiment process is diveded into three parts. Introduces the concept of blob Use the command git-hash-object to understand the object id of blob Use the process of editing the test.txt to understand the version control preliminarily Create test.txt, then write some content (such as “version 1”) to it and last create a object id for it Edit the content of test.txt (such as the content becomes to “version 2”) and create a new object id for it Delete the original file test.txt, you will find you can use the content id to restore the content of test.txt Introduce the concept of tree Add the test.txt (the content is “version 1”) to index (staging area) Create a object id for current staging area Create a new file named new.txt Add the test.txt (the content is “version 2”) and new.txt to index Create a object id for current staging area Add the first object of staging area to the second object of staging area Learn about the concept of commit Commit the first tree Commit the second tree and specify the parent commit is the first commit Commit the third tree and specify the parent commit is the second commit The commands which are used in experiment are placed in the commends at the end of the text After the experiment, we will have a deeper understanding of these three data models. A premise is that git need to complete the requirements of version control. At an abstract level, blob、tree and commit are three data models in git. At an physical level, Blob、tree and commit are a ordinary binary file that saves the content and other information of file or directory. The uniqueness of them lies in the name, they were named by the hash value of the content and other information, which is calld object id of the file. In order to get a depper understanding of these statements, we need to pay attention to the actual physical file of these models. When we create a blob for a file, we will find that a new file shows up in the .git/objects. Although we delete the original file, we can use blob to restore it. In other words, the blob save the content of the file. Creating a tree concludes two parts, the first one is to put some files or directories into staging area, after this operation, we will find a new file named index shows up in the .git. The second one is to create a tree for staging area, we will find a new file shows up in the .git/objects, its format is same as a blob. When we create a commit for a tree (a commit can only be created for a tree), we will find a new file shows up in the .git/objects Let us comb the logical relationship of blob、tree and commit. A blob can save the content of file, but it can’t save the filename and catalog relationship. So git introdces the tree, it can save the filename and catalog relationship. But tree can’t save other information such as commitor and commit time and we can’t understand the meaning of hash value (such who did what), so git introduces the commit, bases on the tree and add other useful information. Secondly, let us see the concept of object in git. // a object in git may be a blob(file), tree(directory) or commit(or snapshot, a state at a certain moment) type object = blob | tree | commit // git maintenances a big dictionary, which uses a string as a key to index an object objects = map\u003cstring, object\u003e // how does git st","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:1:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"staging area 暂存区目前比较难理解，尤其是其内容的变化不知道是如何进行的，以及tree该如何理解 Staging area is a middle state between current state and snapshot/commit. If you have created many modifications, and you only want to use some of them to create a snapshot. Now, using current state to create a new snapshot/commit directly is inconvenient, Every staging area is a tree, it is like a directory, which concludes some files and/or some directories. Tree is also a object in git, so there is a hash string of tree in .git/objects. If you use the command git cat-file -p to get the value of a tree object, you will find its content is some files and/or some directories. ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:2:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Movement ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:3:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"HEAD movement Using relative reference You can use ^ operator to move to a previous state, such as main^ and HEAD^. And you can use multiple operators to move to multiple previous states. To simplify the operation of multiple states movement, you can use ~ operator. For example, HEAD~2 and HEAD^^ are equivalent. ^ + \u003cnumber\u003e isn’t similar with ~ + \u003cnumber\u003e, its usage is shown in the following figure. ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:3:1","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Branch/Commit movement Merge branches The begining state is shown in the following figure: git merge xxx Assuming current branch is main, you want merge bugFix branch into main, you can excute git merge bugFix, the result is shown in the following figure. git rebase xxx Assuming current branch is bugFix, you want merge bugFix branch and main and you want keep just one record line of commit, you can excute git rebase main, the result is shown in the following figure. git rebase xxx means moving current branch to the xxx branch, git rebase yyy xxx means moving xxx branch to the yyy branch An important and easily overlooked point is that excute an rebase command to a commit doesn’t mean just move this commit to the target commit, it will find the lowest common ancestor between source branch and target branch, move the source commits below the LCA to the target branch (below the latest commit) following the original index. If the work of using command git rebase to adjust the branch is too complex, you can use the interactive version of rebase. Just add a extra parameter -i (interactive). Revoke changes The begining state is shown in the following figure: git reset xxx After you excute the command git reset HEAD^, the main back to the previous commit. What need we notice is that the c2 changes don’t disappear, these changes just don’t add to staging area. git revert xxx If we are editing a remote branch which need to be shared with other people, we need to use this command. After we excute the command git revert HEAD The difference between the two commands is that the latter command create a new commit, which can be push to the remote, so that other people can see the change. Move the specify commit git cherry-pick commit... In software development, the term cherry-pick is used to describe the action of choosing specific commits from one branch and applying them to current branch. It is derived from the analogy of a tree with branches that have many cherries (commits). The begining state is shown in the following figure Now we are in the main branch, after we excute the command git cherry-pick bugFix, the bugFix branch will be applied into current main branch. The result is shown in the following figure. If you select multiple commits when you use this command, it will pick the commit one by one, its role is similar with git rebose -i ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:3:2","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Realistic scenarios select a specific historical commit to commit The scenario is that you just want to select the bugFix branch to merge with main and to commit. You can switch to the main branch, then use the git cherry-pick bugFix to select the bugFix branch. The result is shown in the following figure. edit the previous commit Note: I still don’t know the way of datas change, when we use the git rebase -i to edit many commit. Your task is that edit the newImage commit. Firstly, excute git rebase -i HEAD~2, adjust the index of rebasing, get a result that is shown in the following figure. Secondly, edit in the newImage branch, then excute git commit --amend. Thirdly, excute git rebase -i HEAD~2, adjust the index of rebasing. At last, switch to main branch and excute git rebase caption to move the main to the caption. You can also use the git cherry-pick to solve this problem ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:4:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Tag git tag \u003ctag_name\u003e \u003ccommit\u003e: create a tag named tag_name at specify commit ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:5:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Remote warehouse ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:6:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"git fetch download commit records which don’t exist in local from remote update the remote reference git fetch is equivalent to download data from remote, it doesn’t edit the local date such as local reference Parameters for the git-fetch 参数 git fetch origin foo: download the data from remote foo branch :参数 download the remote source branch to the local destination branch, for example If the source is null, the command will create a new local destination branch ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:6:1","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"git pull Because git fetch just download the remote data, we need edit the local data manually. So git pull will complete two works of download remote data and merge the remote and local reference. The local and remote structure is shown in the following figure. After we excute the command git fetch, the remote reference go ahead one step. Then we excute the command git merge o/main. If we excute git pull, we can get the same result. All in all, git pull = git fetch + git merge ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:6:2","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"git push git pull --rebase = git fetch + git rebase Before push the local commit, maybe we need to handle some special situations. c3 bases on c1, but remote branch has gone to the c2, so direct git push operation fails. We need git fetch to gain the remote warehouse data, then merge the data, at last push the data to the remote. And we can also use the git merge to substitute the git rebase Parameters for the git-push git push \u003cremote\u003e \u003cplace\u003e After setting up the mapping, you can use origin as the remote directly. Place means the source of data for commit to the remote warehouse. git push origin : When we set the mapping relationship between source and destination at origin, we can use the command git push origin source directly, but if we don’t set it, we need give this information for git. If the source is null, the command will delete the remote destination branch ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:6:3","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Remote tracking The remote tracking means that you can specify a branch to track a remote branch. Think about it, why when we commit an main branch, it will commit to the main branch in remote warehouse. The reason is that the local main branch maps to the original main branch. You can use git branch -u original/main side to set the side branch to track the remote main branch, after it, you can git push directly at side branch. The result of changing the map relationship is shown in the following figure. ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:7:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":".gitignore 需要注意的一点是 .gitignore 只能忽略那些原来没有被 track 的文件，如果某些文件已经被纳入了版本管理中，则修改 .gitignore 是无效的 1 There are two situations we need to think about: If the file is not be tracked, we can add it into the .gitignore directly and we needn’t to do other things. If the file is commited to the repository, we need to delete it first from the git. We can use git rm --cached or git rm -f command and then push the changes to the repository. The difference between git rm --cached and git rm -f git rm --cached 仅从 Git 的暂存区中删除文件，而不会删除工作目录中的实际文件，执行这个命令后，文件将被标记为未追踪状态，并且不再包含在下一次提交中，通常用于停止 Git 跟踪已经添加到版本控制中的文件，但希望保留在工作目录中的情况 git rm -f 从 Git 的暂存区中强制删除文件(-f)，并且同时从工作目录中删除实际的文件，执行这个命令后，文件将被完全从版本控制中移除，并且不再包含在下一次提交中，通常用于彻底删除文件，包括从版本控制中移除并从工作目录中清除 Next, we will give an example to illustrate the usage of these two commands As we all know, there is a .DS_Store file in macOS，which is called macOS Desktop Services Store. If we don’t use a .gitignore, we will push it to the repository. Now, assuming we have already submitted this file to the repository, how can we do to delete it from the repository? We can find all files named .DS_Store and the use the command git rm --cached .DS_Store or git rm -f .DS_Sotre (according to your read requirement) to delete them. It is suitable for situations with a small number of files. If we have too many files to delete, we can combine other command line tools and git. For example, we can use find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatch to delete all the .DS_Store files in current path. 2 ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:8:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"global config of .gitignore We can use git config --global core.excludesfile \u003c.gitignore global config file path\u003e to specify the global .gitignore file. 3 4 5 之所以添加多个参考，是因为目前对于 .gitignore 中的写法规则不是很明确，几个参考文章中给出的均不相同 ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:8:1","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Comments ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:9:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"The commands which are used in experiment ————————————————————————————————— control the ordinary file // create hash string of object from standord input and file git hash-object -w --stdin git hash-object -w test.txt // get the value of object by hash string: git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4 // judge the type of object: git cat-file -t 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a ————————————————————————————————— control the staging area // index is a equivalent concept of staging area // select a file and put it into the staging area git update-index --add test.txt //what is the meaning of parameter cacheinfo？ // Now, in the working area, you just have one file named test.txt, but this file has twe versions because of different file content, such as version 1 and version 2. // The file is version 2 now, but you only want to use version 1 to update index, so you can use the parameter cacheinfo to specify to use version 1. git update-index --add --cacheinfo 100644 83baae61804e65cc73a7201a7252750c76066a30 test.txt // create an object id for staging area which concludes selected files and directories git write-tree ————————————————————————————————— // control the commit object echo 'first commit' | git commit-tree d8329f echo 'second commit' | git commit-tree 0155eb -p fdf4fc3 ————————————————————————————————— // control the reference // create a new reference, the object must be a commit git update-ref refs/heads/main \u003cobject id\u003e // determine which branch now git symbolic-ref HEAD // edit the HEAD git symbolic-ref HEAD refs/haeds/other ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:9:1","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Git"],"content":"Reference [1] version control - missing-semester [2] Learn Git Branching [3] Pro Git book .gitignore 不生效原因及解决方法 ↩︎ 快速清理已经上传到Git仓库的.DS_Store文件 ↩︎ Git 在 macOS 中忽略所有 .DS_Store 文件 ↩︎ Mac中Git忽略.DS_Store文件 ↩︎ Git全局排除配置 ↩︎ ","date":"2023-08-13","objectID":"/blog/posts/git/version-control-system/:10:0","tags":null,"title":"Version Control System","uri":"/blog/posts/git/version-control-system/"},{"categories":["Linux"],"content":"方法概览 % echo \"echo 'Hello Script'\" \u003e script.sh ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:1:0","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"方式1：直接运行可执行文件 % chmod +x script.sh % ./script.sh Hello Script ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:1:1","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"方式2：使用命令 sh 或 bash % sh script.sh Hello Script % bash script.sh Hello Script ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:1:2","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"方式3：使用命令 source 或 . % source script.sh Hello Script % . ./script.sh Hello Script ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:1:3","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"两种分类方法 ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:2:0","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"是否需要执行权限 只有方式1需要执行权限。这是因为方式1把脚本作为可执行文件，自然需要执行权限，但方式2和方式3都是把脚本作为命令的参数，可以不具备执行权限 ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:2:1","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"是否会创建子进程 只有方式3不会创建子进程，会直接在当前shell环境中执行（主要区别在于变量的作用域，父子进程变量的继承关系） 实验验证 实验原理：子进程能够共享父进程数据，但父进程无法获取子进程设置的数据 实验方法：通过两个文件A和B，A负责设置一个变量，由B以不同方式执行A。若A和B处在相同的shell环境中，则B能够访问到A设置的变量，反之则不同。通过查看B能否访问到A设置的变量来确定A的执行方式是否会创建子进程 实验流程（以source和bash执行A为例）： # 使用source命令执行A，由于source并不会让A在子进程中执行，因此B能够访问到同一进程中的变量 # f_a.sh var=show #f_b.sh source f_a.sh echo $var # result % bash f_b.sh show 由于f_b文件在执行f_a时使用的是source，并不会在子进程中执行f_a中的command，f_a和f_b处于同一个进程下，所以f_b可以访问到var # 使用sh命令执行A，由于sh会让A在子进程中执行，由于B在父进程中，因此无法访问到变量值 # f_a.sh var=show # f_b.sh bash f_a.sh echo $var # result % bash f_b.sh 由于f_b文件在执行f_a时使用的是bash，会在子进程中执行f_a中的command，f_b由于在父进程中，所以f_b无法访问到子进程中的变量var 注：在此过程中，需要了解单引号和双引号在终端中的以下几点 双引号内的变量会被解析，转义字符会被处理，并且可以嵌套使用单引号 单引号内的变量不会被解析，转义字符会被视为普通字符，并且可以嵌套使用双引号 以上的两个执行已经验证了之前的判断，不过有一个容易被忽视的点，即执行f_b.sh时选择的方式。根据f_b.sh和f_a.sh的执行方式的组合（以source和bash为例），可以得到下图 也就是说，参与进来的进程数量最少是1，即当前进程在执行f_b.s时没有创建子进程，f_b.sh在执行f_a.sh时也没有创建子进程；参与进程数量最多是3，即两个执行过程都创建了子进程。 理解到2个执行阶段的情况，这一整个实验的验证原理才算完整。 ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:2:2","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"采用何种解释器执行脚本? 在脚本文件的第一行可以添加shebang（也称为hashbang）行，指定要用于解释和执行该脚本的解释器 在方式2中，sh命令和bash命令并不受shebang行的影响，sh命令则使用sh解释器，bash命令使用bash解释器 在方式1和3中，添加了shebang行则按照shebang指定的解释器执行，若未添加，则使用系统默认的解释器（根据环境变量$SHELL）来执行脚本 shebang不仅可以指定使用shell脚本采用的解释器，也可以指定使用python解释器，例如 #!/usr/local/bin/python 这样的问题在于不具备可移植性，当环境发生改变时，python的路径可能会发生改变，此时解释器的路径就不再奏效 一种解决方案是采用env命令，将shebang修改为#!/usr/local/bin/python（尚未了解shebang的核心机制），能够根据$PATH定位当前环境下的python解释器路径 ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:3:0","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["Linux"],"content":"注意事项 假设在当前路径下存在一个script.sh，点命令的正确且唯一的执行方式是. ./script.sh，其他命令则可以采用command script.sh ","date":"2023-07-27","objectID":"/blog/posts/linux/comparison-of-shell-script-execution-modes/:4:0","tags":null,"title":"Comparison of Shell Script Execution Modes","uri":"/blog/posts/linux/comparison-of-shell-script-execution-modes/"},{"categories":["C-C++"],"content":"普通类型 ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:1:0","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"类类型 对于类类型,编译器只能自动执行一步隐式类型转换.例如从字符串字面值转换为string类型,但是无法继续将string隐式转换为其他类型 ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:2:0","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"新式显示类型转换 格式 cast-name(expression); ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:3:0","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"static_cast Any well-deﬁned type conversion, other than those involving low-level const, can be requested using a static_cast. // i and j are both int type, double slope = static_cast\u003cdouble\u003e(j) / i; // perform a conversion that the compiler will not generate automatically. // converts void * back to the original pointer type void * p = \u0026d; double * dp = static_cast\u003cdouble * \u003e(p); We should note that, the difference between static_cast and C style cast is that if you try to cast an entity which is not compatible to another, then static_cast gives you an compilation time error unlike the implicit c-style cast. So, static_cast also can’t handle the compatible type cast, we should not recognize that we can use it to implement any type conversion we want. A real example, when I want to use a int type variable to edit the element in a std::string, I use the following commands, and I got an error which is difficult to find. std::string str = \"000\"; str[0] = static_cast\u003cchar\u003e(1); When I execute std::cout \u003c\u003c str, I got nothing. Until I use the gdb/lldb, I find the result of static_cast\u003cchar\u003e(1) is '\\x01', it is not the ‘1’ or 49(the ASCII of ‘1’) which I expected. What is the \\x01? \u0026\u0026 Why we get it? Before encountering this problem, I don’t know the principle of static_cast. In fact, static_cast cut out the low 1 byte (the length of char) of the number waitring to be converted. The \\x01 is the content of that 1 byte. Maybe we will confused with the difference between 1 + '0' and static_cast\u003cchar\u003e(1). In fact, the former is not a type conversion, it just add 1 to the ASCII of the character ‘0’. ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:3:1","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"const_cast const_cast only be used to change the constness of an expression. const void *p1 // convert const void * to void * void *p2 = const_cast\u003cvoid *\u003e(p1); // convert void * to int * int *p3 = static_cast\u003cint *\u003e(p2); It is different from the static_cast, which only be used to change the type of an expression. i.e. if we use static_cast to change the constness of an expression or const_cast to change the type of an expression, we will get a compile-time error. const char * cp; // error: static_cast can’t cast away const char * q = static_cast\u003cchar * \u003e(cp); // error: const_cast only changes constness const_cast\u003cstring\u003e(cp); ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:3:2","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"reinterpret_cast performs a low-level reinterpretation of the bit pattern of its operands. int * ip; char * pc = reinterpret_cast\u003cchar * \u003e(ip); It is worth noting that reinterpret_cast is dangerous. As the following code shows. int * ip; char * pc = reinterpret_cast\u003cchar * \u003e(ip); string str(pc); We ought to know that no matter what type of pointer it is, the pc itselt is just a address(a number) and the type shows the type of object addressed by this pointer. So the actual object addressed by pc is an int, not a character. Any use of pc that assumes it’s an ordinary character pointer is likely to fail at run time. But about string str(pc), the compiler has no way of knowing that it actually holds a pointer to an int. Thus, the initialization of str with pc is absolutely correct—albeit in this case meaningless or worse. ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:3:3","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"dynamic_cast ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:3:4","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"Reference [1] 关于编码、X 进制、Python3 字符串的那些事儿 ","date":"2023-06-18","objectID":"/blog/posts/c-c++/c++-type-conversion/:4:0","tags":null,"title":"C++ Type Conversion","uri":"/blog/posts/c-c++/c++-type-conversion/"},{"categories":["C-C++"],"content":"在了解创建对象的方式之前，首先了解一下初始化和赋值两个操作， 初始化是创建变量时赋予其一个初始值，即初始化之前并不存在变量 赋值是把对象的当前值擦除，用新值代替旧值，即赋值之前存在变量 让人困惑的是=既可以用于初始化，也可以用于赋值，不要认为初始化和赋值是相同的操作 关于默认值（默认初始化），值和变量类型和位置决定 函数体外部的内置类型默认初始化为0 函数体内部的内置类型不被默认初始化，数值为未定义 需要注意的是，这里的函数体是不包括main函数的，实测main函数内部的内置类型即使不被初始化，其值也为0 四种方式分别为 等号，圆括号，花括号,最后一种是等号和花括号一起使用 int a = 0; int a(0); int a{0}; int a = {0}; 其中，等号和圆括号是以前就存在的，使用花括号进行初始化或赋值是C++11新标准引入的。 需要理解的是=在这里代表的是初始化而非赋值，而且在实际使用中我们通常会忽略\"=“和花括号组合初始化的语法，因为C++通常把它视作和只有花括号一样。所以说我们关键要看的就是下面这3种方式。 int a = 0; int a(0); int a{0}; 其中，比较难区分的是圆括号和花括号，当然在上述代码中由于他们起到的效果是相同的，因此并不难区分。以vecotr为例，介绍他们的不同之处 花括号内的值和容器内元素类型相同是为列表初始化，否则根据给定容量和值初始化。即花括号内的内容可以是以下几种类型 花括号内元素类型均为容器内元素类型 花括号内元素类型不完全相同 并且顺序为 数字 + 和容器内元素类型相同的元素 vector\u003cint\u003e v1{10, 1}; // 第一种情况，列表初始化，v1包含两个元素10和1 vector\u003cstring\u003e v2{10, \"1\"}; // 第二种情况，列表初始化，v2包含10个值为“1”的元素 圆括号只能根据给定容量和值进行初始化，即圆括号内的内容只能是以下两种之一 数字 数字 + 与容器内类型相同的元素 vector\u003cint\u003e v3(10); // 正确，v3有10个元素，每个值为默认值0 vector\u003cstring\u003e v4(10, \"hi\"); // 正确，v4有10个元素，每个值为“hi” vector\u003cstring\u003e v5(\"hi\"); // 错误，必须包含数字 使用花括号具有2个优点: 防止变窄转换: 大括号不支持变窄转换，等号和圆括号为了向下兼容支持变窄转换。 long double ld = 3.1415926; int a{ld}, b = {ld}; // 错误，因存在变窄转换，花括号初始化禁止这种行为 int c(ld), d = ld; // 正确，虽然存在信息丢失，但圆括号和等号并不会禁止这种行为 免疫C++最令人头疼的解析: C++规定任何可以被解析为一个声明的东西必须被解析为声明，因此无法区分无参的构造函数和函数声明，此规则会默认其为函数声明 花括号初始化共包含2种用途 变量的列表初始化1 int a = {0}; int a{0}; 构造函数初始值列表2 class myClass { private: int a; int b; public: myClass(int para_a, int para_b) : a(para_a), b(para_b) {} }; 构造函数初始值列表由3部分组成：函数头、初始值列表和函数体，成员属性的初始化工作发生在函数体执行之前，因此初始值列表执行的是初始化，而函数值执行的则是初始化后的赋值。 在C++中，const变量、引用和不具备默认构造函数的类类型是无法首先进行默认初始化，然后再赋值，因此在这3种情况下，必须使用初始值列表 同时需要注意的是初始值列表只用于初始化成员的值，并不会限定初始化的具体执行顺序，在涉及到用一成员变量的值初始化另一个成员变量的值时要注意执行顺序 花括号初始化的缺点体现在构造函数的调用顺序方面 直接初始化 并不能简单地把直接初始化理解为不需要使用现存的占据实际空间的对象来初始化其他对象,因为在示例代码中第2个例子虽然使用到了一个现存的对象dots,但是其依然属于直接初始化 直接初始化示例代码 // 好理解的直接初始化 string dots(10, '.'); // 不易理解的直接初始化 string s(dots); 拷贝初始化 需要注意的是第1行示例代码同不易理解的直接初始化的区别,虽然两者都利用了现存的对象dots,但是它们属于不同的初始化方式. 拷贝初始化示例代码 string s2 = dots; string s3 = \"666\"; 涉及到拷贝初始化的场景 使用=定义变量时 一个对象作为非引用类型的形参时 一个返回值类型非引用类型的函数返回一个对象时 使用花括号初始化数组或聚合类 直接使用花括号和等号与花括号一同使用是直接初始化还是拷贝初始化? 如果说以stl中的insert/push同emplace相比,前者进行的是拷贝初始化,后者进行的是直接初始化,那么拷贝和直接的区别就在于是否多经历了一次变量的产生过程,因为push需要首先把待插入的对象真正创建出来然后将其拷贝到另一对象中,而emplace则是直接把数据构造成最终对象 拷贝初始化,拷贝构造函数,拷贝赋值运算符这三者之间的关系容易混淆, 需要明确初始化和赋值的区别,初始化是在对象定义的过程中顺便完成原始值的处理,而赋值是将一个对象赋给一个已存在的对象,初始化的对象是以前不存在的对象,赋值运算符的对象是已经存在的对象 拷贝初始化和直接初始化的区别是否仅仅是是否生成了中间变量 拷贝初始化和直接初始化，这两个说法是独立于 类的成员函数这一概念的。拷贝初始化和直接初始化的本质是初始化，强调的是同赋值这一操作之间的区别，但是他们究竟会调用何种类成员函数是不确定的，直接初始化可能调用构造函数，也可能调用拷贝构造函数。 Reference [1] 区别使用()和{}创建对象 std::initializer_list ↩︎ Constructors and member initializer lists ↩︎ ","date":"2023-06-18","objectID":"/blog/posts/c-c++/comparison-of-c++-object-initialization-method/:0:0","tags":null,"title":"Comparison of C++ object initialization method","uri":"/blog/posts/c-c++/comparison-of-c++-object-initialization-method/"},{"categories":["Compile-Link"],"content":"说明 cmake的定义是什么 ？—–高级编译配置工具 当多个人用不同的语言或者编译器开发一个项目，最终要输出一个可执行文件或者共享库（dll，so等等）这时候神器就出现了—–CMake！ 所有操作都是通过编译CMakeLists.txt来完成的—简单 官方网站是 www.cmake.org，可以通过访问官方网站获得更多关于 cmake 的信息 学习CMake的目的，为将来处理大型的C/C++/JAVA项目做准备 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:1:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"CMake安装 1、绝大多数的linux系统已经安装了CMake 2、Windows或某些没有安装过的linux系统，去http://www.cmake.org/HTML/Download.html 可以下载安装 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:2:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"CMake一个HelloWord 1、步骤一，写一个HelloWord #main.cpp #include \u003ciostream\u003e int main(){ std::cout \u003c\u003c \"hello word\" \u003c\u003c std::endl; } 2、步骤二，写CMakeLists.txt #CMakeLists.txt PROJECT (HELLO) SET(SRC_LIST main.cpp) MESSAGE(STATUS \"This is BINARY dir \" ${HELLO_BINARY_DIR}) MESSAGE(STATUS \"This is SOURCE dir \"${HELLO_SOURCE_DIR}) ADD_EXECUTABLE(hello ${SRC_LIST}) 3、步骤三、使用cmake，生成makefile文件 cmake . 输出： [root@localhost cmake]# cmake . CMake Warning (dev) in CMakeLists.txt: Syntax Warning in cmake code at /root/cmake/CMakeLists.txt:7:37 Argument not separated from preceding token by whitespace. This warning is for project developers. Use -Wno-dev to suppress it. -- The C compiler identification is GNU 10.2.1 -- The CXX compiler identification is GNU 10.2.1 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- This is BINARY dir /root/cmake -- This is SOURCE dir /root/cmake -- Configuring done -- Generating done -- Build files have been written to: /root/cmake 目录下就生成了这些文件-CMakeFiles, CMakeCache.txt, cmake_install.cmake 等文件，并且生成了Makefile. 现在不需要理会这些文件的作用，以后你也可以不去理会。最关键的是，它自动生成了Makefile. 4、使用make命令编译 root@localhost cmake]# make Scanning dependencies of target hello [100%] Building CXX object CMakeFiles/hello.dir/main.cpp.o Linking CXX executable hello [100%] Built target hello 5、最终生成了Hello的可执行程序 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:3:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"CMake一个HelloWord-的语法介绍 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:4:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"PROJECT关键字 可以用来指定工程的名字和支持的语言，默认支持所有语言 PROJECT (HELLO) 指定了工程的名字，并且支持所有语言—建议 PROJECT (HELLO CXX) 指定了工程的名字，并且支持语言是C++ PROJECT (HELLO C CXX) 指定了工程的名字，并且支持语言是C和C++ 该指定隐式定义了两个CMAKE的变量 _BINARY_DIR，本例中是 HELLO_BINARY_DIR _SOURCE_DIR，本例中是 HELLO_SOURCE_DIR MESSAGE关键字就可以直接使用者两个变量，当前都指向当前的工作目录，后面会讲外部编译 问题：如果改了工程名，这两个变量名也会改变 解决：又定义两个预定义变量：PROJECT_BINARY_DIR和PROJECT_SOURCE_DIR，这两个变量和HELLO_BINARY_DIR，HELLO_SOURCE_DIR是一致的。所以改了工程名也没有关系 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:4:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"SET关键字 设置变量值 SET(SRC_LIST main.cpp) # SRC_LIST 变量的值即为 main.cpp SET(SRC_LIST main.cpp t1.cpp t2.cpp) # SRC_LIST 变量的值即为 main.cpp, t1.cpp, t2.cpp 设置 cmake 构建参数 以设置编译模式为例 SET(CMAKE_BUILD_TYPE \"Debug\") # 设置 CMake 编译模式为 Debug SET(CMAKE_BUILD_TYPE \"Release\") # 设置 CMake 编译模式为 Release 设置编译模式除了采用上述方式，还可以直接在编译命令中进行指定 cmake -DCMAKE_BUILD_TYPE=Debug cmake -DCMAKE_BUILD_TYPE=Release ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:4:2","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"MESSAGE关键字 向终端输出用户自定义的信息 主要包含三种信息： SEND_ERROR，产生错误，生成过程被跳过。 SATUS，输出前缀为—的信息。 FATAL_ERROR，立即终止所有 cmake 过程. ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:4:3","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"ADD_EXECUTABLE关键字 生成可执行文件 ADD_EXECUTABLE(hello ${SRC_LIST}) 生成的可执行文件名是hello，源文件读取变量SRC_LIST中的内容 也可以直接写 ADD_EXECUTABLE(hello main.cpp) 上述例子可以简化的写成 PROJECT(HELLO) ADD_EXECUTABLE(hello main.cpp) 注意：工程名的 HELLO 和生成的可执行文件 hello 是没有任何关系的 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:4:4","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"语法的基本原则 变量使用${}方式取值，但是在 IF 控制语句中是直接使用变量名 指令(参数 1 参数 2…) 参数使用括弧括起，参数之间使用空格或分号分开。 以上面的 ADD_EXECUTABLE 指令为例，如果存在另外一个 func.cpp 源文件 就要写成：ADD_EXECUTABLE(hello main.cpp func.cpp)或者ADD_EXECUTABLE(hello main.cpp;func.cpp) 指令是大小写无关的，参数和变量是大小写相关的。但，推荐你全部使用大写指令 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:5:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"语法注意事项 SET(SRC_LIST main.cpp) 可以写成 SET(SRC_LIST “main.cpp”)，如果源文件名中含有空格，就必须要加双引号 ADD_EXECUTABLE(hello main) 后缀可以不行，他会自动去找.c和.cpp，最好不要这样写，可能会有这两个文件main.cpp和main ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:5:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"内部构建和外部构建 上述例子就是内部构建，他生产的临时文件特别多，不方便清理 外部构建，就会把生成的临时文件放在build目录下，不会对源文件有任何影响强烈使用外部构建方式 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:6:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"外部构建方式举例 //例子目录，CMakeLists.txt和上面例子一致 [root@localhost cmake]# pwd /root/cmake [root@localhost cmake]# ll total 8 -rw-r--r--. 1 root root 198 Dec 28 20:59 CMakeLists.txt -rw-r--r--. 1 root root 76 Dec 28 00:18 main.cpp 1、建立一个build目录，可以在任何地方，建议在当前目录下 2、进入build，运行cmake .. 当然..表示上一级目录，你可以写CMakeLists.txt所在的绝对路径，生产的文件都在build目录下了 3、在build目录下，运行make来构建工程 注意外部构建的两个变量 1、HELLO_SOURCE_DIR 还是工程路径 2、HELLO_BINARY_DIR 编译路径 也就是 /root/cmake/bulid ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:6:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"让Hello World看起来更像一个工程 为工程添加一个子目录 src，用来放置工程源代码 添加一个子目录 doc，用来放置这个工程的文档 hello.txt 在工程目录添加文本文件 COPYRIGHT, README 在工程目录添加一个 runhello.sh 脚本，用来调用 hello 二进制 将构建后的目标文件放入构建目录的 bin 子目录 将 doc 目录 的内容以及 COPYRIGHT/README 安装到/usr/share/doc/cmake/ ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:7:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"将目标文件放入构建目录的 bin 子目录 每个目录下都要有一个CMakeLists.txt说明 [root@localhost cmake]# tree . ├── build ├── CMakeLists.txt └── src ├── CMakeLists.txt └── main.cpp 外层CMakeLists.txt PROJECT(HELLO) ADD_SUBDIRECTORY(src bin) src下的CMakeLists.txt ADD_EXECUTABLE(hello main.cpp) ADD_SUBDIRECTORY 指令 ADD_SUBDIRECTORY(source_dir [binary_dir] [EXCLUDE_FROM_ALL]) 这个指令用于向当前工程添加存放源文件的子目录，并可以指定中间二进制和目标二进制存放的位置 EXCLUDE_FROM_ALL函数是将写的目录从编译中排除，如程序中的example ADD_SUBDIRECTORY(src bin) 将 src 子目录加入工程并指定编译输出(包含编译中间结果)路径为bin 目录 如果不进行 bin 目录的指定，那么编译结果(包括中间结果)都将存放在build/src 目录 更改二进制的保存路径 SET 指令重新定义 EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH 变量 来指定最终的目标二进制的位置 SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) 思考：加载哪个CMakeLists.txt当中 哪里要改变目标存放路径，就在哪里加入上述的定义，所以应该在src下的CMakeLists.txt下写 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:7:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"安装 一种是从代码编译后直接 make install 安装 一种是打包时的指定 目录安装。 简单的可以这样指定目录：make install DESTDIR=/tmp/test 稍微复杂一点可以这样指定目录：./configure –prefix=/usr ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:8:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"如何安装HelloWord 使用CMAKE一个新的指令：INSTALL INSTALL的安装可以包括：二进制、动态库、静态库以及文件、目录、脚本等 使用CMAKE一个新的变量：CMAKE_INSTALL_PREFIX // 目录树结构 [root@localhost cmake]# tree . ├── build ├── CMakeLists.txt ├── COPYRIGHT ├── doc │ └── hello.txt ├── README ├── runhello.sh └── src ├── CMakeLists.txt └── main.cpp 3 directories, 7 files 安装文件COPYRIGHT和README INSTALL(FILES COPYRIGHT README DESTINATION share/doc/cmake/) FILES：文件 DESTINATION： 1、写绝对路径 2、可以写相对路径，相对路径实际路径是：${CMAKE_INSTALL_PREFIX}/\u003cDESTINATION 定义的路径\u003e CMAKE_INSTALL_PREFIX 默认是在 /usr/local/ cmake -DCMAKE_INSTALL_PREFIX=/usr 在cmake的时候指定CMAKE_INSTALL_PREFIX变量的路径 安装脚本runhello.sh PROGRAMS：非目标文件的可执行程序安装(比如脚本之类) INSTALL(PROGRAMS runhello.sh DESTINATION bin) 说明：实际安装到的是 /usr/bin 安装 doc 中的 hello.txt 一、是通过在 doc 目录建立CMakeLists.txt ，通过install下的file 二、是直接在工程目录通过 INSTALL(DIRECTORY doc/ DESTINATION share/doc/cmake) DIRECTORY 后面连接的是所在 Source 目录的相对路径 注意：abc 和 abc/有很大的区别 目录名不以/结尾：这个目录将被安装为目标路径下的 目录名以/结尾：将这个目录中的内容安装到目标路径 安装过程 cmake .. make make install ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:8:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"静态库和动态库的构建 任务： １，建立一个静态库和动态库，提供 HelloFunc 函数供其他程序编程使用，HelloFunc 向终端输出 Hello World 字符串。 ２，安装头文件与共享库。 静态库和动态库的区别 静态库的扩展名一般为“.a”或“.lib”；动态库的扩展名一般为“.so”或“.dll”。 静态库在编译时会直接整合到目标程序中，编译成功的可执行文件可独立运行 动态库在编译时不会放到连接的目标程序中，即可执行文件无法单独运行。 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:9:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"构建实例 [root@localhost cmake2]# tree . ├── build ├── CMakeLists.txt └── lib ├── CMakeLists.txt ├── hello.cpp └── hello.h hello.h中的内容 #ifndef HELLO_H #define Hello_H void HelloFunc(); #endif hello.cpp中的内容 #include \"hello.h\" #include \u003ciostream\u003e void HelloFunc(){ std::cout \u003c\u003c \"Hello World\" \u003c\u003c std::endl; } 项目中的cmake内容 PROJECT(HELLO) ADD_SUBDIRECTORY(lib bin) lib中CMakeLists.txt中的内容 SET(LIBHELLO_SRC hello.cpp) ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) ADD_LIBRARY ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) hello：就是正常的库名，生成的名字前面会加上lib，最终产生的文件是libhello.so SHARED，动态库 STATIC，静态库 ${LIBHELLO_SRC} ：源文件 同时构建静态和动态库 // 如果用这种方式，只会构建一个动态库，不会构建出静态库，虽然静态库的后缀是.a ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) ADD_LIBRARY(hello STATIC ${LIBHELLO_SRC}) // 修改静态库的名字，这样是可以的，但是我们往往希望他们的名字是相同的，只是后缀不同而已 ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) ADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC}) SET_TARGET_PROPERTIES 这条指令可以用来设置输出的名称，对于动态库，还可以用来指定动态库版本和 API 版本 同时构建静态和动态库 SET(LIBHELLO_SRC hello.cpp) ADD_LIBRARY(hello_static STATIC ${LIBHELLO_SRC}) //对hello_static的重名为hello SET_TARGET_PROPERTIES(hello_static PROPERTIES OUTPUT_NAME \"hello\") //cmake 在构建一个新的target 时，会尝试清理掉其他使用这个名字的库，因为，在构建 libhello.so 时， 就会清理掉 libhello.a SET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUTPUT 1) ADD_LIBRARY(hello SHARED ${LIBHELLO_SRC}) SET_TARGET_PROPERTIES(hello PROPERTIES OUTPUT_NAME \"hello\") SET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUTPUT 1) 动态库的版本号 一般动态库都有一个版本号的关联 libhello.so.1.2 libhello.so -\u003elibhello.so.1 libhello.so.1-\u003elibhello.so.1.2 CMakeLists.txt 插入如下 SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1) VERSION 指代动态库版本，SOVERSION 指代 API 版本。 安装共享库和头文件 本例中我们将 hello 的共享库安装到/lib目录， 将 hello.h 安装到/include/hello 目录 //文件放到该目录下 INSTALL(FILES hello.h DESTINATION include/hello) //二进制，静态库，动态库安装都用TARGETS //ARCHIVE 特指静态库，LIBRARY 特指动态库，RUNTIME 特指可执行目标二进制。 INSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib) 注意： 安装的时候，指定一下路径，放到系统下 cmake -DCMAKE_INSTALL_PREFIX=/usr .. 使用外部共享库和头文件 准备工作，新建一个目录来使用外部共享库和头文件 [root@MiWiFi-R4CM-srv cmake3]# tree . ├── build ├── CMakeLists.txt └── src ├── CMakeLists.txt └── main.cpp main.cpp #include \u003chello.h\u003e int main(){ HelloFunc(); } 解决：make后头文件找不到的问题 PS：include \u003chello/hello.h\u003e 这样include是可以，这么做的话，就没啥好讲的了 关键字：INCLUDE_DIRECTORIES 这条指令可以用来向工程添加多个特定的头文件搜索路径，路径之间用空格分割 在CMakeLists.txt中加入头文件搜索路径 INCLUDE_DIRECTORIES(/usr/include/hello) 解决：找到引用的函数问题 报错信息：undefined reference to `HelloFunc()' 关键字：LINK_DIRECTORIES 添加非标准的共享库搜索路径 指定第三方库所在路径，LINK_DIRECTORIES(/home/myproject/libs) 关键字：TARGET_LINK_LIBRARIES 添加需要链接的共享库 TARGET_LINK_LIBRARIES的时候，只需要给出动态链接库的名字就行了。 在CMakeLists.txt中插入链接共享库，主要要插在executable的后面 查看main的链接情况 [root@MiWiFi-R4CM-srv bin]# ldd main linux-vdso.so.1 =\u003e (0x00007ffedfda4000) libhello.so =\u003e /lib64/libhello.so (0x00007f41c0d8f000) libstdc++.so.6 =\u003e /lib64/libstdc++.so.6 (0x00007f41c0874000) libm.so.6 =\u003e /lib64/libm.so.6 (0x00007f41c0572000) libgcc_s.so.1 =\u003e /lib64/libgcc_s.so.1 (0x00007f41c035c000) libc.so.6 =\u003e /lib64/libc.so.6 (0x00007f41bff8e000) /lib64/ld-linux-x86-64.so.2 (0x00007f41c0b7c000) 链接静态库 TARGET_LINK_LIBRARIES(main libhello.a) 特殊的环境变量 CMAKE_INCLUDE_PATH 和 CMAKE_LIBRARY_PATH 注意：这两个是环境变量而不是 cmake 变量，可以在linux的bash中进行设置 我们上面例子中使用了绝对路径INCLUDE_DIRECTORIES(/usr/include/hello)来指明include路径的位置 我们还可以使用另外一种方式，使用环境变量export CMAKE_INCLUDE_PATH=/usr/include/hello 补充：生产debug版本的方法： cmake .. -DCMAKE_BUILD_TYPE=debug ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:9:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"头文件 需要首先明确的一点是，一个.h头文件对应一个.cpp文件并非严格要求，只是一种较为规范的写法。由于其他文件需要引用，因此一定是存在.h头文件的，头文件中函数的具体实现可以放置于头文件中，也可以放置于.cpp文件中 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:10:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"引入方式 \u003c\u003e是只在系统目录中搜索 \"\"是优先在当前目录搜索，未找到则进入系统目录搜索 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:10:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"Search Path We can use g++ -xc++ -E -v -1 command to get the processing flow of the preprocess, which contains the search paths of the header file. -x language is used to specify explicitly the language for the following input files (rather than letting the compiler choose a default based on the file name suffix). In my opinion, now, we want to get the processing flow of the c++ file’s proprocess with no input file, so we must specify the input file type manually. -E is the option for prepocessing -v is used to output detail information - 表示接受来自标准输入的输入。此处，未提供实际的源文件，只关心获取编译器信息。 Refer to the official document for detailed information. ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:10:2","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"效果 由于include头文件的实际效果是把头文件的内容插入到文件中，因此 在不支持重载机制的c语言中，当头文件中的声明语句和.cpp中实现语句不同时会报错，可以在编译时就发现错误 当.cpp中实现了多个函数，且函数之间存在相互调用时，添加.h文件可以无需关心函数的实现顺序，因为添加了.h头文件，因此会将声明语句复制到.cpp文件中 引入可以使用相对路径 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:10:3","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"引入第三方库 cmake不过是一个构建工具，其仍然需要完成程序的编译链接过程。 因此这里涉及到的所有函数的作用或者意义都会对应着程序的编译链接中的某一个过程。 因为程序的编译链接无非是要解决头文件和链接库的问题，所以下面讨论的这些情况也都离不开这两个问题。 例如纯头文件库就只需要考虑如何引入头文件；下述例子的子模块不过是在提供了一个头文件之外，还生成了一个静态链接库；第三方库则更进一步，在提供头文件和静态链接库之外，还提供了动态链接库，而且由于纯头文件库和子模块往往都是和原项目位于同一目录下的，因此寻找这些头文件和静态链接库往往是容易的，但是第三方库往往是位于系统的其他某个位置，如何找到它提供的头文件和库就是一个需要重点考虑的问题。 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:11:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"纯头文件库（header-only） 通过 include_directories() 或 target_include_directories() 即可直接使用 target_include_directories()起到的作用是通过指定头文件的搜索路径，可以把自定义头文件当作系统头文件使用 单文件include头文件不使用target_include_directories()示例 functions模拟的是第三方纯头文件库 CMakeLists.txt cmake_minimum_required(VERSION 3.12) project(header_only_demo LANGUAGES CXX) # 构建可执行文件 add_executable(main main.cpp) func.h #ifndef FUNC_H #define FUNC_H #include \u003ciostream\u003e void func() { std::cout \u003c\u003c \"call func()\" \u003c\u003c std::endl; } #endif main.cpp #include \"functions/func.h\" int main() { func(); return 0; } 单文件include头文件使用target_include_directories()示例 functions模拟的是第三方纯头文件库 CMakeLists.txt cmake_minimum_required(VERSION 3.12) project(header_only_demo LANGUAGES CXX) # 构建可执行文件 add_executable(main main.cpp) # 指定头文件搜索路径 target_include_directories(main PRIVATE ./functions) func.h #ifndef FUNC_H #define FUNC_H #include \u003ciostream\u003e void func() { std::cout \u003c\u003c \"call func()\" \u003c\u003c std::endl; } #endif main.cpp #include \u003cfunc.h\u003e int main() { func(); return 0; } ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:11:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"子模块 把第三方项目源码置于工程根目录下，通过add_subdirectory()和target_link_libraries() main.cpp #include \u003cfunc.h\u003e int main() { func(); return 0; } funclib/func.h #ifndef FUNC_H #define FUNC_H void func(); #endif funclib/func.cpp #include \u003cfunc.h\u003e #include \u003ciostream\u003e void func() { std::cout \u003c\u003c \"func()\" \u003c\u003c std::endl; } 对于最简单的子模块，同header_only相比，子模块不仅提供了.h头文件，还提供了.cpp的实现文件 因此需要在子模块的CMakeLists.txt中通过add_library()生成静态或动态库，然后在项目根目录中通过target_link_libraries()link项目中的多个子模块。并且，对于期望构建代码的子模块，需要在项目根路径下的CMakeLists.txt中使用add_subdirectory()指定该模块。 除此之外，同header_only相比，值得关注的一点是include子模块中的.h问题,通过target_include_directories()可以简写include语句,但CMakeLists.txt只能对相同路径下的.cpp文件起到作用,由于main.cpp和funclib/func.cpp中都需要引入func.h,因此一种简单的实现方式是,在项目根路径和子模块下的CMakeLists.txt中都需要添加target_include_directories()语句,如以下代码所示 CMakeLists.txt cmake_minimum_required(VERSION 3.12) project(mul_module_demo LANGUAGES CXX) add_subdirectory(funclib) add_executable(main main.cpp) target_include_directories(main PRIVATE ./funclib) target_link_libraries(main PUBLIC funclib) funclib/CMakeLists.txt add_library(funclib STATIC func.cpp) target_include_directories(funclib PRIVATE .) 这样虽然能够解决问题,但是当子模块数量过多时,项目根路径下的CMakeList.txt文件会和每个子模块的CMakeLists.txt中都存在重复代码, cmake通过设置target_include_directories()语句中的一个参数解决了上述问题 将项目根路径下的CMakeLists.txt中的target_include_directories()语句删除,在每个子模块中添加该语句,同时将以上示例代码该语句中的PRIVATE修改为PUBLIC, PUBLIC表示包含的头文件能够在子模块和link该子模块的父模块之间传播,从而只需要在子模块中添加该语句,父模块依然可以把自定义头文件作为系统头文件使用,实现代码如下所示 CMakeLists.txt cmake_minimum_required(VERSION 3.12) project(mul_module_demo LANGUAGES CXX) add_subdirectory(funclib) add_executable(main main.cpp) target_link_libraries(main PUBLIC funclib) funclib/CMakeLists.txt add_library(funclib STATIC func.cpp) target_include_directories(funclib PUBLIC .) ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:11:2","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"第三方库 通过 find_package() 和 target_link_libraries() 需要了解包(package)、库和组件的概念，包包含多个库/组件，库和组件的概念是相同的，例如TBB包提供了多个库(组件) 为了便于描述，通过OpenCV的实际例子来解释如何利用cmake来引入第三方库。 在使用OpenCV之前，需要首先进行安装。而OpenCV的安装同样需要使用cmake。参照OpenCV: Installation in Linux官方站点给出的安装流程进行安装。When we finish installing the opencv, we will get some files. 程序的编译链接过程，无非就是处理头文件和依赖库的问题。使用cmake也是完成程序的编译链接工作，它也需要调用gcc/g++。那么在理论上，通过cmake可以完成的工作，人工操作都能够完成，只不过在一些大型复杂项目中，需要做的工作太多，使用cmake可以简化这个过程。所以我们不妨首先考虑在一个小例子中，人工操作和cmake操作的对应关系，以便推导到大型项目下的cmake是如何处理的。 假设现在需要编译一个RGB图像转灰度图像的单程序。人工操作只需要在编译时候指明头文件的搜索路径，以及所需库的搜索路径及所需要链接的库。 g++ xxx.cpp -o yyy -I/usr/local/include/opencv4 \\ -L/usr/local/lib\\ -lopencv_calib3d \\ -lopencv_core \\ -lopencv_dnn \\ -lopencv_features2d \\ -lopencv_flann \\ -lopencv_gapi \\ -lopencv_highgui \\ -lopencv_imgcodecs \\ -lopencv_imgproc \\ -lopencv_ml \\ -lopencv_objdetect \\ -lopencv_photo \\ -lopencv_stitching \\ -lopencv_video \\ -lopencv_videoio 使用上述命令即可正常完成编译。但是产生的一个问题就是，指明的头文件的搜索路径还比较简单，但是下方的这些-l所要链接的库过多比较麻烦。 cmake就通过以下命令可以解决这个问题 find_package( OpenCV REQUIRED ) include_directories(${OpenCV_INCLUDE_DIRS}) target_link_libraries(\u003cproject name\u003e ${OpenCV_LIBS}) 其中target_include_directories负责指定头文件搜索路径，也就对应着-I/usr/local/include/opencv4；target_link_libraries负责指定所要链接的库，对应着上述g++选项中众多的-l选项。关于这一点，通过以下两条命令即可验证 MESSAGE( STATUS \"OpenCV_INCLUDE_DIRS = ${OpenCV_INCLUDE_DIRS}.\") MESSAGE( STATUS \"OpenCV_LIBS = ${OpenCV_LIBS}.\") -- OpenCV_INCLUDE_DIRS = /usr/local/include/opencv4. -- OpenCV_LIBS = opencv_calib3d;opencv_core;opencv_dnn;opencv_features2d;opencv_flann;opencv_gapi;opencv_highgui;opencv_imgcodecs;opencv_imgproc;opencv_ml;opencv_objdetect;opencv_photo;opencv_stitching;opencv_video;opencv_videoio. 我们虽然理解target_include_directories和target_link_libraries的作用，但是${OpenCV_INCLUDE_DIRS}和${OpenCV_LIBS}又是从何而来，find_package又起到了什么作用？ ${OpenCV_INCLUDE_DIRS}和${OpenCV_LIBS}显然是两个环境变量，但是在cmake之前找到环境变量，是没有这两个值的，那么可以猜想find_package所做的工作就是设置这两个环境变量，实际也正是如此。 也就是说find_package需要找到第三方库的头文件和库的路径。但是第三方库的数量众多，是如何能够做到这一点的？ 这就涉及到find_package搜索文件的两种模式和对应的两种文件：2 Module Mode Module mode: Find.cmake，(CMake官方预定义的一些依赖包所对应的查找文件，Linux下通过apt安装的CMake的路径为: /usr/share/cmake-\u003cversion\u003e/Modules，Mac下通过brew安装的CMake的路径为：/opt/homebrew/Cellar/cmake/\u003cversion\u003e/share/cmake/Modules，具体的路径取决于CMake的安装路径) Config Mode Config mode: Config.cmake，(通过CMake编译安装的第三方库，所处路径和构建 CMakeLists.txt 时的选项相关，如果给定了-DCMAKE_INSTALL_PREFIX选项，那么就会在该路径下的lib/cmake，如果没有给定该选项，那么就会在/usr/local/lib/cmake下)。 find_package根据这两种文件实现环境变量的设置。 关于两种模式下的cmake文件搜索路径问题 在Module mode 下，一般CMake会根据自身的安装路径自行查找，如果CMake和后续的库都是统一通过系统包管理器来安装的，那么Find.cmake文件的所处位置一般都是正确的。不过在官方文档中看到了CMAKE_MODULE_PATH这一变量，其可用于指定include()和find_package()对于CMake modules的搜索路径，若确实无法找到相关文件，也可尝试设置此变量。 Module mode 有默认的路径，但是 Config mode 下我们可能是通过 系统包管理器 或者 pip 安装的一些包，cmake 又该如何寻找这些包的 Config.cmake 文件呢? 根据Config Mode Search Procedure，可以发现一个cmake variable CMAKE_PREFIX_PATH。根据官方文档对于该变量的解释，其可用于帮助find_package()来查找一些包。 需要注意的是，这一变量不仅仅可以通过 set(CMAKE_PREFIX_PATH \"\u003cpath\u003e\")在项目中被设置，其同时是一个环境变量，我们也可以通过环境变量来设置 关于更多的cmake variables，可见cmake-variables 下面给出使用Config mode的一个示例: 假设当前使用conda创建了一个env，名称为test，其路径为$HOME/miniconda3/envs/test. 通过此环境下的pip安装了pybind11，其路径为$HOME/miniconda3/envs/test/lib/python\u003cedition\u003e/site-packages/pybind11 可以发现其路径下的share/cmake/pybind11中就存放着诸多*.cmake文件，根据Config Mode Search Procedure 官方文档给出的搜索路径，刚好对应到\u003cprefix\u003e/\u003cname\u003e*/(lib/\u003carch\u003e|lib*|share)/cmake/\u003cname\u003e*/这一条匹配规则，所以我们只需设置CMAKE_PREFIX_PATH和\u003cprefix\u003e匹配即可，即$HOME/miniconda3/envs/test/lib/python\u003cedition\u003e/site-packages 当我们完成此环境变量的设置后，CMakeLists.txt 中出现find_package(pybind11 \u003cedition\u003e CONFIG REQUIRED)就不会再报错了 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:11:3","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"示例 ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:12:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"构建流程 A simple but typical use of cmake with a fresh copy of software source code is to create a build directory and invoke cmake there:3 cd some_software-1.4.2 mkdir build cd build cmake .. -DCMAKE_INSTALL_PREFIX=/opt/the/prefix cmake --build . # It is equivalent to make cmake --install . # It is equivalent to make install The role of cmake is just generate Makefile for make, it doesn’t compile the project truely. e.g. cmake .. -DCMAKE_INSTALL_PREFIX=/opt/the/prefix. cmake --build or make compile the project. This step will invoke some compiler and linker. cmake --build . --target install or make install. A popular understanding of installing is that move the executable file, header files and libraries to the path which is specified by -DCMAKE_INSTALL_PREFIX option, if we don’t use this option, in general, the default intall prefix is /usr/local/. In general, it will generate some directories: bin, include, lib and share. A more common command flow: cmake -B build . / cmake -B build -S . cmake --build \u003cbuild directory path\u003e 等价于 make cmake --install \u003cbuild directory path\u003e 等价于 make install 关于安装路径的问题： 在使用 cmake 创建构建系统时指定 install 路径：4 cmake -DCMAKE_INSTALL_PREFIX set the environment variable CMAKE_INSTALL_PREFIX 安装前临时指定 install 路径： 若使用 cmake 5: cmake --install \u003cbuild directory path\u003e --prefix \u003cinstall path\u003e 若直接指定使用 make 构建工具 6make DESTDIR=\u003cinstall path\u003e install // cmake最低版本 cmake_minimum_required(VERSION 3.0.0) // 工程文件名 project(experiment2 VERSION 0.1.0) // 寻找第三方库 // c++包管理工具vcpkg(类似pip，使用时再查找) find_package(库名称 REQUIRED(库是必须的，未安装则报错)) // 匹配所有源文件添加到变量SRC_FILES中 file(GLOB SRC_FILES \"${PROJECT_SOURCE_DIR}/src/*.h\" \"${PROJECT_SOURCE_DIR}/src/*.cpp\" \"${PROJECT_SOURCE_DIR}/src/*.cc\" \"${PROJECT_SOURCE_DIR}/src/*.c\" ) # 这里只是设置两个变量，并没有指定这个路径 set(INC_DIR include目录路径) # 设置include路径变量 set(LINK_DIR 库目录路径) # 设置library路径变量 # 指定include和lib路径 include_directories(${INC_DIR}) link_directories(${LINK_DIR}) # 链接静态库，在下一步构建可执行文件之前 # 需要理解的是上一步只是指示了头文件和库的路径，程序还需要显示包含 # 头文件往往都是在程序中再include，lib可以在程序中指明，但一般是直接在这里写上，程序中就不再添加代码了 link_libraries(库名称) # 构建可执行文件 # ${CMAKE_PROJECT_NAME}：被替换为project指定的名称 # ${SRC_FILES}：file命令找到的所有源文件 add_executable(${CMAKE_PROJECT_NAME} ${SRC_FILES}) # 链接动态库(Link)，需要在上一步构建可执行文件之后 target_link_libraries(${CMAKE_PROJECT_NAME} PRIVATE 库名称) // 支持c++17 target_compile_features(${CMAKE_PROJECT_NAME} PRIVATE cxx_std_17) // 自动化工作 // 需要使用再详细查找 add_custom_command( TARGET ${CMAKE_PROJECT_NAME} POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_directory \"\") ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:12:1","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"CMakeLists示例 此示例用于winPcap开发 cmake_minimum_required(VERSION 3.0.0) project(experiment2 VERSION 0.1.0) file(GLOB SRC_FILES \"${PROJECT_SOURCE_DIR}/*.cpp\" ) set(INC_DIR E:/useful/cmake_project/WpdPack/Include) set(LINK_DIR E:/useful/cmake_project/WpdPack/Lib/x64) include_directories(${INC_DIR}) link_directories(${LINK_DIR}) link_libraries(Packet wpcap) add_executable(${CMAKE_PROJECT_NAME} ${SRC_FILES}) ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:12:2","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"Reference [1] CMake Reference Documentation [2] CMake FAQ [3] 理解find_package() [4] Cmake中文实战教程 Heuristic search for system headers ↩︎ find_package官方文档 ↩︎ Command Line cmake tool ↩︎ CMAKE_INSTALL_PREFIX ↩︎ cmake –prefix document ↩︎ make DESTDIR document ↩︎ ","date":"2023-06-16","objectID":"/blog/posts/compile-link/cmake-make/:13:0","tags":null,"title":"CMake Make","uri":"/blog/posts/compile-link/cmake-make/"},{"categories":["Compile-Link"],"content":"Compilation process analysis 涉及到两部分内容，一部分是cuda面对编译问题时的设计架构，另一方面是cuda实际的编译流程 首先对CUDA程序的编译流程进行简要介绍，下图是NVIDIA CUDA Compiler Driver NVCC - The CUDA Compilation Trajectory中给出的cuda编译流程。 上图可以结合实际流程和用到的指令来理解，这些可以通过nvcc -dryrun \u003ccuda program name\u003e来获取到 -dryrun: List the compilation sub-commands without executing them. 生成的中间文件，可以通过nvcc -keep来获取到 -keep: Keep all intermediate files that are generated during internal compilation steps. Now, we will analyse the detail progress of nvcc compilation: 删除生成的注册链接文件（如果存在）： rm main_dlink.reg.c 这一步确保之前生成的文件不会干扰当前的编译过程 预处理CUDA文件生成中间文件 生成 main.cpp4.ii gcc -D__CUDA_ARCH_LIST__=520 -E -x c++ -D__CUDACC__ -D__NVCC__ \"-I/home/jiaheng/dev/cuda-12.1/bin/../targets/x86_64-linux/include\" -D__CUDACC_VER_MAJOR__=12 -D__CUDACC_VER_MINOR__=1 -D__CUDACC_VER_BUILD__=105 -D__CUDA_API_VER_MAJOR__=12 -D__CUDA_API_VER_MINOR__=1 -D__NVCC_DIAG_PRAGMA_SUPPORT__=1 -include \"cuda_runtime.h\" -m64 \"main.cu\" -o \"main.cpp4.ii\" CUDA前端编译器处理预处理文件 cudafe++ --c++14 --gnu_version=90400 --display_error_number --orig_src_file_name \"main.cu\" --orig_src_path_name \"/home/jiaheng/gaohy/nvcc-simulate/main.cu\" --allow_managed --m64 --parse_templates --gen_c_file_name \"main.cudafe1.cpp\" --stub_file_name \"main.cudafe1.stub.c\" --gen_module_id_file --module_id_file_name \"main.module_id\" \"main.cpp4.ii\" 预处理生成CUDA代码中间文件 生成 main.cpp1.ii gcc -D__CUDA_ARCH__=520 -D__CUDA_ARCH_LIST__=520 -E -x c++ -DCUDA_DOUBLE_MATH_FUNCTIONS -D__CUDACC__ -D__NVCC__ \"-I/home/jiaheng/dev/cuda-12.1/bin/../targets/x86_64-linux/include\" -D__CUDACC_VER_MAJOR__=12 -D__CUDACC_VER_MINOR__=1 -D__CUDACC_VER_BUILD__=105 -D__CUDA_API_VER_MAJOR__=12 -D__CUDA_API_VER_MINOR__=1 -D__NVCC_DIAG_PRAGMA_SUPPORT__=1 -include \"cuda_runtime.h\" -m64 \"main.cu\" -o \"main.cpp1.ii\" CUDA编译器生成PTX代码 生成 main.ptx cicc --c++14 --gnu_version=90400 --display_error_number --orig_src_file_name \"main.cu\" --orig_src_path_name \"/home/jiaheng/gaohy/nvcc-simulate/main.cu\" --allow_managed -arch compute_52 -m64 --no-version-ident -ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 --include_file_name \"main.fatbin.c\" -tused --module_id_file_name \"main.module_id\" --gen_c_file_name \"main.cudafe1.c\" --stub_file_name \"main.cudafe1.stub.c\" --gen_device_file_name \"main.cudafe1.gpu\" \"main.cpp1.ii\" -o \"main.ptx\" PTX汇编成CUBIN ptxas -arch=sm_52 -m64 \"main.ptx\" -o \"main.sm_52.cubin\" 生成Fatbin文件 fatbinary --create=\"main.fatbin\" -64 --cicc-cmdline=\"-ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 \" \"--image3=kind=elf,sm=52,file=main.sm_52.cubin\" \"--image3=kind=ptx,sm=52,file=main.ptx\" --embedded-fatbin=\"main.fatbin.c\" 生成 fatbinary 之后，如何把这个二进制数据和 host cpp 代码进行关联是个关键问题，CUDA 采用的方案是，把 fatbinary 二进制文件以十六进制字符串形式，通过内联汇编写入 fatbin.c 这一 c 文件中，并且在其上又建立了一个 stub.c 抽象层次，stub.c 加入到了 host code 的编译流程中。 编译CUDA代码生成对象文件 生成 main.o gcc -D__CUDA_ARCH__=520 -D__CUDA_ARCH_LIST__=520 -c -x c++ -DCUDA_DOUBLE_MATH_FUNCTIONS \"-I/home/jiaheng/dev/cuda-12.1/bin/../targets/x86_64-linux/include\" -m64 \"main.cudafe1.cpp\" -o \"main.o\" 上面这条命令的核心内容就是 gcc -c main.cudafe1.cpp -o main.o。 从本质上来说，main.cudafe1.cpp 中是 include 了 fatbin.c 的内容，即通过它是可以看到 fatbinary 那些数据的。 其余内容就是 define 一些量 -D__CUDA_ARCH__=520 -D__CUDA_ARCH_LIST__=520 -DCUDA_DOUBLE_MATH_FUNCTIONS 这一步生成的 main.o 中是包含 nv_fatbin 这个 secton 的，因为 cudafe1.cpp 所 include 的 stub.c，或者说是最根源的fatbin.c 中，在内联汇编中是制定了 section 的， asm( \".section .nv_fatbin, \\\"a\\\"\\n\" \".align 8\\n\" \"fatbinData:\\n\" ); 9. 链接生成中间文件 `nvlink -m64 --arch=sm_52 --register-link-binaries=\"main_dlink.reg.c\" \"-L/home/jiaheng/dev/cuda-12.1/bin/../targets/x86_64-linux/lib/stubs\" \"-L/home/jiaheng/dev/cuda-12.1/bin/../targets/x86_64-linux/lib\" -cpu-arch=X86_64 \"main.o\" -lcudadevrt -o \"main_dlink.sm_52.cubin\" --host-ccbin \"gcc\"` 链接器会将 fatbinary 以特殊的方式嵌入到主机端的 ELF 文件中。通常，这些嵌入的数据会放在 .nv_fatbin 或 .nvFatBinSegment section 中，但是不确定嵌入过程是否是在此步中进行的。 其中 `-lcudadevrt` 对应到的是 CUDA 中的 libcudadevrt.a， 解包后的内容为 cuda_device_runtime.o，也就是说在这个步骤中是链接了 CUDA runtime library 的。 10. 生成Fatbin文件 `fatbinary --create=\"main_dlink.fatbin\" -64 --cicc-cmdline=\"-ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 \" -link \"--image3=kind=el","date":"2023-05-31","objectID":"/blog/posts/compile-link/cuda-compilation/:1:0","tags":null,"title":"CUDA Compilation","uri":"/blog/posts/compile-link/cuda-compilation/"},{"categories":["Compile-Link"],"content":"GPU Architecture and Compute Capability 关于 GPU Architecture 的发展，截止到 2022 年的情况可见下图，最新的架构可见官方文档 关于不同GPU的计算能力，可见官方文档(中文) ","date":"2023-05-31","objectID":"/blog/posts/compile-link/cuda-compilation/:2:0","tags":null,"title":"CUDA Compilation","uri":"/blog/posts/compile-link/cuda-compilation/"},{"categories":["Compile-Link"],"content":"Reference [1] NVCC与PTX ","date":"2023-05-31","objectID":"/blog/posts/compile-link/cuda-compilation/:3:0","tags":null,"title":"CUDA Compilation","uri":"/blog/posts/compile-link/cuda-compilation/"},{"categories":["HPC"],"content":"Todo L2 cache gpgpu-sim 源码分析 Bank conflict 的题目分析 warp occupancy 概念和计算 由broadcast式访问global memory引申的对于constant memory的理解和使用 并行化+访存优化，并行化中有一个branch divergence的问题 查找 DRAM burst突发传送官方文档说明 发现矩阵乘法是一个结合各种并行算法以及CUDA硬件架构知识的好的入手点，create一门课程 “从矩阵乘法入门并行计算-CUDA版” 需要验证如果shared memory中的元素大小和bank大小不一致时，访问其中更小的数据是否会造成bank conflict。需要借助nvprof，但是nvprof在选择检测bank事件时无法正常工作 CUDA C只是对标准C进行了语言级的扩展，通过增加一些修饰符使编译器可以确定哪些代码在主机上运行，哪些代码在设备上运行 GPU计算的应用前景很大程度上取决于能否从问题中发掘出大规模并行性 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:1:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"宏观视角 高性能计算的第一性原理：访存优化。所有的努力（优化硬件设计，优化算法）都是在试图解决内存墙。 访存优化3大关键： 一是减少数据搬运 二是减少数据访存延时 三是保证负载均衡 GPU中的并行算法设计：设计block和thread的workload，搞清楚一个block负责哪部分的计算，一个thread要负责哪部分的计算。而设计的原则就是尽可能地减少访存，提高数据的复用概率，然后让所有的处理器都满负荷地进行工作，不能浪费。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:2:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"SIMD \u0026 SIMT 涉及到AVX指令，正在尝试 说明两种方式的区别 The two most important things about SIMD and SIMT are: How is the SIMT to implement ? How is the SIMD to calculate ? GPU从整体上来说是SIMT，但是到Warp层次后实际就是SIMD了 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:3:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Kernel hardware mapping kernel function -\u003e GPU block -\u003e SM（one block can only be executed by one SM, but one SM can execute multiple blocks) 这里有一个疑问，一个SM可以执行多个block，多个block的执行是并发的还是可以并行的，换个角度来说就是正在执行的warp是同属于一个block的，还是可以隶属于多个block 关于此问题，还尚未找到官方资料中给出的证据，暂且认为SM上执行的warp可能属于不同block，也就是可以理解为开始执行kernel函数后，grid中的多个block被分配到某一个SM上，然后在SM的视角下就不再有block的概念，它所能看到的就是一些warp，通过warp scheduler来对warp进行调度，并且认为block一开始被分配到某个SM后不会在执行过程中去更换SM，直到执行完毕。 这种理解方式有一定的合理性，原因在于grid，block，warp本身就是为programmer所提供的逻辑概念，对于硬件来说，它能看到的不过是一些thread，它调度的也是thread。但是对于人来说，thread这一调度单位太细，很难实现对具体问题的抽象，所以才提供了更高一级的概念，即grid，block和warp。从这一角度来看，一个SM在同一时间能调度多个block就是合理的。 thread -\u003e SP main time consuming: kernel function startup thread block switch ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:4:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Hardware structure Grid、Block are login concepts, they are created by CUDA for programmers. According to the real physical level, every SM in GPU will excute multiple blocks, and it will divides block into multiple warps. The basic execution unit of SM is warp. In fact, the amazing computing capility of GPU comes from multiple thread. But we couldn’t just use thread this only one concept to program since that it is difficult to describe the job or we can say organize them. So, CUDA introduce the concept of Grid and Block which are logic concepts, they are created by CUDA for programmers. In fact, we we can see them as a organization structure. 首先给出一个gpu的简易逻辑图，理解gpu，sm，sp，warp scheduler的关系 一个kernel 函数是一个grid，对应整个gpu 然后grid中包含很多block，这个和gpu中的sm对应 block包含很多thread，这个和sm中的sp对应 sm的组成： register shared memory the cache of constant memory the cache of texture and surface memory L1 cache warp scheduler SP（截止到2023/12/09，对sp的理解是它只是一个泛称，不是特指某种具体的运算单元，SP可能对应于不同的硬件组件，包括浮点运算单元（FP）、整数运算单元（INT）、特殊功能单元（SFU）） 所以调度问题分为两个层面： 对于block的调度: 这个和sm有关系，多个block和多个sm，sm可以任意选择block执行，而且这种选择并不是一选定终生，中间过程还可以调整，但是block并不能拆分，只能整个放到sm上 对于thread的调度: 把一个block放到一个sm上，这时候我们的视角就要缩小到这个sm中了，这时候我们不需要考虑block层面了，只是要考虑block中这一大堆thread如何调度。这时候warp的概念就出现了，把一大堆thread范围为一些warp。然后由warp scheduler调度这一个warp，更准确的说法是由warp scheduler调度warp中的thread，所以warp只是一个中间概念，最终调度的仍然是thread(明确这一点对于理解后文的bank conflict至关重要) According to the real physical level, a SM(Streaming Multiprocessor) has many SP(Streaming Processor). Considure how can a every SM in GPU will excute multiple blocks, and it will divides block into multiple warps. The basic execution unit of SM is warp. Some official concepts about warp: A block assigned to an SM is further divided into 32 thread units called warps. The warp is the unit of thread scheduling in SMs. Each warp consists of 32 threads of consecutive threadIdx values: thread 0 through 31 form the first warp, 32 through 63 the second warp, and so on. An SM is designed to execute all threads in a warp following the Single Instruction, Multiple Data (SIMD) model ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:5:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"SIMT Architecture There is a question involved here that branch divergence between difference threads in the same warp.(Branch divergence occurs only within a warp, different warps execute independently regardless of whether they are executing common or disjoint code paths.1) It is worth noting that not all branch divergence elimination will generate performance benefits. Because if there is only a single if sentence such as the following code if (condition) { // code block A } // rest of the code Although maybe there are some threads which satisfies the condition, they will enter to the if sturct and execute the code block A and other threads will not. 但这些不进入的线程只需等待进入 code block A 的线程执行完即可。 If we have an integral if-else sturct such as the following code if (condition) { // code block A } else { // code block B } // rest of the code 在这种情况下，Warp中的线程会分别执行 code block A 和 code block B。如果条件不同，线程会分别进入 code block A 或 code block B，这就意味着Warp中的一部分线程需要先执行一个分支，然后再执行另一个分支。这样每个分支都要被串行执行一次，导致性能降低，因为每个分支的执行时间都被加起来了。 So, it does not mean that performance will decrease if branch divergence arises. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:5:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Memory structure How to detect the using situation of the different types of memory? Use nvcc compilation option --ptxas-option=-v --ptxas-option is used to specify options directly to ptxas(the PTX optimizing assembler, its location in the whole compilation process can be seen at CUDA Compilation) Use nvcc compilation option -keep Use nvprof command nvprof --print-gpu-trace \u003cprogram path\u003e ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Cache There are 5 types of cache in cuda: shared memory(equivalent to a user-managed chache) L1 cache L3 cache constant cache texture cache We will talk more details about shared memory later, so we only focus on the remaining four types of real cache. L2 cache Just like L1 cache and shared memory, the L2 cache and global memory is related. L2 cache is used to provide higher bandwidth and lower latency accesses to global memory. We can refer to Query L2 cache Properties to get the properties of L2 cache. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Register \u0026 Local Memory ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Global Memory The path of accessing global memory: L1 cache -\u003e L2 cache -\u003e global memory coalesced \u0026 uncoalesced coalesced memory access \u003c=\u003e a global memory access request from a warp will cause to 100% degree of coalescing. The above conclusion has two important things we need to pay attention to: The object we talk about is a warp The definition of degree of coalescing is described as the following formula $Degree \\ of \\ coalescing \\ (合并度) = \\frac{ request \\ bytes \\ number \\ (warp实际请求数据量) }{ bytes \\ number \\ that \\ participate \\ in \\ the \\ data \\ transforming \\ (实际输出的数据量)}$ 看到一句话，提到了DRAM burst，暂时还没有找到官方的解释 CUDA Coalesced access uses the DRAM’s burst mode 因为coalesced access是基于DRAM的burst mode来实现的，所以本质上会涉及到DRAM burst发生的性质和要求： 对齐 访存大小 疑惑点其实是在于发生coalesced是否和warp相关，是不是必须是同一个warp内的线程的访问才肯跟造成coalesced access，还是说同一个block不同warp，还是说不同block都可以？如果仅从DRAM burst发生的角度考虑，burst发生的条件应该是和CUDA的一些概念无关的，所以视角似乎可以直接放到不同线程上，并不需要考虑是否是同一warp或者是否是同一block 想要理解memory coalesced和uncoalesced，思维必须从串行思维转换到并行思维， Coalesce happens amongst threads, not amongst different iterations of the loop within each thread’s execution. 关注的重点不应放在一个单独的thread上，我觉得一个比较合适的视角是放在一个warp上（关于这一点，有一个很明显的错误示范，就是矩阵乘法P=MxN，如果从单一thread的角度来看，对M的访问应当是满足coalesced地，但是如果考虑属于一个warp的不同thread，就会发现实际上对N的访问才是coalesced。考虑某一时刻属于同一个warp的thread的访存方式。关于这一示例的详细分析，可见The CUDA Parallel Programming Model - 5. Memory Coalescing Common memory access types Please note that the third and the last code can’t get the right answer. The following code is just to used to describe types of memory access type. Sequential coalesced access(顺序的合并访问) __global__ void add_sequential_coalesced(float *x, float *y, float *z) { int threadId = threadIdx.x + blockDim.x * blockIdx.x; z[threadId] = x[threadId] + y[threadId]; } Out-of-order coalesced access(乱序的合并访问) __global__ void add_out_of_order_coalesced(float *x, float *y, float *z) { int threadId = threadIdx.x ^ 0x1; threadId = threadIdx.x + blockDim.x * blockIdx.x; z[threadId] = x[threadId] + y[threadId]; } Misaligned uncoalesced access(不对齐的非合并访问) __global__ void add_misaligned_uncoalesced(float *x, float *y, float *z) { int threadId = threadIdx.x + blockDim.x * blockIdx.x + 1; z[threadId] = x[threadId] + y[threadId]; } Strided uncoalesced access(跨越式的非合并访问) __global__ void add_stripped_uncoalesced(float *x, float *y, float *z) { int threadId = blockIdx.x + threadIdx.x * blockDim.x; z[threadId] = x[threadId] + y[threadId]; } Please Note that this is different from grid stride loop, which emphasizes that how to solve the big problem which the scale is bigger than the amount of threads. But there we want to emphasize a type of memory access. Broadcast uncoalesced access(广播式的非合并访问) __global__ void add_broadcast_uncoalesced(float *x, float *y, float *z) { int threadId = threadIdx.x + blockDim.x * blockIdx.x; z[threadId] = x[0] + y[threadId]; } broatcast这种方式还涉及到constant memory的使用 其实global memory就类似dram，l2 cache也就是个cache，所以thread访问global memory的过程和体系结构里面对于cache的分析过程是完全一样的，thread请求一个字节的数据，发现cache中不存在，即发生cache miss，然后就去访存，并且把数据缓存到cache line中，访问同一cache line对应数据的thread的再访存就是cache hit了，所说的这个合并访问似乎不过是访问这个cache line的过程，只要是一次访存对应几次都是cache hit就算是合并访存了，似乎完全可以这样理解. 其实这块判断是否会发生合并的一个前提就是确定从global memory一次到底取多少数据，现有认知是按照字节编制，但是按照字进行读取，但是书上却说一次读取32Bytes，一个字总不能有32Bytes吧。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Shared Memory 共享内存中的内存块通常被直接称为 memory tile 或简称为 tile。（可能这就是Tiled Matrix Multiplication的由来） Create Shared Memory 静态shared memory，使用__shared__限定符创建时就指定存储空间的大小 __shared__ float array[1024]; 动态shared memory，不确定空间大小，需要动态申请时 extern __shared__ float array[1024]; 需要在kernel函数调用时，指定申请的shared memory的大小 kernel\u003c\u003c\u003cgridSize, blockSize, sizeof(float) * 1024\u003e\u003e\u003e( … ); 在C/C++中，存在一个变长数组（Variable Length Arrays，VLA）的概念，允许使用变量来指定数组的大小。 但是实际测试，变量指定数组大小应用于kernel函数时，会报错\"error: expression must have a constant value\" Bank Conflict To understand this problem well, we should revisiv the hardware structure of gpu. 在此基础上，我们将gpu的建议结构图进行扩充，装入shared memory和bank的结构 还需要一张shared memory中是如何划分的bank bank的划分单位和最大bandwith都是32bits=4bytes=1word 但是寻址单位还是1byte 哪些情况下会产生bank conflict, 首先看一下都有哪些可能的bank访问情况 同一warp： 1.1 两个thread访问同一个bank中相同的字中的地址 (broadcast, conflict-free) 1.2 两个thread访问同一个bank中不同的字中的地址 (conflict) 1.3 两个thread访问不同bank (conflict-free) 不同warp： 2.1 两个thread访问同一个bank相同的字中的地址 (conflict) 2.2 两个thread访问同一个bank不同的字中的地址 (conflict) 2.3 两个thread访问不同bank (conflict-free) 要理解bank conflict，需要首先了解bank是怎么回事， To achieve high bandwidth, shared memory is divided into equally-sized memory modules, called banks, which can be accessed simultaneously. 尤其是后面这句话比较重要，不同bank可以同时响应数据请求（实现这一点应该是需要硬件支持的，每一个bank是一个独立的存储单元） 所以就可以理解为什么不同thread访问同一个bank的时会降低效率，因为本来可以同时读，现在只能串行读(关于这一点还有以下疑点：bank coflict 只发生在不同warp中的thread在访问同一个bank的不同byte时，同一个warp内的thread无论如何访问都不会产生bank conflict) 这样来看，bank本身和ram的性质类似，但是整个shared_memory可以看为是多个ram拼接而成 According to the real hardware architecture of SM, SM has multiple warp schedulers. A block will be distributed to a SM, but the unit of execution of SM is warp which has 32 threads. It is easy to understand the principle of this setting, as we all know a block has many threads, if SM dispatch all of them at the same time, it will casuce difficulties. So the designer divide the block into warp. All warps in the same block will share the same shared memory. Shared memory is also divided into many subdivisions. The number of subdivisions equals to the number of warp. Warp access shared memory use the bank as the unit. The most optimal situation is every warp correspondens to a bank. At this situation, the time of accessing whole 32 banks is just 1 memory cycle. To be precise, it should contains 32 threads and banks in figure. It is just a schematic drawing. But if many bank access the same bank, it will cause the following situation. At this situation, the time of accessing whole 32 banks is 32 memory cycles. To be precise, it should contains 32 threads and banks in figure. It is just a schematic drawing. An correlative calculation of this problem The hardware splits a memory request with bank conflicts into as many separate conflict-free requests as necessary, decreasing throughput by a factor equal to the number of separate memory requests. If the number of separate memory requests is n, the initial memory request is said to cause n-way bank conflicts. To get maximum performance, it is therefore important to understand how memory addresses map to memory banks in order to schedule the memory requests so as to minimize bank conflicts. How can we solve this problem ? We can pad and adjust the memory structure as the following picture shows. Reference [1] hardware-effects-gpu-Bank conflicts [2] Nsight Compute CLI - Metric Comparison ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:4","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Constant Memory A simple use of constant memory comes from convolution. In convolution, because there are four aspects which leads to that we can use constant memory. The ratio of floating-point arithmetic calculation to global memory accesses is so low.(计算访存比较低，简单理解就是读了很多数据但是计算的比较少，事倍功半) The size of mask is small. (The constant memory size is small) The constants of mask are not changed throughout the execution of the kernel. (The constant memory is prohibited modification) All threads need to access the mask elements. (store memory into cache is effective) According to the picture at the beginning of the Memory structure. We can learn about the constant memory is in DRAM. But because the variable or space in constant is prohibited modification, so cuda runtime can put its content to cache trustfully, at the same time, no modification means that there is no cache coherence issue. There are three important aspects of using constant memory: __constant__ float M[];, use the __constant__ specifier and M should be a global variable cudaMemcpyToSymbol(M, M_h, Mask_Width*sizeof(float)); ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:5","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Host Side Memory pageable memory 可分页内存 使用malloc()/new()和free()/delete()函数分配和释放 此类型内存是可以从内存被换出到磁盘的 pinned memory pinned memory, aka non-pageable memory(不可分页内存) / page-locked(页锁定内存) 使用cudaHostAlloc() / cudaMallocHost()和cudaFreeHost()函数分配和释放 cudaHostAlloc()和cudaMallocHost()的关系是 cudaHostAlloc(xxx, yyy, cudaHostAllocDefault) 等价于 cudaMallocHost(xxx, yyy) 此类型内存一直停留在内存，不会被换出到磁盘 此类型内存支持DMA访问，支持与GPU之间进行异步通信（asynchronous data transfer） Some background on the memory management in operating systems cudaMemcpy() uses the hardware direct memoryory access (DMA) device. The operating system give a translated physical address to DMA, i.e. the DMA hardware operates on physical addresses. Uses the DMA to implement the cudaMemcpy() faces a chance that the data in the pageable memroy can be overwritten by the paging activity before the DMA transmission. The solution is to perform the copy operation in two steps: For a host-to-device copy, the CUDA runtime first copies the source host memory data into a pinned memory buffer, sometimes also referred to as page locked memory buffer. It then uses the DMA device to copy the data from the pinned memory buffer to the device memory. The problems of this solution: Extra copy adds delay to the cudaMemcpy() operation. Extra complexity involved leads to a synchronous implementation of the cudaMemcpy() function. About the synchronous and asynchronous, please see the API synchronization behavior To solve this problem, we can use the cudaHostAlloc() to open up pinned memory buffer, and use the cudaMemcpyAsync() to copy a data asynchronously. Zero-Copy Memory 首先，零拷贝内存并不是像unified memory这样的逻辑存在，其是一种物理存在。其特别之处在于实际的物理存储空间实际是 Host Memory，但是 device 却可以通过某种方式直接访问，无需人工进行拷贝操作。 The way of opening up zero-copy memory The zero-copy memory is a special host memory, it is a pinned memory. When we use cudaHostAlloc() to open up a pinned memory, we need to transmit the third parameter flag. We need to transmit cudaHostAllocMapped as a flag to cudaHostAlloc(). Host code use cudaHostGetDevicePointer() to get a pointer which points to the pinned memroy. Please note that we should get the zero-copy memory pointer in host code rather than device cost, although it is more reasonable to get this pointer in device code. At this time, the pinned memory is called zero-copy memory. #include \u003ciostream\u003e #include \u003ccuda_runtime.h\u003e __host__ __device__ void output(int *a) { for (int i = 0; i \u003c 10; i++) printf(\"%d\", a[i]); printf(\"\\n\"); } __global__ void kernel(int *d_a) { output(d_a); d_a[2] = 5; } int main() { int *h_a, *d_a; cudaHostAlloc((void **)\u0026h_a, 10 * sizeof(int), cudaHostAllocMapped); cudaHostGetDevicePointer((void **)\u0026d_a, h_a, 0); for (int i = 0; i \u003c 10; i++) h_a[i] = 1; kernel\u003c\u003c\u003c1, 1\u003e\u003e\u003e(d_a); cudaDeviceSynchronize(); output(h_a); return 0; } // output: // 1111111111 // 1151111111 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:6","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Unified Memory Unified Memory是一种逻辑上的存在，它提供了一种抽象层，让程序员可以将主机（CPU）和设备（GPU）上的内存视为一个统一的内存空间。 使用Unified Memory的情况下，程序员无需显式地管理数据的迁移，系统会根据需要自动处理。 Unified Memory通过使用页表和硬件支持，实现了逻辑上的一致性。 Unified Memory并不是物理上的一块内存，而是一个逻辑概念，通过系统的管理和硬件支持，实现了对主机和设备上内存的透明管理。这有助于简化GPU编程中的内存管理任务。 Optimization Techniques Unified Memory for CUDA Beginners ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:6:7","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Memory API CUDA C提供了与C语言在语言级别上的集成，主机代码和设备代码由不同的编译器负责编译，设备函数调用样式上接近主机函数调用 cudaMemcpy() will synchronize automatically, so if the last line code is cudaMemcpy(), we needn’t to use the cudaDeviceSynchronize() Different devices corresponding to different memory functions Location memory allocate memory release Host malloc/new free/delete Device cudaMalloc cudaFree Unified Memory cudaMallocManaged cudaFree Which memory types do we have ? Host and device has different authorities to use the memory. The following table describes their authorities. Memory type Host Device Global memory W/R W/R Constant memory W/R R Why we need unified memory ? Additional transfers between host and device memory increase the latency and reduce the throughput. Device memory is small compared with the host memory. Allocating the large data from host memory to device memory is difficult. Annotate: W means Write and R means Read ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:7:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"2D Array Refering to the methos of opening up a 2D space in host code which see the first dimension of array is some pointers and the second dimension of array is a 1D array. When we want to allocate a 2D array in device memory, the above method is difficult, because we need to access a space of device memory in host code. So, CUDA provide pitched memory to implement it. We can use cudaMallocPitch() to create a 2D space in device memory, cudaMemset2D() to copy data between host and device and cudaFree() to release space. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:7:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Software structure All CUDA threads in a grid execute the same kernel function; It is easy to explain it. When we want to call a kernel function, we will specify the grid and block structure using the dim3 data type. It means that we want to use all these threads where locate in the grid to execute this kernel function. In general, a grid is a three-dimensional array of blocks1, and each block is a three dimensional array of threads. From a code implementation perspective, these two three-dimensional arrays are both a dim3 type parameter, which is a C struct with three unsigned integer fields: x, y, and z. The first execution configuration parameter specifies the dimensions of the grid in the number of blocks. And the second specifies the dimensions of each block in the number of threads. For example, as the following code shows, there is a grid and a block. The grid consists of 32 blocks, and it is a linear structure. The block consists of 128 threads, and it is also a linear structure. dim3 dimGrid(32, 1, 1); dim3 dimBlock(128, 1, 1); vecAddKernel\u003c\u003c\u003cdimGrid, dimBlock\u003e\u003e\u003e(...); About the more detail specifications please see official technical specifications ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:8:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Software stack ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:9:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Kernel Function Because the execution of the kernel function is asynchronous, that means the subsequent codes don’t know when the result will be returned by kernel funcion, so the type of returen value of kernel funciont must be void. CPU以及系统内存成为主机，GPU及其内存成为设备 GPU设备上执行的函数称为核函数（Kernel） 核函数调用时«\u003cpara1，para2»\u003e中的para1表示设备在执行核函数时使用的并行线程块的数量，通俗来说总共将创建para1个核函数来运行代码，共para1个并行执行环境，para1个线程块。这para1个线程块称为一个线程格（Grid） 核函数中存在一个CUDA运行时已经预先定义的内置变量blockIdx，表示当前执行设备代码的线程块索引 The difficulty of writing parallel programs comes from arranging the structure of grid、block and thread so that they can adapt the programs. What we ought to know is that the kernel funtion is just like a big loop in logic, it will enumerate the whole grid in threads. Note: This perspective is just from code, it is not the true execution logic. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:10:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"指针 主机指针只能访问主机代码中的内存，设备指针只能访问设备代码中的内存 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:11:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"设备指针 虽然cudaMalloc()同malloc()，cudaFree()同free()非常相似，但是设备指针同主机指针之间并不完全相同，设备指针的使用规则如下 cudaMalloc()分配的指针可以传递给设备函数，设备代码可以使用该指针进行内存读/写操作（解引用） cudaMalloc()分配的指针可以传递给主机函数，主机代码不可以使用该指针进行内存读/写操作（解引用） ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:11:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"主机指针与设备指针数据拷贝 主机-\u003e主机：memcpy() 主机-\u003e设备：cudaMemcpy()指定参数cudaMemcpyHostToDevice 设备-\u003e主机：cudaMemcpy()指定参数cudaMemcpyDeviceToHost 设备-\u003e设备：cudaMemcpy()指定参数cudaMemcpyDeviceToDevice The communication between CPU and GPU is asynchronous for high performance. So need to use the synchronous mechnisms for them. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:11:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Function type __host__ __global__ __device__ function type \\ action Callable from Executed on __global__ host / divice(compute capability 5.0 or higher) device __device__ device device __host__ host host Without any of the __host__, __device__, or __global__ specifier is equivalent only the __host__ specifier. Some special usage: The __global__ and __device__ execution space specifiers cannot be used together. The __global__ and __host__ execution space specifiers cannot be used together. The __device__ and __host__ execution space specifiers can be used together.(This usage is used to decrease the verbose codes, the compiler will compile the function for host and device seperately) More informations please see the official station. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:12:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Common Parallelization methods ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:13:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Grid-stride loop This method is used to solve the problem, the parallelism(并行度) is more than the quantity of threads. In some situations, we can create many threads so that satisfied the parallelism, that we can allocate a separate thread for every threads. But if the parallelism is more than the quantity of threads and we still use the above strategy, we will get the following result. The parallelism is 32, but we just have 8 threads, we can’t allocate a separate thread for every threads. Grid-stride loop provide a new approach to solve this problem. At first, we studt the content of this method and we will think the core principle of this method. The process of grid-stride loop looks like the following figure. In short, the core approach to implement it is for (size_t i = threadIdx.x; i \u003c n; i += \u003ctotal number of threads\u003e. When the number of threads is smaller than parallelism, we can’t use the traditional method to implement the parallel, simply speaking, the distribution of thread can’t satisfied the parallelism. Grid-stride loop uses to map the threads to tasks reasonably, the is a magic number, it can ensure different thread will not intersect with each other and finish all tasks. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:13:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Fixed location solve the data conflict The most obvious answer is using mutex or atomic operation. But as we all know, whether it’s mutex or atomic, they both have some consuming. We know that the data conflict comes from shared data, different thread maybe use the same data at the same time. So an approach to avoid happening this problem is that control different threads use different data. According to the process of Grid-stride loop, we notice that different threads use the different datas which have different locations. We can specify a fixed location to store a thread’s data to avoid using the mutex or atomic. A good example is array summation. As the following code shows. #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003ccuda_runtime.h\u003e #include \"CudaAllocator.h\" #include \"ticktock.h\" #include \u003cstdio.h\u003e __global__ void parallel_sum(int *arr, int *sum, int n) { for (int i = blockDim.x * blockIdx.x + threadIdx.x; i \u003c n / 4; i += gridDim.x * blockDim.x) { for (int j = 0; i + j \u003c n; j += gridDim.x * blockDim.x) { sum[i] += arr[i + j]; } } } int main() { int n = 1 \u003c\u003c 4; // unified memory std::vector\u003cint, CudaAllocator\u003cint\u003e\u003e arr(n); std::vector\u003cint, CudaAllocator\u003cint\u003e\u003e sum(n / 4); for (size_t i = 0; i \u003c n; i++) { arr[i] = i; } // 设置共n/4个thread，每个block为4个thread，因此block数量为n / 4 / 4 dim3 blockSize(4); dim3 gridSize(n / 4 / 4); parallel_sum\u003c\u003c\u003cgridSize, blockSize\u003e\u003e\u003e (arr.data(), sum.data(), n); cudaDeviceSynchronize(); int final_sum{0}; for (int i = 0; i \u003c n / 4; i++) final_sum += sum[i]; std::cout \u003c\u003c \"sum = \" \u003c\u003c final_sum \u003c\u003c std::endl; return 0; } ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:13:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Synchronization CPU programing needs synchronous mechanism, GPU programing also needs it. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:14:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Atomic We can learn about the execution logic by refering to C++ atomic and details of function by refering to CUDA C++ Programming Guide. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:14:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Asynchronization (CUDA stream) Serialize data transfer and GPU computation causes that PCIe idle and GPU idel appear interleavly. Most CUDA devices support device overlap. Because data transmission is more timeless than computation, so simultaneously execute a kernel while performing a copy between device and host memory can cover up the time consumation of data transmission. CUDA supports parallel execution of kernels and cudaMemcpy with streams. A stream is a sequence of commands that execute in order. The commands issued on a stream may execute when all the dependencies of the command are met. The dependencies could be previously launched commands on same stream or dependencies from other streams. About the PCIe transmission rate is shown as the following picture: 流的分类： 根据发出方分类： Host端发出的流(主要讨论的是这种) Device端发出的流 根据有无内容分类： 默认流(default stream) / 空流(null stream) 明确指定的非空流 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:15:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Execution order 同一个CUDA流中的操作是串行顺次执行的，不同stream中的operation随机执行，可能是并发交错执行的 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:15:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Related API __host__ ​cudaError_t cudaStreamCreate ( cudaStream_t* pStream ) Create an asynchronous stream. __host__ ​__device__ ​cudaError_t cudaStreamDestroy ( cudaStream_t stream ) Destroys and cleans up an asynchronous stream. __host__ ​cudaError_t cudaStreamQuery ( cudaStream_t stream ) Queries an asynchronous stream for completion status. __host__​ cudaError_t cudaStreamSynchronize ( cudaStream_t stream ) Waits for stream tasks to complete. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:15:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"如何理解流 从主机和设备两个视角的动作来分析 使用cudaMemcpyAsync()时，Host memory必须是non-pageable memroy / pinned memory, 数据传输过程由GPU的DMA负责 如果是pageable memroy使用cudaMemcpyAsync(), 需要首先将pageable memory移动到pinned memory，这个过程中就会涉及到数据同步。 还有一个需要注意的事情就是PCIe，同一时刻H2D和D2H都只能进行1个操作。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:15:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"C++ Encapsulation As we all know, the style of many CUDA APIs is C-style, we need to learn about how to use it conjunction with C++. How does the std::vector standard template library use the Device(GPU) memory ? Many examples use the original pointer to point a Device memory. But if we want to use a std::vector or other standard template library that locates in Device memory, we can’t use the cudaMalloc() or cudaMallocManaged(). Taking the std::vector as an example, next, we will discuss the method of allocating Device memory for containers. Whether it’s principle or usage methods is too complex to understand in a short time. So pause it for a period of time. When we must need to learn its principle we study it again. We can learn about it from 一篇文章搞懂STL中的空间配置器allocator. In short, std::allocator integrates the memory management and object management by using four member function. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:16:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"GPU execution core 一个kernel函数在逻辑上以block为单位映射到SM中，物理上以warp为单位解析指令将指令分发到具体的运算单元(SP/core, SFU, DP)或访存单元(LD/ST)。 SM中活动的warp数量占物理warp数量的比率为occupancy(占用率)。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:17:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Device API __host__ ​__device__ ​cudaError_t cudaGetDeviceCount ( int* count ) Returns the number of compute-capable devices. __host__ ​cudaError_t cudaGetDeviceProperties ( cudaDeviceProp* prop, int device ) Returns information about the compute-device. __host__​ cudaError_t cudaSetDevice ( int device ) Set device to be used for GPU executions. More information please see the official website. Three are three ways to transfer data from one device to another: cudaMemcpyPeerAsync() cudaMemcpy(): rely on the unified address system Implicit peer memory access performed by the driver ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:18:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"CUDA Libraries ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:19:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"cuBLAS ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:19:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"cuSOLVER ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:19:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"cuFFT ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:19:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Thrust Three main functionalities The host and device vector containers A collection of parallel primitives such as, sort, reduce and transformations Fancy iterators ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:19:4","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"CUDA Compilation For detailed information, please refer to this article. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:20:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"GPGPU-Sim Official site ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:21:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"How to run Use the command ldd to make sure the application’s executable file is dynamically linked to CUDA runtime library Copy the contents of configs/QuadroFX5800/ or configs/GTX480/ to your application’s working directory. These files configure the microarchitecture models to resemble the respective GPGPU architectures. Run a CUDA application on the simulator source setup_environment \u003cbuild_type\u003e ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:21:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Source code organization structure Gpgpu-sim的源码位于gpgpu-sim_distribution/src/gpgpu-sim。 目前，我们主要关注其中和配置相关的内容，我们通过修改gpgpu-simi的源码（增加一个配置项），重新编译并用其执行程序来简单理解gpgpu-sim对于配置项的设置方式。 修改gpu-sim.cc:gpgpu_sim_config::reg_options()，在其中添加一个配置项 option_parser_register(opp, \"-magic_number\", OPT_INT32, \u0026magic_number_opt, \"A dummy magic number\", \"0\"); 修改gpu-sim.h，在配置项对应结构体中添加对应字段 int magic_number_opt; 重新编译gpgpu-sim项目 将编译后生成的gpgpusim.config拷贝到待执行cuda程序路径下 修改待执行cuda程序路径下的gpgpusim.config配置文件，添加配置项 -magic_number 25 执行cuda程序，在输出信息中就可以看到新增的配置项 -magic_number 25 # A dummy magic number ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:21:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Reference [1] Working with GPGPU-Sim - Introduction [2] Working with GPGPU-Sim - Adding Configuration Options [3] Improving GPGPU-Sim Performance [4] ECE 695 GPGPU-Sim Tutorial 学习笔记 [5] GPGPU-SIM系列文章 | 科学网 附加内容： If want to use ptxplus (native ISA) change the following options in the configuration file -gpgpu_ptx_use_cuobjdump 1 -gpgpu_ptx_convert_to_ptxplus 1 If want to use GPUWatch change the following options in the configuration file -power_simulation_enabled 1 (1=Enabled, 0=Not enabled) -gpuwattch_xml_file .xml ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:21:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Related Programming Models 就目前了解到的 OpenACC 和 OpenMP 是由编译器提出的一种叫做Offloading的机制实现的 OpenCL Open Computing Language OpenACC Open Accelerators OpenACC is a feature of the compiler, so we don’t need to install it if we want use it. More details please see the gnu official website. OpenMP Open Multi-Processing Reference to the memroy modle of OpenMP, we can get the following information: “The OpenMP API provides a relaxed-consistency, shared-memory model.” threaded parallelism 虽然OpenMP只能用于单机，但是可以处理单机上的多卡 OpenMP is a feature of the compiler, so we don’t need to install it if we want use it. More details please see the gnu official website. MPI Message Passing Interface MPI可以理解为是一种独立于语言的信息传递标准, 本身和代码没有关系，可以看为是一种规定。 OpenMPI和MPICH等编程模型是对这种标准的具体实现。也就是说，OpenMPI和MPICH这类库是具体用代码实现了MPI标准。因此我们需要安装OpenMPI或者MPICH去实现我们所学的MPI的信息传递标准。 process parallelism ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:22:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"如何使用CUDA加速程序 目前理解到的CUDA加速程序的两个关键问题是： 任务并行化 寻找到任务中可以并行完成的部分，制定某种策略将任务合理分配到每个线程中。此过程期望解决的是计算瓶颈(cpu-bound)问题。 1.1 udacity的视频主要讲解的就是这部分 1.2 小彭课程第6讲也是这部分 主要就是讲解一些并行原语 访存优化 此过程期望解决的是内存瓶颈(memory-bound)问题。 2.1 gpu的存储模型（《大众高性能》） 2.2 小彭课程第7讲 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"公共概念 在使用 tile 的算法中，存在 ghost cell 和 halo cell / skirt cell，按照目前的理解，前者指的是实际不存在元素，后者指的是实际存在，但是不在当前 tile 范围内的元素。下面以 tiled 1D convolution 为例来说明它们的实际指向 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"对任务划分的理解 想要实现并行化，很重要的一点是考虑“如何合理地将任务划分到不同的thread上” 如何选择grid和block的规模，除了考虑以上合理的任务划分之外，还可以从性能的角度进行考量。 如果仅从下图内容来看，block规模的确定要更为重要，grid的规模只需要根据任务划分和block规模来确定即可 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"矩阵乘法 SGEMM Single-precision General Matrix Multiply 单精度通用矩阵乘法 DGEMM Double-precision General Matrix Multiply 双精度通用矩阵乘法 CGEMM Complex-single-precision General Matrix Multiply 复数单精度通用矩阵乘法 ZGEMM Complex-double-precision General Matrix Multiply 复数双精度矩阵乘法 目前感觉从具体的算子入门CUDA编程中的各种概念、并行算法、访存优化的手段是个非常好的方式，因为各种算法，访存优化一定都是基于实际的应用场景而出现的，都不是仅仅的概念本身 把thread都放置在同一个block中的缺点在于，SM无法对block进行调度，原本的两层调度：block调度和warp调度，现在就只剩下一个warp调度了 native implementation 的核心问题是：计算访存比过低，即使将global memory替换为shared memory，访存时间占比仍然远大于计算时间占比。所以才会考虑矩阵分块 Tiled Matrix Multiplication tiled matrix multiplication之所以减小了对内存带宽的要求，是因为一个thread读取的内容是可以被其他thread共享的。在分tile之前，一个thread从global memory读取的数据只会让它自己使用，但是分了tile之，一个thread从global memory加载的数据也可以被处于同一个tile中的其他thread所访问，增加了数据重用率。 More information please see the original passage Tiled Matrix Multiplication. Reference [1] Intel-maxas | SGEMM ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Reduction ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:4","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Convolution ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:5","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"understand of convolution 在 很详细的讲解什么以及为什么是卷积 一文中，作者从物理意义的角度解释了信号处理中的卷积操作 卷积操作的核心目的在于计算某一时刻下全局的信号强度值。具体的过程包括 “卷” 和 “积” 两个过程，系统响应函数 g 可以看为信号衰减的变化函数曲线，把 g 翻转过来并且平移的过程刚好遵循了信号衰减的变化情况。积的原因在于某一时刻下全局的信号强度值不仅和某一时刻的信号相关，还和此前的还未衰减完成的信号强度相关，所以实际需要进行累加操作。 卷积这块有一个神奇的题目和神奇的公式： 问: kD convolution 过程中（不考虑ghost elements的运算），每个元素的平均访问次数 答: 平均访问次数=$\\frac{output_{width}^k \\times mask_{width}^k}{input_{width}^k}$ 其中，在$stride=1$的情况下，满足$output_{width} = input_{width} - mask_{width} + 1$,即$input_{width} = output_{width} + mask_{width} - 1$ 2D convolution上述公式的验证代码如下： #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003calgorithm\u003e int main() { int m, n; std::cin \u003e\u003e m \u003e\u003e n; int width; std::cin \u003e\u003e width; auto count = std::vector\u003cstd::vector\u003cint\u003e\u003e(m + 10, std::vector\u003cint\u003e(n + 10, 0)); for (int begin_x = 1; begin_x + width - 1 \u003c= m; begin_x++) { for (int begin_y = 1; begin_y + width - 1 \u003c= n; begin_y++) { for (int i = 0; i \u003c width; i++) { for (int j = 0; j \u003c width; j++) { int x = begin_x + i, y = begin_y + j; count[x][y]++; } } } } float sum = 0.0f; std::cout \u003c\u003c std::endl; for (int i = 1; i \u003c= m; i++) { for (int j = 1; j \u003c= n; j++) { std::cout \u003c\u003c count[i][j] \u003c\u003c ' '; sum += count[i][j]; } std::cout \u003c\u003c std::endl; } std::cout \u003c\u003c \"\\n\" \u003c\u003c sum \u003c\u003c std::endl; std::cout \u003c\u003c \"\\n\" \u003c\u003c (sum / (m * n)) \u003c\u003c std::endl; return 0; } Tiled 1D Convolution 边界处理： 判断法 扩展法 背景介绍 假定每个thread处理一个output element 每一个block要处理的部分称为一个input tile, 生成的部分称为一个output tile Common calculation formula 下图包含了一些常见概念的对应关系。 $input \\ tile \\ width = output \\ tile \\ width + \\frac{mask \\ width - 1}{2} \\times 2 = output \\ tile \\ width + (mask \\ width - 1)$ 需要额外关注的一点是，有一些题目会给定 output tile width 和 mask width，要求计算input tile width，这类题目一般认为 input tile 是包含 helo cells 的，也就是下图中黄色部分标注的内容，其对应的output tile是下图中上方的黄色部分标注的内容。 Two tiled strategy Strategy-1 (most intuitive): loading all input data elements into the shared memory, which is needed for calculating all output elements of a thread block 这种方式存在的问题是，存在重复的 global memory 的访问。按照现在的划分方式，每一个 tile 都对应着一个 block, 而不同 block 对应的 shared memory 是不同的，因此 tile1 中的 2 和 3 号元素，虽然在 加载 tile0 时已经被加载到shared memory中了，但是存储 tile0 的 shared memory 和存储 tile1 的 shared memory 是不同的存储空间，因此 2 和 3 号元素需要从 global memory 中访问 2 次。 如果只使用一个 block 来计算确实可以解决重复访问的问题，但是仅使用一个 block，无法充分利用大量的 SM（CUDA 中采用的 2 种 scheduling：block scheduling 和 warp scheduling，只使用一个 block 就无法充分进行 block scheduling 了） Performance Evaluation 所谓的性能评估就是分别计算一下采用 tile 和不采用 tile 时 global memory 的访问次数。注意以下在分析时，均只分析一个 block 的访存情况 basic 1D convolution __global__ void convolution_1D_ba sic_kernel(float *N, float *P, int Mask_Width, int Width) { int i = blockIdx.x*blockDim.x + threadIdx.x; float Pvalue = 0; int N_start_point = i - (Mask_Width/2); for (int j = 0; j \u003c Mask_Width; j++) { if (N start_ point + j \u003e= 0 \u0026\u0026 N_ start_ point + j \u003c Width) { Pvalue += N[N_start_point + j]*M[j]; } } P[i] = Pvalue; } 为了绘图的方便，这里假设采用的 mask width 为 5，即左右两侧会各出现 2 个 ghost cell 假设 ghost cell 不需要读取 global memory。考虑一种计算方式：假设 ghost cell 需要读取 global memory，计算总的访存次数，然后减去 ghost cell 涉及到的访存次数。 总的访存次数 每一个 output element 对应的访存次数为 mask width 次。因此每一个 thread block 的访存次数为 $blockDim.x \\times mask \\ width$ ghost cell 涉及到的访存次数 首先只考虑最左侧的 ghost cell 的访存情况，最左侧的 cell 只有一个 output element 的计算才会涉及，每往右侧走一个涉及到的访问次数就会加 1，最左侧的 ghost cells 的最右侧一个，涉及的次数是$\\frac{mask \\ width - 1}{2}$ 因此再考虑上右侧，全部ghost cell 涉及的访存次数为 $(1 + 2 + \\dots + \\frac{mask \\ width - 1}{2}) \\times 2 = \\sum_{i=1}^{\\frac{mask \\ width - 1}{2}}(i) \\times 2$ tiled 1D convolution __global__ void convolution_1D_tiled_kernel(float *N, float *P, int Mask_Width, int Width) { int i = blockIdx.x*blockDim.x + threadIdx.x; __shared__ float N_ds[TILE_SIZE + MAX_MASK_WIDTH - 1]; int n = Mask_Width/2; int halo_index_left = (blockIdx.x - 1)*blockDim.x + threadIdx.x; if (threadIdx.x \u003e= blockDim.x - n) { N_ds[threadIdx.x - (blockDim.x - n)] = (halo_index_left \u003c 0) ? 0 : N[halo_index_left]; } N_ds[n + threadIdx.x] = N[blockIdx.x*blockDim.x + threadIdx.x]; int halo_index_right = (blockIdx.x + 1)*blockDim.x + threadIdx.x; if (threadIdx.x \u003c n) { N_ds[n + block","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:23:6","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"GPU Microarchitecture(SIMT Core) The microarchitecture of the GPU pipeline is divided into a SIMT front-end and a SIMD back-end. The GPU pipeline consists of three scheduling “loops”: instruction fetch loop: Fetch, I-Cache, Decode, and I-Buﬀer instruction issue loop: I-Buﬀer, Scoreboard, Issue, and SIMT Stack register access scheduling loop: Operand Collector, ALU, and Memory 注意蓝色和橙色部分存在I-Buffer的交叉 在讲述One/Two/Three-Loop Approximation之前，需要明确的是我们要分析的是SIMT Core的结构，要考虑的问题是如何统筹规划每一个warp所要执行的指令。这一点前提认知很重要，会直接影响到对后面一些结构的理解。 还有一个比较重要的事情，就是弄清楚这里说的one,two,three到底指的是什么，目前理解指的是3种scheduler,分别是SIMT stack, Scoreboard 和 Operand Collector. ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"One-Loop Approximation SIMT stack The SIMT stack is used to solve the thread divergence. It sends the target PC to the fetch unit and the active mask to the issue unit. The fetch unit is used to control which instruction is fetched next. The issue unit is used to control which lanes of the warp are active. The mask is a bit vector with 1 for every thread that is active for the corresponding control flow branch. When that control flow branch is being executed, only the threads with 1 in the corresponding branch bit execute those instructions. A simple method to address the control divergence is PDOM mechanism(post-dominator stack-based reconvergence mechanism). The post-dominator active mask has 1 for every thread that is active in each of the divergent paths that reconverge at that point. When we hit a divergent point, we push on the stack: (1) the current active mask and the next PC at the reconverge point; 虽然这里说的是current active mask，但是current active mask和 reconverge point 的active mask实际是一样的 (2) the active mask, PC, and reconverge PC for every branch. 如果有多个branch，入栈的先后顺序一般采取 the entry with the most active threads ﬁrst and then the entry with fewer active threads。我的理解是thread越多越有可能引入新的branch，所以优先让较少thread先执行，避免使局面变得更加混乱。由于栈是FILO，所以the entry with fewer active threads后入栈.不过这只是一般做法，并非强制要求。 For example, look at the following picture, we hit a divergent point A (1) the current active mask / reconverge point active mask is 1111, and the reconverge point is G (2) the branch of this divergent point A contains B and F 关于(2)中不同branch入栈的顺序，下图B分支点处采用的是一般的原则，A处则和一般原则相反 以上我们只讲述了SIMT stack是怎么使用的，现在思考一下它到底起到了什么作用，我们为何需要引入这样一种结构 观察上图中的(b)部分，不难发现程序的执行流从(a)那种复杂的形式，已经转变为了(b)中这种串行的方式。每个cycle执行一条指令即可，所以引入stack的目标就是 To achieve this serialization of divergent code paths one approach. The SIMT stack helps eﬃciently handle two key issues that occur when all threads can execute independently: nested control ﬂow skipping computation a warp is eligible to issue an instruction if it has a valid and ready (according to the scoreboard) in the I-Buffer. SIMT deadlock What is the SIMT deadlock problem? *mutex = 0; // A while (!atomicCAS(mutex, 0, 1)); // B atomicExch(mutex, 0); // C 上述代码中包含一个分支， 考虑在使用 SIMT-stack 时的场景 图中B表示条件命中，B’表示条件不命中 SIMT-stack内容如下 Ret/Reconv PC Next PC Active Mask - C mask-A / mask-C C B' mask-B' C B mask-B 最下方一行是TOS(top of stack) 根据SIMT stack的内容，首先弹栈会让第一个命中的thread退出循环，它通过atomicCAS()将mutex修改为了1。然后SIMT stack会继续弹栈，这时候其他thread开始执行。但是问题在于现在还没有把C弹栈，所以mutex还没有被改回0，而现在正在执行的指令必须等到mutex等于0后才可以正常执行从而推出循环，而它们不执行完，SIMT stack就不会继续弹栈。这就造成了死锁。 A mechanism for avoiding SIMT deadlock stackless branch reconvergence mechanism Assuming a warp contains 32 threads, the barrier participation mask is 32-bits wide. If a bit is set, that means the corresponding thread in the warp participates in this convergence barrier The barrier participation mask is used by the warp scheduler to stop threads at a specific convergence barrier ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:1","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Two-Loop Approximation The problem of One-Loop Approximation is that it assumes that the warp will not issue another instruction until the first instruction completes execution, so maybe it will cause a long execution latencies. A method to address this problem is that issue a subsequent instruction from a warp while earlier instructions have not yet completed, but it will face a new problem, we don’t know whether the next instruction to issue for the warp has a dependency upon an earlier instruction that has not yet completed execution. So a separate scheduler is introduced, it is used to decide which of several instructions in the instruction buﬀer should be issued next to the rest of the pipeline to avoid dependency problem. 总结一下，简单来说，所谓的two-loop approximation不过是面对one-loop approximation所遇到的问题，考虑额外添加一个调度器，在前一条指令还没有执行完毕时就能够发射其他指令以类似流水线的方式执行从而可以增加指令吞吐量，但是遇到一个依赖性的问题，可能还没有执行的指令和要发射的指令存在数据相关，所以就引入了计分板来尝试解决这个问题，然后又发现单纯使用计分板同样遇到了一些问题，然后就有一个大佬提出了一种解决方案。这整个过程就是一个发现问题，然后解决问题的循环。 Scoreboard Scoreboards can be designed to support either in-order execution or out-of-order execution. Scoreboarding keeps track of dependencies to make sure we do not allow an instruction to start executing if there is a dependency with a previous instruction that is still executing. As the following example shows: add r3, r2, r1 // r3 = r2+r1 sub r5, r3, r4 // RAW add r5, r2, r1 // WAW After the first instruction issues, we mark r3 as unavailable. When the sub instruction arrives, it cannot issue since r3 is not ready (RAW). After the first instruction completes, sub now can read the new value of r3 and issue, marking r5 which is the destination register as unavailable. The third instruction cannot issue since it writes to r5 (WAW). Please note that in the above example, we issue in order: the read has already read the register values when we issue the write after it. So there is no WAR. The two problem and solve method of the above implementation of scoreboard is used in in-order execution The simple in-order scoreboard design needs too many storage space Solution: change the implementation of scoreboard The original way is hold a single bit per register per warp(每个warp都有一个完整的下图的结构), it looks like the following picture Now, the design contains a small number of entries per warp(每个warp一个bit vector), where each entry is the identifier of a register. It looks like the following picture If an instruction that encounters a dependency must repeatedly lookup its operands in the scoreboard until the prior instruction it depends upon writes its results to the register file. It consumes too many computation resources 首先可以确定的一点在计分板结构改变后，维护计分板内容的方式也发生了改变。根据书上说的，改变了修改计分板的时机。我现在对于解决这个问题大致的一个理解是，计分板和指令buffer是两个分离的结构，当一条指令执行结束后会修改计分板的内容，然后顺便把指令buffer中对应存在依赖的寄存器标记清空，这样在从指令buffer中取指令的时候拿到的就是新的状态，如果从指令buffer中读取到的指令不存在对于某个寄存器的依赖时就去执行这一指令，如果存在就换别的执行，不过这块的逻辑还没有看的太明白。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:2","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Three-Loop Approximation Operand Collector 为了隐藏长时间的内存访问延迟，一种方法就是实现以周期为单位对warp进行切换，通过warp切换来掩盖延迟。 为了实现这一点，就需要使用较大的 registers file。而 registers file最朴素的实现方式就是 one port per operand per instruction issued per cycle， 但是这样我理解着是只能串行访问，吞吐量比较低。所以一种方式就是划分bank，不同bank可以做到并行访问，从而增大并行度。 引入了 bank，同时也就引入了bank conflict, 下图的naive microarchitecture就具有这种问题，设计operand collector也正是为了解决这种问题, operand collector就是引入的第3个scheduler，完成指令在并行访问寄存器堆时的调度工作。 naive microarchitecture for providing increased register file bandwidth(by single-ported logical banks of registers) operand collector microarchitecture(the staging registers have been replaced with collector units) operand collector究竟是怎么调度的似乎书上并没有详细描述，只是给了一种新的从 register 到 bank 的映射方式(如下图所示），确保不同 warp 原来会被分到同一个 bank 的register 现在会被分到不同bank，但是同一个 warp 内不同 thread 之间的 bank conflict 并没有解决, 也就是它只对减少不同 warp 间的 bank conflict 起到了作用。 具有 WAR hazard, 3种可能的解决方法： release-on-commit warpboard: at most one instruction per warp to be executing release-on-read warpboard: only one instruction at a time per warp to be collecting operands instruction level parallelism Instruction Replay 当一条指令在GPU流水线上发生结构冒险了怎么办？对于一般的CPU来说我们可以简单的暂停当前指令，直到结构冒险消除再继续执行。但是这种方法在高吞吐量的系统中并不适用，停滞的指令可能处于任务的关键路径上进而影响到任务的完成时间，并且大量的停滞需要额外的缓冲区来存储寄存器信息。同时停滞一个指令可能会停滞其他完全不必要停滞的指令，降低了系统的吞吐量。 在GPU中我们可以尝试使用instruction replay来解决这个问题。instruction replay最早是在CPU的推测执行中作为一种恢复机制出现的，当我们执行了错误的分支，正确的指令会被重新取回并执行，消除错误分支的影响。在GPU中我们一般会避免推测执行，因为这会浪费宝贵的能源以及吞吐量。GPU实现instruction replay是为了减少流水线阻塞以及芯片面积和对应的时间开销。 在GPU上实现instruction replay可以通过在instruction buffer中保存当前指令直到这条指令已经执行完成，然后再将其移出。 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:3","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Memory system First Level The shared memory is implemented as a static random access memory (SRAM). 每一个lane都有一个对应的bank，bank上各有一个读port和一个写port shared memory 和 global memory 的访问粒度似乎是不同的，shared memory可以以warp为单位进行访问，但是global memory每次就是访问一个cache block While the data array is highly banked to enable ﬂexible access to shared memory by individual warps, access to global memory is restricted to a single cache block per cycle. The L1 cache block size is 128 bytes in Fermi and Kepler and is further divided into four 32byte sectors in Maxwell and Pascal. 要是按照这个的说法，每次读取global memory最小单位就是32B The 32-byte sector size corresponds to the minimum size of data that can be read from a recent graphics DRAM chip in a single access. 一个128B的cache block，会分为32个bank，每个bank对应4B(32-bit entries) Each 128-byte cache block is composed of 32-bit entries at the same row in each of the 32 banks. The data to be written either to shared memory or global memory is ﬁrst placed write data buﬀer (WDB). Memory Partition Unit The memory access schedulers in memory partition unit contains frame buffer(FB) and raster operation(ROP) unit. L2 cache To match the DRAM atom size of 32 bytes in GDDR5, each cache line inside the slice has four 32-byte sectors. L2 cache line的长度是128B，由4个32B组成 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:4","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Warp The multiprocessor creates, manages, schedules, and executes threads in groups of 32 parallel threads called warps. 一个SM可能执行多个block。虽然说不同block之间可以并行执行（不过要求在不同SM上才可以并行），但是映射到同一个SM的block，它上面的warp是不能并行执行的，只能相互等待。 How block’s threads get mapped to warps? We can get answer from 4.1. SIMT Architecture. The way a block is partitioned into warps is always the same; each warp contains threads of consecutive, increasing thread IDs with the first warp containing thread 0. 从这个答案中，不难引发另一个疑问，即 How thread ID can be calculated? We can get answer from 2.2. Thread Hierarchy. The index of a thread and its thread ID relate to each other in a straightforward way: For a one-dimensional block, they are the same; for a two-dimensional block of size $(D_x, D_y)$, the thread ID of a thread of index $(x, y)$ is $(x + y \\times D_x)$; for a three-dimensional block of size $(D_x, D_y, D_z)$, the thread ID of a thread of index $(x, y, z)$ is $(x + y \\times D_x + z \\times D_x \\times D_y)$. (Editer replenishment): please note that the above comparison is between index of thread and thread ID, so dont’s be confused about the first situation. i.e. “for a one-dimensional block, they are the same”, it means for a one-dimensional block, the thread ID is equals to the index of this thread. According to the question of “Does CUDA think of multi-dimensional gridDim, blockDim and threadIdx just as a linear sequence?”, we can see the type of thread organization as the row major ordered multi-dimensional arrays. But please note the difference between the index in CUDA and the index of traditional array or matrix. For traditional array or matrix, we are used to use the (row_index, col_index) to indicate the position of an element in an array or a matrix. But in CUDA, the coordinates seem to become adverse, CUDA uses the (x = column_number, y = row_number) to express a grid or block. In fact, these two expressions don’t create conflicts. The (row_index, col_index) is a perspective of actual storage mode. Now, if we place the array or the matrix into a coordinate system, we can also use the (x, y) to indicate an element of the array or matrix. We can say that the (row_index, col_index) is a coordinate from storage structure perspective and the (x = column_number, y = row_number) is a coordinate from math coordinate system perspective. Because the concept grid and block are just for programmer convenience, so they don’t imply the actual storage structure, so the CUDA use the math coordinate to indicate the position of an element in an array or a matrix. For the thread index $(x, y)$, the x is the column number, y is the row number, it is like the following picture of block index. How to understand and calculate occupancy ? Warp Scheduling Strategy Loose Round Robin (LRR) 处于Ready状态了就开始执行，否则跳过先发射下一个warp Two-level (TL) 把warp分为两组，Pending warps 和 Active warps，warp在这两个组之间变换，当warp需要等待某些长延迟操作时，就切换到pending warp那一组，当条件就绪后，则转到active warp这一组，在active warp这一组采用LRR的调度策略 Greedy-then-oldest (GTO) 考虑到局部性，会贪婪地执行一个warp，直到它进入stall状态才会切换其他warp执行 ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:24:5","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"CUDA Related Documents NVIDIA CUDA Compiler Driver NVCC ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:25:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["HPC"],"content":"Reference [1] CUDA C++ Programming Guide [2] Does NVCC include header files automatically? [3] 网格跨步 [4] CUDA Runtime API Documentation (Please note the version of coda) [5] CUDA编程方法论-知乎专栏 [6] CUDA Crash Course - Youtube [7] GPGPU架构优秀PPT(Teaching部分) [8] Accelerated Computing - Programming GPUs [9] CUDA编程入门及优化 | 知乎 [10] Tensor Core技术解析（上） [11] Tensor Core技术解析（下） [12] NVIDIA Developer Tools 汇总 [13] 《General-Purpose Graphics Processor Architecture》中文翻译 GPU SIMT Architecture - branch divergence ↩︎ ","date":"2023-05-31","objectID":"/blog/posts/hpc/gpu-structure-and-programing/:26:0","tags":[],"title":"GPU Structure and Programing","uri":"/blog/posts/hpc/gpu-structure-and-programing/"},{"categories":["Linux"],"content":"Terminal 快捷键 历史命令： Ctrl P : 上一条命令，可以一直按表示一直往前翻 Ctrl N : 下一条命令 Ctrl R，再按历史命令中出现过的字符串：按字符串寻找历史命令 命令行编辑： Ctrl A ： 移动光标到命令行首 Ctrl E : 移动光标到命令行尾 Ctrl B : 光标后退 Ctrl F : 光标前进 Ctrl W : 删除光标前的单词 Ctrl K ：删除光标之后所有字符 Ctrl U : 清空当前键入的命令 用户相关命令 1. 创建用户：adduser username 2. 修改用户组: usermod -g groupname username 3. 删除组: groupdel groupname 4. 删除用户: deluser -r username(-r是为了顺带删除用户目录) 5. 强制结束进行: kill -9 processId 云服务器 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:0:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"本地免密登录 文件相关 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:1:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"ls命令各字段分布 在使用ls获取文件的各项信息时，常用的选项包括如下几种： -a：展示包括隐藏文件在內的所有文件 -l：打印文件的详细信息 -h：以人类可以理解的格式输出文件大小 -G：以彩色文本输出结果 关于时间信息 -U：展示文件的创建时间 -l：展示文件最后的修改时间 -c：展示文件状态最后改变时间 -u：用文件最后的访问时间代替原始-l展示的最后修改时间 关于排序 -t：首先根据时间戳降序排序，当时间戳相同时，按照文件名字典序生序排列 -S：字典序排序前按照文件大小降序佩列 $ ls -l -a # 也可以把选项合并成ls -la total 56K drwxr-xr-x 2 yzh yzh 4096 Sep 11 09:52 . --\u003e 当前目录 drwxr-xr-x 10 yzh yzh 4096 Sep 10 19:51 .. --\u003e 父目录 -rw-r--r-- 1 yzh yzh 34565 Sep 4 10:48 01.md -rw-r--r-- 1 yzh yzh 9314 Sep 11 09:36 02.md |\\./\\./\\./ | \\./ \\./ \\.../ \\........../ +--\u003e 文件名（the pathname） | | | | | | | | +------------\u003e 上次修改日期（last modified time） | | | | | | | +---------------------\u003e 文件大小(字节)（number of bytes in the file） | | | | | | +--------------------------\u003e 文件所属组（group name） | | | | | +------------------------------\u003e 文件所属用户（owner name） | | | | +---------------------------------\u003e 硬链接数量（number of links） | | | +-------------------------------------\u003e 其他用户权限 | | +----------------------------------------\u003e 组内用户权限 | +-------------------------------------------\u003e 所属用户权限 +---------------------------------------------\u003e 文件类型（file mode） ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:2:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"常见的文件类型 -（短划线）：普通文件 d：目录 l：符号链接（软链接） c：字符设备文件 b：块设备文件 s：套接字文件 p：命名管道（FIFO） ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:3:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"文件权限解释 文件分为普通文件和目录文件。 对于普通文件，读写执行权限是比较好理解的； 对于目录文件，具有读权限意味着可以读取当前目录下的文件，具有写权限意味着可以更改目录结构，更改目录结构和更改目录下文件的内容是不同的，修改目录下一个普通文件中的内容并不会改变目录结构，在目录下新增/删除文件/目录才会更改目录结构；具有可执行权限意味着可以进入当前目录 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:4:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"关于时间 时间有哪些分类？ 访问时间（access time）- atime inode 创建时间（inode creation time） 改变时间（change time）- ctime 修改时间（modification time）- mtime 通过ls命令的不同选项可以查询到不同的时间，查询创建时间采用ls -lU，查询访问时间采用ls -lu，查询改变时间采用ls -lc，查询修改时间采用ls -l1 在以上4种时间中，inode创建时间是很好理解的，问题在于如何区分其他三种时间类型， 向文件写入会修改atime，ctime和mtime 文件权限和属主的变更会修改atime和ctime 读文件会修改atime 从以上三种情形可以看出，改变是指文件状态的改变，修改是指文件内容的修改，访问操作涉及的范围则相对宽泛，无论读、写还是状态的改变都会涉及到文件的访问 shell 更多内容见shell 十四问 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:5:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"查看当前可用shell cat /etc/shells ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:6:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"修改默认shell 使用 chsh 工具 chsh --shell /bin/zsh username 修改/etc/passwd文件 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:7:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"特殊变量 $0 - 脚本名 \\$1 到 \\$9 - 脚本的参数。$1 是第一个参数，依此类推 $@ - 所有参数 $# - 参数个数 $? - 前一个命令的返回值（返回码）。返回值0表示正常执行，非0表示有错误发生 $$ - 当前脚本的进程识别码 !! - 完整的上一条命令，包括参数。常见应用：当你因为权限不足执行命令失败时，可以使用 sudo !!再尝试一次。 $_ - 上一条命令的最后一个参数。如果你正在使用的是交互式 shell，你可以通过按下 Esc 之后键入 . 来获取这个值。 返回码可以和逻辑运算符（|| 和 \u0026\u0026）在脚本中搭配使用 非常用变量 $* - 把所有命令行参数看为一个字符串 $@ - 把所有命令行参数看为一个个独立的字符串 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:8:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"替换技术 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"参数替换 ${} 在${}中，通过#、%和/符号能够实现字符串处理 % var=\"hello\" % echo ${var} hello # 单变量时花括号可省略 % echo $var hello 常见的字符串操作根据修改位置分为：左侧和右侧，根据动作类型分为：删除和替换，根据匹配长度分为：最短匹配和最长匹配 实际的可选操作是以上几种分类方法的组合，具体方式如下 注：以下示例使用的变量为var=\"/dir1/dir2/dir3/my.file.txt\" 左侧删除最短匹配 ${var#pattern}：#表示左侧、删除操作、进行最短匹配，即删除左侧和pattern匹配的最短部分 ${var#*/}：pattern为*/，结果为dir1/dir2/dir3/my.file.txt 左侧删除最长匹配 ${var##pattern}：##表示左侧、删除操作、进行最长匹配，即删除左侧和pattern匹配的最长部分 ${var##*/}：pattern为*/，结果为my.file.txt 右侧删除最短匹配 ${var%pattern}：%表示右侧、删除操作、进行最短匹配，即删除右侧和pattern匹配的最短部分 ${var%/*}：pattern为/*，结果为dir1/dir2/dir3 右侧删除最长匹配 ${var%%pattern}：%%表示右侧、删除操作、进行最长匹配，即删除右侧和pattern匹配的最长部分 ${var%%/*}：pattern为/*，结果为空值 替换 ${var/pattern/replace}：表示用replace替换字符串中的pattern，且只替换左侧第一个匹配项 ${var/dir/path}：把左侧第一个dir替换为path，结果为/path1/dir2/dir3/my.file.txt ${var//pattern/replace}：表示用replace替换字符串中的pattern，且替换全部匹配项 ${var//dir/path}：把全部的dir替换为path，结果为/path1/path2/path3/my.file.txt String slicing is used to extract substrings from a string. Its syntax shows below: ${string:start:length} start: Represents the starting position of the slice (inclusive). If not specified, it defaults to 0. length: Repersents the length of substring what you want to get. ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:1","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"算术替换 (()) 和 $(()) % res=$((3+5)) % echo res 8 % ((res = 3 * 5)) % echo $res 15 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:2","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"文件名替换 通过通配符匹配文件名 % ls a.c b.c c.c d.c mkdir_script.sh % echo *.c a.c b.c c.c d.c ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:3","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"命令替换 `` 或 $() shell会首先执行反引号或$()包裹的内容，将执行结果作为整个替换部分的值 % out=`ls` % echo $out a.c b.c c.c d.c mkdir_script.sh % out=$(pwd) %.echo $out /tmp/missing/lecture2 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:4","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"进程替换 \u003c() 和 \u003e() 进程替换在临时文件和管道操作符之外提供了一种新的方式，这种方式能够更加方便地处理命令之间的输入和输出关系 小括号内包含着命令，进程替换会将小括号内命令的执行结果存入一个临时文件中，同时返回该临时文件的路径 % mkdir dir1; touch dir1/{a,b}.c % mkdir dir2; touch dir2/{b,c}.c % diff \u003c(ls dir1) \u003c(ls dir2) 1d0 \u003c a.c 2a2 \u003e c.c diff需要两个文件作为输入，因此需要两个ls命令首先将执行结果放入一个文件中，再把文件路径作为输入值传递给diff命令，这一执行顺序刚好符合进程替换的执行顺序 如何确定临时文件的位置？ 由于进程替换的返回值就是临时文件的路径，因此只需要在小括号内输入任意命令，通过echo命令输出进程替换的返回值即可显示临时文件的路径 % echo \u003c(true) /dev/fd/11 % ls -l \u003c(true) prw-rw---- 0 root staff 0 7 30 22:50 /dev/fd/11 注： true也是一条命令，不进行操作只返回true值 /dev/fd 是一个特殊的目录，用于表示进程的文件描述符（File Descriptors），后面的11并不是固定值，只是在执行命令时获得的临时文件描述符为11 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:9:5","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"流及其重定向 在了解具体的流重定向方法之前，我们需要首先了解Linux下3种特殊的设备：stdin, stdout, stderr。它们都位于/dev/目录下，详细信息如下： lr-xr-xr-x 1 root wheel 0B Nov 26 08:20 stderr -\u003e fd/2 lr-xr-xr-x 1 root wheel 0B Nov 26 08:20 stdin -\u003e fd/0 lr-xr-xr-x 1 root wheel 0B Nov 26 08:20 stdout -\u003e fd/1 下面要使用的0，1，2实际指代的就是这3类设备 更详细的内容请见3.6 Redirections | Linux manual, 以下只是部分内容。 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:10:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"输入流重定向\u003c % cat \u003c hello.txt hello % cat 0\u003c hello.txt 0\u003c表示将cat命令的标准输入（stdin）从名为hello.txt的文件中读取数据，默认情况下，直接使用\u003c实现输入流重定向。之所以用0表示，是因为stdin实质上是一个链接文件/dev/stdin，其指向/dev/fd/0这个字符设备文件 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:10:1","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"输出流重定向\u003e 1\u003e表示将 标准输出(stdout) 从终端重定向至文件，由于被重定向因此终端不再显示结果。之所以用1表示是因为stdout-\u003e链接文件/dev/stdout-\u003e字符设备文件/dev/fd/1 2\u003e表示将 标准错误输出(stderr) 从终端重定向至文件。echo hello的stdout结果是hello，stderr结果是空。stdout未发生重定向，因此终端显示hello，stderr的空结果被重定向至hello.txt。在一般情况下，stdout和stderr都是定向到终端的，通过1\u003e和2\u003e可以区分二者。之所以用2表示是因为stderr-\u003e链接文件/dev/stderr-\u003e字符设备文件/dev/fd/2 \u0026\u003e 和 \u003e\u0026表示将 标准输出和标准错误输出 统一重定向至文件 在不加数字时，即\u003e则默认表示对 标准输出(stdout) 进行重定向 % echo hello \u003e hello.txt % cat hello.txt hello % echo hello 1\u003e hello.txt % cat hello.txt hello % echo hello 2\u003e hello.txt hello % cat hello.txt 以上描述的都是将内容重定向至文件，如果想要重定向到管道(stdout / stderr)需要添加\u0026符号，以便于区分普通文件名和管道名称 2\u003e\u00261表示将标准错误重定向至标准输出（stdout） 1\u003e\u00262表示将标准输出重定向至标准错误（stderr） 结合重定向至文件和重定向至管道，可以把所有输出内容全部重定向至文件，如以下代码所示 % xxx 1\u003eoutput.txt 2\u003e\u00261 需要注意的是，上述重定向的顺序不能更改。大致可以理解为shell在重定向时是顺序处理的，如果标准错误的重定向先于标准输出的重定向，那么结果将是标准错误仍然会到达标准输出原有的输出端，并不会到达文件 输入流和输出流合用 # cat \u003c hello.txt \u003e hello2.txt # cat hello2.txt hello ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:10:2","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"向文件追加内容\u003e\u003e 与输出流重定向类似，存在1\u003e\u003e和2\u003e\u003e，表示以追加的形式进行stdout和stderr的重定向 # echo hello1 \u003e hello.txt # echo hello2 \u003e\u003e hello.txt hello1 hello2 注：需要明确的是在shell中执行都都是一个个的程序，即使是sudo也只是一个特殊的程序而已。程序的调用执行是由shell负责的， 在使用重定向和管道时，前后要执行的程序是不知情的，重定向和管道是由shell负责的。 因此对于命令sudo echo x \u003e file.txt，假设当前用户并不具备file.txt的写权限，即使前面添加了sudo，执行结果依然是无权限，这是因为该命令的执行逻辑为，shell以echo x作为参数执行sudo程序，然后将结果输入到file.txt中，实际的输入过程shell仍然是以当前用户身份进行的，并不是以root身份进行的，因此操作仍然无权限。 在这种情况下，echo x | sudo tee file.txt就可以正常执行，这是因为实际是以root身份执行写入操作的 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:10:3","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"条件判断 test [ [[ 其中[和test是等效的命令，[也称为test的别名。三者具体的区别见如下站点 What is the difference between test, [ and [[ ? ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:11:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"通配符 *：匹配任意长度的字符，包括空字符 *.txt 可以匹配所有以.txt结尾的文件 ?：匹配单个字符 file?.txt 可以匹配file1.txt、file2.txt等 []：匹配方括号内的任意一个字符 [abc]file.txt 可以匹配afile.txt、bfile.txt、cfile.txt {}：用于生成多个相关字符串 file{1,2}.txt -\u003e file1.txt file2.txt file{a..d}.txt -\u003e filea.txt fileb.txt filec.txt filed.txt ..为范围操作符 ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:12:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"Emacs 和 vi 模式切换 如何在terminal下使用vi的操作方式？ 见Chapter 4: The Z-Shell Line Editor 4.1.1: The simple facts ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:13:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"job control 如何管理background job？ 使用jobs命令可以列出当前终端下的所有job 使用kill命令结合各种信号，以下是几种常用的信号及其解释 SIGSTOP 和 SIGCONT 用于暂停/恢复进程的执行，SIGSTOP特殊在于其无法被捕获、处理或忽略 恢复进行执行还可以使用 fg（foreground）和bg（background）命令，分别控制进程在前台和后台继续执行 SIGHUP 用于通知进程其终端连接已断开的一种信号，当一个终端连接被关闭时，该终端上运行的所有进程都会收到 SIGHUP 信号(和此信号相关的有一个nohup命令(Allows for a process to live when the terminal gets killed)，通过nohup和\u0026的结合使用可以实现后台运行进程且终端关闭后进程不被终止的效果) SIGINT 通常是由用户在终端上按下Ctrl+C发送给程序的。它用于请求中断程序的执行。默认情况下，大多数程序会响应SIGINT信号并进行清理工作后正常退出 SIGTERM 通常不是由用户手动触发，而是由系统或其他进程发送给程序，用于请求程序停止执行并正常退出 SIGKILL 用于强制终止进程的执行，当进程收到信号时，无论其当前状态如何，该进程都会立即被终止，并且没有机会进行任何清理或处理操作 对于以上内容，难点在于如何理解后4种信号，他们都会让进程终结，但是会应用于不同场景，更加常用的是SIGINT 和 SIGKILL ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:14:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"process control ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:15:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"SSH If you want a remote mechine excute a command or a script , you have two ways. One is that you get a connection to the remote mechine firstly, and then excute a command or a script. The other is that you can use a special format command. The command which you want to excute follows the ssh command. It looks like ssh user@hostnames \u003ccommand\u003e. More details can be found in ssh 教程 The configuration file of ssh is the ~/.ssh/config, in this file, you can use a hostname, which can simplies the connection sentence for every time. ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:16:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"Common scenarios move files in this directory to an another directory find . -type f -d 1 | xargs -I {} mv {} \u003ctarget directory\u003e ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:17:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Linux"],"content":"常见sheel脚本示例 统计当前目录下各文件行数以及总行数 #!/bin/bash total_lines=0 for file in *; do if [ -f \"$file\" ]; then lines=$(wc -l \u003c \"$file\") total_lines=$((total_lines + lines)) echo \"File: $file, Lines: $lines\" fi done echo \"Total Lines: $total_lines\" 注：该示例除了基本的变量替换以及条件判断，值得注意的一点就是wc在使用重定向符\u003c时，就无法再确定输入来自何文件，因此输出只会包含计算出的行数，不再包含文件名，刚好符合这里的用法 命令别名 直接alias [alias name]='[command]'，仅在当前会话中有效 修改/root/.bashrc，永久生效 注意：alias的=两侧不能包含空格 Symbolic link and Hard link Please note that when you create a symbolic link, you ought to use the absolute path. If you use the relative path, when you excute the command ls -l, you will find the target file of symbolic link is not the file what you want it to point to. But you can use either relative path or absolute path to create a hard link. Search command man apropos: Use keyword to search command tldr Reference [1] shell 十三问原帖 [2] shell 十三问markdown版 [3] A User’s Guide to the Z-Shell Difference between atime、ctime and mtime ↩︎ ","date":"2023-01-18","objectID":"/blog/posts/linux/linux-basic-knowledge/:18:0","tags":null,"title":"Linux Basic Knowledge","uri":"/blog/posts/linux/linux-basic-knowledge/"},{"categories":["Python"],"content":"python介绍 跨平台，面向对象，解释型语言 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:1:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"编译相关 pyc文件： .pyc 是一种二进制文件，是由 .py 文件经过编译后，生成一种byte code文件。 .py 文件变成 .pyc 文件后，加载的速度有所提高，而且 .pyc 是一种跨平台的字节码，是由python的虚拟机来执行的，这个类似于JAVA或者.NET的虚拟机的概念。 .pyc 的内容是跟python的版本相关的，不同版本编译后的 .pyc 文件是不同的，2.5编译的 .pyc 文件对于2.4版本的python是无法执行的。可用于隐藏Python源代码和提高运行速度 pyw文件: Python源文件，常用于图形界面程序文件 pyo文件： .pyo 是优化编译后的字节码文件 python -O 源文件 即可将源程序编译为 .pyo 文件。 pyd文件： 由其他语言编写并编译的二进制文件, 常用于实现接口插件或Python动态链接库 # 编译成pyc文件 # ------------------------------------------------------ python -m py_compile $filename # 其中，$filename是要编译的python源码文件名 2. 编译成pyo文件 # ------------------------------------------------------- python -O -m py_compile $filename # 或者 python -OO -m py_compile $filename # 其中， + -O选项表示优化产生的字节码，优化程度由PYTHONOPTIMIZE(environment)的值来决定。 + -OO选项表示在-O优化的基础上移除所有的doc-strings(文档文本)。 对于模块文件，第一次被导入时将被编译成字节码的形式，并在以后再次导入时优先使用“.pyc”文件，以提高模块的加载和运行速度 对于非模块文件，直接执行时并不生成“.pyc”文件，可以选择手动编译 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:2:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"pip命令 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:3:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"对象 python中一切都是对象 内置对象可直接使用，数字，字符串，列表 非内置对象需要导入模块 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:4:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"IDLE交互模式 在 IDLE 交互模式中浏览上一条语句的快捷键是 ALT + P IDLE下一条 Alt + n 在 IDLE 交互模式中，复合语句(例如for循环等需要按两次回车) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:5:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"强弱类型\u0026动态静态 强类型：某一个变量被定义类型，如果不经强制转换，那么它永远是该数据类型 弱类型：某一个变量被定义类型，该变量可以根据环境变化自动进行转换，不需要经过现行强制转换 动态类型：在运行期间才去做数据类型检查的语言，，即写程序时不需要指明变量类型，到程序运行为变量赋值时变量的类型才得以确认 静态类型：数据类型在编译期间检查，也就是说在写程序时要声明所有变量的数据类型 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:6:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"python运算符 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"算术运算符 算术运算符 功能 + 两个数相加，或是字符串连接 - 两个数相减 * 两个数相乘，或是返回一个重复若干次的字符串 / 两个数相除，结果为浮点数（小数） // 两个数相除，结果为向下取整的整数 % 取模，返回两个数相除的余数 ** 幂运算，返回乘方结果 $3\u003c5\u003e2 \\Leftrightarrow 3\u003c5 \\ and \\ 5\u003e2$ python不支持++和--自增自减运算符，起到的作用仅是改变正负 +-2 \u003e\u003e -2 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"逻辑运算符 逻辑运算符 功能 and 布尔“与”运算符，返回两个变量“与”运算的结果 or 布尔“或”运算符，返回两个变量“或”运算的结果 not 布尔“非”运算符，返回对变量“非”运算的结果 具有惰性求值特点，只计算必须计算的表达式 # 由于是 or 运算，只要有一者为真，那么结果为真，因此到3时就可以确定最终结果了(python认为非0值均为True) \u003e\u003e\u003e 3 or 5 3 ## 由于是and运算，只要一者为假，那么最终结果为假 \u003e\u003e\u003e 0 and 2 0 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"位运算符 位运算符 功能 \u0026 按位“与”运算符：参与运算的两个值，如果两个相应位都为 1，则结果为 1，否则为 0 ^ 按位“异或”运算符：当两对应的二进制位相异时，结果为 1 ~ 按位“取反”运算符：对数据的每个二进制位取反，即把 1 变为 0，把 0 变为 1 « “左移动”运算符：运算数的各二进制位全部左移若干位，由“«”右边的数指定移动的位数，高位丢弃， 低位补 0 » “右移动”运算符：运算数的各二进制位全部右移若干位，由“»”右边的数指定移动的位数 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"成员运算符 成员运算符 功能 in 当在指定的序列中找到值时返回 True,否则返回 False not in 当在指定的序列中没有找到值时返回 True,否则返回 False ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"身份成员运算符 身份成员运算符 功能 is 判断两个标识符是否引用自同一个对象，若引用的是同一个对象则返回 True，否则返回 False is not 判断两个标识符是不是引用自不同对象，若引用的不是同一个对象则返回 True，否则返回 False 同一个对象：具有相同的id ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"集合操作符 集合操作符 功能 S | T 返回一个新的集合，包括在集合S和T的所有元素 S - T 返回一个新集合，包括在集合S但不在T中的元素 S \u0026 T 返回一个新集合，包括同时在集合S和T中的元素 S ^ T 返回一个新集合， 包括集合S和T中不相同元素，等价于 (S | T) - (S \u0026 T)，和两个数异或的感觉差不多，相同数异或之后就没得了 S \u003c= T 或 S \u003c T 返回True/False， 判断S和T的子集关系 S \u003e= T 或 S \u003e T 返回True/False， 判断S和T的包含关系 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:7:6","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"python 6种数据类型 map、filter、enumerate、zip具有的特点：1. 惰性求值 2. 访问过的元素不可再次访问，简单理解就是迭代器已经到了end()的位置 x = [1, 2, 3] y = filter(lambda x : x + 1, x) print(list(y)) print(list(y)) 结果： [1, 2, 3] [] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Number（数字） 复数 \u003e\u003e\u003e c = 3 + 4j \u003e\u003e\u003e c.real # 实部 3.0 \u003e\u003e\u003e c.imag # 虚部 4.0 在数字中间位置使用单个下划线作为分隔来提高数字的可读性，不影响数字的值，仅是方便读 \u003e\u003e\u003e 1_2_3.4_5 123.45 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"String（字符串) 1、反斜杠可以用来转义，使用r意思是将那些特殊的转义字符看为普通字符，例如’\\n’代表换行，但是r’\\n’仅代表两个字符，一个’'，一个’n’，当我们希望字符串中的’'仅是一个’'字符而非转义符号时，一种方法是’\\’，另一种就是字符串前面加上’r' 2、字符串可以用+运算符连接在一起，用*运算符重复。 3、Python中的字符串有两种索引方式，从左往右以0开始，从右往左以-1开始。 4、Python中的字符串不能改变，因此切片不支持字符串修改 常用转义字符 转义字符 含义 转义字符 含义 \\b 退格，把光标移动到前一列位置 \\ 一个斜线\\ \\f 换页符 \\’ 单引号’ \\n 换行符 \\” 双引号” \\r 回车 \\ooo 3位八进制数对应的字符 \\t 水平制表符 \\xhh 2位十六进制数对应的字符 \\v 垂直制表符 \\uhhhh 4位十六进制数表示的Unicode字符 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"List（列表）[] 1、List写在方括号之间，元素用逗号隔开。 2、和字符串一样，list可以被索引和切片。 3、List可以使用+操作符进行拼接。 4、List中的元素是可以改变的。 5、列表支持双向索引(最后一个元素索引值为-1) 6、一个列表中的数据类型可以各不相同 remove(x)：If the element doesn’t exist, it throws ValueError: list.remove(x): x not in list exception. +在进行列表拼接时，并非把一个列表中的元素加入到另一个列表中，而是重新开辟一个列表，将两部分列表中的元素复制过去，较为耗时 append()和extend()都是原地操作，前者是增加一个元素，后者可以将可迭代对象逐个放入 +=类似extend()，是原地操作，但是+并不是原地操作 x = [1, 2, 3] print(x, id(x)) x += [4] print(x, id(x)) x = x + [5] print(x, id(x)) 结果： [1, 2, 3] 2918749822344 [1, 2, 3, 4] 2918749822344 [1, 2, 3, 4, 5] 2918749822216 insert()虽然会移动元素，但是仍是原地操作 x = [1, 2, 3] print(x, id(x)) x.insert(1, 2) print(x, id(x)) 结果： [1, 2, 3] 2785177427336 [1, 2, 2, 3] 2785177427336 乘法增加列表元素对象,对原列表内容的重复，且复制出来的不是值，而是引用，修改任何一个其它的也会改变 \u003e\u003e\u003e x = [[1]] \u003e\u003e\u003e x *= 3 \u003e\u003e\u003e x [[1], [1], [1]] \u003e\u003e\u003e x[0][0] = 2 \u003e\u003e\u003e x [[2], [2], [2]] 列表推导式得到的重复内容，仅是值，而非引用，改变其中一个，其它的并不会改变 \u003e\u003e\u003e x = [[] for i in range(3)] \u003e\u003e\u003e x[0].append(1) \u003e\u003e\u003e x [[1], [], []] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Tuple（元组）() 1、与字符串一样，元组的元素不能修改。 2、元组也可以被索引和切片，方法一样。 3、注意构造包含 0 或 1 个元素的元组的特殊语法规则。 tup1 = () # 空元组 tup2 = (20,) # 一个元素，需要在元素后添加逗号 4、元组也可以使用+操作符进行拼接。 5.元组支持双向索引(最后一个元素索引值为-1) 连续赋值可以得到一个元组 \u003e\u003e\u003e x = 3, 4 \u003e\u003e\u003e x (3, 4) del 不能删除元组中单个元素，但是可以直接删除整个元组 元组虽然为不可变序列，但是其中确可以放入可变序列。并且其中的可变序列还可以进行修改。但放入可变序列的元组就不能再放进set或者作为dist的键了 元组其实就是一种特殊的列表，什么都可以放，只是不能修改 \u003e\u003e\u003e a = [1, 2] \u003e\u003e\u003e b = (1, a) \u003e\u003e\u003e b (1, [1, 2]) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Set（集合）{} 可以使用大括号 { } 或者 set() 函数创建集合，注意：创建一个空集合必须用 set() 而不是 { } 集合中只能保存不可变序列，例如字符串，元组，原因与Why Lists Can’t Be Dictionary Keys类似 当两个集合中存储的数据相同时，两个集合相等 注： 是两个集合相等，不是两个对象相同，是两个对象，但是它们的内容相等 集合是无序容器，所以判断是否相等时不考虑数据顺序，仅考虑含有的数字是不是一样的 集合的大小关系 \u003c=\u003e 包含关系 x = {1, 2, 3} y = {1, 2, 5} z = {1, 2, 3, 4, 5} print(x \u003c y) # x不是y的真子集 print(y \u003c z) # y是z的真子集 print(x \u003c z) # x是z的真子集 结果： False True True 无法删除集合中指定位置的元素，只能删除特定值的元素 del不能删除集合中的元素，但是可以删除整个集合 函数 描述 remove 使用 remove 方法删除元素时，如果元素不存在集合中，那么程序会报错。 discard 使用 discard 方法删除元素时，如果元素不存在集合中，那么程序不会报错。 pop 使用 pop 方法删除集合中的元素时，会自动删除集合中的第一个元素，并返回被删除的元素，如果集合为空，程序报错。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Dictionary（字典）{} 1、字典是一种映射类型，它的元素是键值对。 2、字典的关键字必须为不可变类型，且不能重复，即数字，字符串，元组 3、创建空字典使用 { } sorted()直接对字典排序，实际是对字典的键进行排序，因为字典属于无序容器，顺序对它来说并没有意义 Why Lists Can’t Be Dictionary Keys 如果需要一个可以记住元素插入顺序的字典，可以使用 collections.OrderedDict 输出字典，默认输出键 x = { \"name\":\"ghy\", \"age\": 20, \"sex\":\"male\" } for i in x: print(i) 结果： name age sex 序号 函数 描述 1 radiansdict.clear() 删除字典内所有元素 2 radiansdict.copy() 返回一个字典的浅复制 3 radiansdict.fromkeys(seq) 创建一个新字典，以序列seq中元素做字典的键，None为所有键对应的初始值 4 radiansdict.get(key, default=None) 返回指定键的值，如果值不在字典中返回default值 5 key in dict 如果键在字典dict里返回true，否则返回false 6 radiansdict.items() 以列表返回可遍历的(键, 值) 元组数组 7 radiansdict.keys() 以列表返回一个字典所有的键 8 radiansdict.setdefault(key, default=None) 和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default 9 radiansdict.update(dict2) 把字典dict2的键/值对更新到dict里 10 radiansdict.values() 以列表返回字典中的所有值 不可变数据（3 个）：Number（数字）、String（字符串）、Tuple（元组）； 可变数据（3 个）：List（列表）、Dictionary（字典）、Set（集合） 有序序列：列表，字符串，元组 无序序列：字典，集合 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:8:6","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"python类型转换 函数 描述 int(x, base = 10) 将x转换为一个整数（1.若 x 为纯数字，则不能有 base 参数，否则报错；其作用为对入参 x 取整；2.若 x 为 str，则 base 可略可有，base 存在时，视 x 为 base 类型数字，并将其转换为 10 进制数字 float(x) 将x转换到一个浮点数 complex(real [,imag]) 创建一个$real + imag * j$复数，或者转化一个字符串或数为复数。如果第一个参数为字符串，则不需要指定第二个参数 str(x) 将对象 x 转换为字符串 repr(x) 将对象 x 转换为表达式字符串 eval(str) 用来计算在字符串中的有效Python表达式,并返回一个对象 tuple(s) 将序列 s 转换为一个元组 list(s) 将序列 s 转换为一个列表 set(s) 转换为可变集合 dict(d) 创建一个字典。d 必须是一个 (key, value)元组序列。 frozenset(s) 转换为不可变集合 chr(x) 将一个整数转换为一个字符 ord(x) 将一个字符转换为它的整数值(ASCII码) hex(x) 将一个整数转换为一个十六进制字符串 oct(x) 将一个整数转换为一个八进制字符串 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:9:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"print语句 print(*objects, sep=' ', end='\\n', file=sys.stdout) objects –表示输出的对象。输出多个对象时，需要用 , （逗号）分隔 sep – 指定输出对象之间的间隔符 end – 用来设定以什么结尾。默认值是换行符 \\n，我们可以换成其他字符 file – 要写入的文件对象 格式化输出： \u003e\u003e\u003e print(\"the length of (%s) is %d\" %('runoob',len('runoob'))) the length of (runoob) is 6 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:10:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"$abs(a + bj) = \\sqrt{a^2 + b^2}$ ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:11:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"内存管理机制 Python 采用的是基于值的自动内存管理方式，相同的值在内存中只有一份 这个问题比较复杂，因为运行结果要分为在交互模式下和在程序中两种情况，上面的说法也没错，但是说的非常笼统 首先，Python启动时，会对[-5, 256]区间的整数进行缓存 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:12:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"交互模式下 浮点数的id不同，不过连续赋值有点奇怪 \u003e\u003e\u003e x = 3.4 \u003e\u003e\u003e y = 3.4 \u003e\u003e\u003e id(x) == id(y) False \u003e\u003e\u003e x, y = 3.4, 3.4 \u003e\u003e\u003e id(x) == id(y) True 列表内部，缓存区以内相同数的id相等，在缓存区间以外，相同大整数的id相等，小数(例如负数)的id不等 \u003e\u003e\u003e x = [30000, 30000] \u003e\u003e\u003e id(x[0]) == id(x[1]) True \u003e\u003e\u003e x = [-111, -11] \u003e\u003e\u003e x = [-111, -111] \u003e\u003e\u003e id(x[0]) == id(x[1]) False 不同列表之间，缓存区以内相同数值id相等， 在缓存区间以外相同数值的id不等 \u003e\u003e\u003e x = [300, 300] \u003e\u003e\u003e y = [300, 300] \u003e\u003e\u003e id(x[0]) == id(y[0]) False 相同列表，相同短字符串的id相等，相同长字符串的id不等 \u003e\u003e\u003e x = ['abc', 'abc'] \u003e\u003e\u003e id(x[0]) == id(x[1]) True \u003e\u003e\u003e x = ['abc' * 50, 'abc' * 50] \u003e\u003e\u003e id(x[0]) == id(x[1]) False ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:12:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"程序中 浮点数的id相等 x = 3.4 y = 3.4 print(id(x) == id(y)) True x, y = 3.4, 3.4 print(id(x) == id(y)) True 列表内部执行结果与交互模式相同 不同列表之间，缓存区以外相同大整数id相等，小数(例如负数)id不等 x = [300, 300] y = [300, 300] print(id(x[0]) == id(y[0])) True x = [-111, -111] y = [-111, -111] print(id(x[0]) == id(y[0])) False 字符串同交互模式 这句话并不严密 对象存储的是值的内存地址或者引用，为对象修改值时，并不是真的直接修改变量的值，而是使变量指向新的值 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:12:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"库 python标准库 名称 作用 datetime 为日期和时间处理同时提供了简单和复杂的方法 zlib 直接支持通用的数据打包和压缩格式：zlib，gzip，bz2，zipfile，以及 tarfile random 提供了生成随机数的工具 math 为浮点运算提供了对底层C函数库的访问 sys 工具脚本经常调用命令行参数。这些命令行参数以链表形式存储于 sys 模块的 argv 变量 glob 提供了一个函数用于从目录通配符搜索中生成文件列表 os 提供了不少与操作系统相关联的函数 无论时标准库还是第三方库使用时都需要import 但是在使用标准库中那68个内置函数时是不需要导入库的 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:13:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"注释 单行注释 ：# 多行注释：三个单引号 ''' 或者三个双引号 \"\"\" 注：这并不代表着三个单引号或双引号中的内容就是注释，它们也可用来定义字符串(单行字符串或多行字符串) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:14:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"python关键字 id不是关键字，可以作为变量名，但不建议 python变量名是区分大小写的 关键字 描述 and 逻辑运算符。 as 创建别名。 assert 用于调试。 break 跳出循环。 class 定义类。 continue 继续循环的下一个迭代。 def 定义函数。 del 删除对象。 elif 在条件语句中使用，等同于 else if。 else 用于条件语句。 except 处理异常，发生异常时如何执行。 False 布尔值，比较运算的结果。 finally 处理异常，无论是否存在异常，都将执行一段代码。 for 创建 for 循环。 from 导入模块的特定部分。 global 声明全局变量。 if 写一个条件语句。 import 导入模块。 in 检查列表、元组等集合中是否存在某个值。 is 测试两个变量是否相等。 lambda 创建匿名函数。 None 表示 null 值。 nonlocal 声明非局部变量。 not 逻辑运算符。 or 逻辑运算符。 pass null 语句，一条什么都不做的语句。 raise 产生异常。 return 退出函数并返回值。 True 布尔值，比较运算的结果。 try 编写 try…except 语句。 while 创建 while 循环。 with 用于简化异常处理。 yield 结束函数，返回生成器。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:15:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"del 删除整个列表 del list 删除列表中某个元素 del list[0] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:16:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"切片 浅复制是指复制出的为原内容的引用，存储在同一内存区域，copy()是指对列表中的每一个元素执行浅拷贝，例如列表中嵌套列表，copy出的新列表中的嵌套列表为原来的拷贝 深复制是指复制出的为原内容的拷贝，存储在不同内存区域，deepcopy()是指对列表中的每一个元素执行深拷贝 切片返回的为浅复制，因此可以通过切片直接修改原有序列中那些容器，改变切片中的数值原有容器对应数值并不会改变 但是切片得到和原列表并不是一个对象，两者的id并不相等 \u003e\u003e\u003e x = [1, [2, 3]] \u003e\u003e\u003e y = x[:] \u003e\u003e\u003e id(x) 2491381320136 \u003e\u003e\u003e id(y) 2491381319048 \u003e\u003e\u003e x [1, [2, 3]] \u003e\u003e\u003e y [1, [2, 3]] \u003e\u003e\u003e y[0] = 4 \u003e\u003e\u003e x [1, [2, 3]] \u003e\u003e\u003e y [4, [2, 3]] \u003e\u003e\u003e y[1][0] = 5 \u003e\u003e\u003e x [1, [5, 3]] \u003e\u003e\u003e y [4, [5, 3]] 但是直接赋值得到的和原列表是一个对象，修改其中一个中的任何元素，另一个对应元素也会改变(相当于一个引用) \u003e\u003e\u003e x = [1, [2, 3]] \u003e\u003e\u003e y = x \u003e\u003e\u003e id(x) 2491381319240 \u003e\u003e\u003e id(y) 2491381319240 \u003e\u003e\u003e y[0] = 2 \u003e\u003e\u003e x [2, [2, 3]] \u003e\u003e\u003e y [2, [2, 3]] 切片非常神奇的地方在于，切片的结果和原对象不是同一个对象，但是却可以直接采用切片对原对象进行修改 x = [1,2,1,1,2] print(x, id(x)); print(x[:], id(x[:])) x[len(x):] = [3] print(x) 结果： [1, 2, 1, 1, 2] 2168963063176 [1, 2, 1, 1, 2] 2168963063048 [1, 2, 1, 1, 2, 3] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:17:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"+= python对[-5, 256]内的数字在内存中进行了缓存，所以当多个对象(例如下面的x和y)都等于范围内一个数字时，实际代表的对象就只是一个 \u003e\u003e\u003e x = 3 \u003e\u003e\u003e id(x) 1382786208 \u003e\u003e\u003e id(3) 1382786208 \u003e\u003e\u003e x += 3 \u003e\u003e\u003e id(x) 1382786304 \u003e\u003e\u003e id(6) 1382786304 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:18:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"序列解包 解包：把容器内的元素一个个抽离出来的过程 根据以上结果，可以推断`*a`的结果是将原列表中的两个子列表单独抽离出来 在定义函数时，某个参数名字前面带有2个*符号表示可变长度参数，可以接收任意多个关键参数并将其存放于一个字典之中 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:19:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"排序 x.sort():原地排序，默认升序，```reverse = True````表示降序 sorted():非原地排序，返回排序后的列表，默认升序 reversed()：对列表元素逆序排列返回迭代对象，通过list()可生成列表 def size(x): return x + 5 x = [3, 4, 1, 2] y = sorted(x, key = lambda x : x, reverse = False) print(y) y = sorted(x, key = size, reverse = True) print(y) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:20:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"random模块中常用方法 方法名 功能描述 randint(1,10) 产生 1 到 10 的一个整数型随机数 random() 产生 0 到 1 之间的随机浮点数 uniform(1.1,5.4) 产生 1.1 到 5.4 之间的随机浮点数，区间可以不是整数 choice(’tomorrow') 从序列中随机选取一个元素 randrange(1,100,2) 生成从1到100的间隔为2的随机整数 sample([1, 2, 3, 4, 5], 3) 从列表[1, 2, 3, 4, 5]中随机选择3个元素，如果要生成的个数大于列表中元素数量会报错 random.shuffle([‘A’, ‘B’, ‘C’, ‘D’, ‘E’]) 打乱列表[‘A’, ‘B’, ‘C’, ‘D’, ‘E’]顺序 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:21:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"列表推导式和生成器推导式 列表推导式使用[]生成, 生成器推导式使用()生成 列表推导式的返回值是一个列表，生成器推导式的返回值是一个生成器对象，只能一次遍历 生成器推导式使用()生成，用一个生成一个，在我们不对它进行操作之前，它什么都不会做 x 如果是生成器推导式生成的，list(x)一次使得迭代器遍历结束，因此后一次list(x)的结果就为空了 准确的的理解是，生成器推导式并不会把结果计算出来放入到内存中，而是用一个生成一个，因此只能遍历一次 \u003e\u003e\u003e x = (3 for i in range(3)) \u003e\u003e\u003e x \u003cgenerator object \u003cgenexpr\u003e at 0x0000025F8A7B3A40\u003e \u003e\u003e\u003e list(x) [3, 3, 3] \u003e\u003e\u003e list(x) [] g = (i for i in range(3)) print(g.__next__()) # 0 print(next(g)) # 1 结果： 0 1 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:22:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"while和for循环的else 只要循环不是由break结束的，就会执行else中的语句 while xxx: xxx else: xxx for xxx: xxx else: xxx ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:23:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"条件表达式 在条件表达式中不允许使用赋值运算符“=”，会提示语法错误 \u003e\u003e\u003e if a = 3: SyntaxError: invalid syntax ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:24:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"global关键字 内部函数有引用外部函数的同名变量或者全局变量，并且对这个变量有修改时，Python 会认为它是一个局部变量，如果函数中并没有 x 的定义，则会报错local variable 'xxx' referenced before assignment ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:25:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"pass语句 pass 不做任何事情，一般用做占位语句 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:26:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"函数 如果函数中没有 return 语句，则默认返回空值 None ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"python内置函数 内置函数不需要导入对应模块即可使用 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"callable() callable() 函数用于检查一个对象是否是可调用的 对于函数、方法、lambda 函式、 类以及实现了 call 方法的类实例, 它都返回 True ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"isinstance() 判断一个对象是否是一个已知的类型 isinstance() 与 type() 区别： type() 不会认为子类是一种父类类型，不考虑继承关系。 isinstance() 会认为子类是一种父类类型，考虑继承关系。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"map() map() 函数会根据提供的函数对指定序列做映射 map(function, iterable, ...) 可迭代对象iterable中的每一个元素调用 function 函数，对iterable进行映射，返回映射结果map的迭代器 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"filter() filter(function, iterable) filter() 函数会把iterable中那些使function()返回值为True的元素留下，返回filter迭代器 map() 和 filter()区别： a = [1, 2] b = filter(lambda x : x \u003e 1, a) print(list(b)) \u003e\u003e\u003e [2] c = map(lambda x : x \u003e 1, a) print(list(c)) \u003e\u003e\u003e [False, True] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"zip() 将可迭代的对象作为参数，将对象中对应位置的元素按照下标打包成一个个元组，返回一个zip迭代器，通过list()等转化为其它容器 \u003e\u003e\u003e a = [1, 2, 3] \u003e\u003e\u003e b = [4, 5, 6] \u003e\u003e\u003e c = zip(a, b) \u003e\u003e\u003e list(c) [(1, 4), (2, 5), (3, 6)] # 不是对应位置的结果 a = [1, 2, 3] b = ['a', 'b'] c = zip(a, b) print(list(c)) 结果：[(1, 'a'), (2, 'b')] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:6","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"enumerate() enumerate(iterable, start=0) Parameters: Iterable: any object that supports iteration Start: the index value from which the counter is to be started, by default it is 0 \u003e\u003e\u003e s = \"abc\" \u003e\u003e\u003e o = enumerate(s, 2) \u003e\u003e\u003e o \u003cenumerate object at 0x0000024411E5A240\u003e \u003e\u003e\u003e list(o) [(2, 'a'), (3, 'b'), (4, 'c')] ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:7","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"eval() 函数功能更：执行一个字符串表达式，并返回表达式的值 \u003e\u003e\u003e eval('2 + 2') 4 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:8","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"join() 用于将序列中的元素以指定的字符连接生成一个新的字符串 \u003e\u003e\u003e str = '-' \u003e\u003e\u003e seq = ['a', 'b', 'c'] \u003e\u003e\u003e str.join(seq) 'a-b-c' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:9","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"len() python 3.x 在统计字符串长度时，无论是数字，英文字母还是汉字，计数均按照一个字符处理 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:10","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"reduce() 该函数不是内置函数 代码实现出处 Geeksforgeeks讲解 # reduce()代码实现 def reduce(function, iterable, initializer=None): it = iter(iterable) if initializer is None: value = next(it) # 返回第一个值，详细说明查一下next()，使用一次next，迭代器本身会自增 else: value = initializer for element in it: value = function(value, element) return value # 当缺省initializer时，next(it)会使迭代器会后移一位，因此for循环时会从第2个元素开始 # python code to demonstrate working of reduce() # importing functools for reduce() import functools # initializing list lis = [1, 3, 5, 6, 2, ] # using reduce to compute sum of list print(\"The sum of the list elements is : \", end=\"\") print(functools.reduce(lambda a, b: a+b, lis)) # using reduce to compute maximum element from list print(\"The maximum element of the list is : \", end=\"\") print(functools.reduce(lambda a, b: a if a \u003e b else b, lis)) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:11","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"input() input()函数的返回结果都是字符串,需要将其转换为相应的类型再处理 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:12","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"all() 和 any() all()函数检查序列对象中是否所有元素均等价于True any()函数检查序列对象中是否存在元素等价于True x = [1, 1, 0] print(all(x)) print(any(x)) 结果： False True ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:13","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"sum() sum(iterable, start) 求和，如果计算的不是数值，需要指定start。这并不难理解，数值类型不指定可以认定为0，其他类型很难说 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:14","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"globals() 和 locals() globals()：返回当前作用域内所有全局变量和值的字典 locals()：返回当前作用域内所有局部变量和值的字典 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:27:15","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"字符串 ASCII码：1个字节 GB2312、GBK和CP936：2个字节表示中文 UTF-8：3个字节表示常见汉字 Python 3.x默认使用UTF-8编码，数字、英文字母，汉字，在统计字符串长度时都按一个字符对待和处理 x = \"高\" y = 'a' print(len(x), len(y)) 结果： 1 1 字符串使用r意思是将那些特殊的转义字符看为普通字符，例如’\\n’代表换行，但是r’\\n’仅代表两个字符，一个’'，一个’n’，当我们希望字符串中的’'仅是一个’'字符而非转义符号时，一种方法是’\\’，另一种就是字符串前面加上’r’ \u003e\u003e\u003e s = '\\n' \u003e\u003e\u003e print(s) \u003e\u003e\u003e s = r'\\n' \u003e\u003e\u003e print(s) \\n ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"string中定义的相关常量 whitespace = ' \\t\\n\\r\\v\\f' ascii_lowercase = 'abcdefghijklmnopqrstuvwxyz' ascii_uppercase = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' ascii_letters = ascii_lowercase + ascii_uppercase digits = '0123456789' hexdigits = digits + 'abcdef' + 'ABCDEF' octdigits = '01234567' punctuation = r\"\"\"!\"#$%\u0026'()*+,-./:;\u003c=\u003e?@[\\]^_`{|}~\"\"\" printable = digits + ascii_letters + punctuation + whitespace ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"字符串格式化 %操作符： \u003e\u003e\u003e str = '0x7f' \u003e\u003e\u003e print('I am %s'%str) I am 0x7f format()方法 \u003e\u003e\u003e print(\"I am {}\".format(\"0x7f\")) I am 0x7f \u003e\u003e\u003e print(\"{} {} {}\".format(\"I\", \"am\", \"0x7F\")) I am 0x7F \u003e\u003e\u003e print(\"{2} {1} {0}\".format('c', 'b', 'a')) a b c # 与使用%操作符等价的format格式，例如%s \u003c=\u003e {参数位置:s}，同样可以进行宽度，精度控制 \u003e\u003e\u003e print(\"I am {0:s}\".format(\"0x7F\")) I am 0x7F # 使用‘#’可以添加上不同进制数前面的标志 \u003e\u003e\u003e print('{0:d}, {0:b}, {0:x}, {0:o}'.format(65)) 65, 1000001, 41, 101 \u003e\u003e\u003e print('{0:#d}, {0:#b}, {0:#x}, {0:#o}'.format(65)) 65, 0b1000001, 0x41, 0o101 # 控制精度 \u003e\u003e\u003e print(\"{0:.2f}\".format(11.12345)) 11.12 f-strings方式 weight = 8 height = 8 print(f\"weight:{weight}, height:{height}, weight*height:{weight*height}\") 结果： weight:8, height:8, weight*height:64 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"find() 和 rfind() str.find(str, beg=0, end=len(string)) str：待查询字符串 beg：规定开始位置下标 end: 规定结束位置下标的后一位(即左闭右开区间) find()返回待查询字符串作为子串在当前字符串中第一次出现的位置，如果没有匹配项则返回 -1 rfind()返回待查询字符串作为子串在当前字符串中最后一次出现的位置，如果没有匹配项则返回 -1 \u003e\u003e\u003e n = 6 \u003e\u003e\u003e x = bin(n) \u003e\u003e\u003e x '0b110' \u003e\u003e\u003e x.rfind('1') 3 \u003e\u003e\u003e str = \"abc\" \u003e\u003e\u003e str.find('b', 0, 1) -1 \u003e\u003e\u003e str.find('b', 0, 2) 1 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"startswith() 检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False str.startswith(str, beg=0,end=len(string)) str：待查询字符串 beg：规定开始位置下标 end: 规定结束位置下标的后一位(即左闭右开区间) \u003e\u003e\u003e 'abc'.startswith('a', 1) False \u003e\u003e\u003e 'abc'.startswith('a', 0) True \u003e\u003e\u003e 'abcd'.startswith('bc', 1, 2) False \u003e\u003e\u003e 'abcd'.startswith('bc', 1, 3) True ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"index() 和 rindex() index()：返回一个字符串在另一个字符串中作为子串第一次出现的位置，不存在则抛出异常 rindex()：返回一个字符串在另一个字符串中作为子串最后一次出现的位置，不存在则抛出异常 \u003e\u003e\u003e str = \"abb,a,s\" \u003e\u003e\u003e str.index('a') 0 \u003e\u003e\u003e str.rindex('a') 4 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"count() 返回一个字符串作为子串在当前字符串中出现的次数 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:6","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"split() str.split(str=\"\", num=string.count(str)). str – 分隔符，默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)等。 num – 分割次数。分割num次生成num+1个子串。默认为 -1, 即分隔所有。 当不指定分隔符时，采取默认的空白字符(上方提到的)，切分结果中的空字符会被自动删除 指定分隔符时，空字符不会被删除 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:7","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"partition() 根据指定的分隔符将字符串进行分割，返回一个3元的元组 如果分割符在待分割字符串中，那么第一个为分隔符左边的子串，第二个为分隔符本身，第三个为分隔符右边的子串 如果分隔符不在待分割字符串中，那么第一个为原字符串，第二个和第三个为空字符串 str = 'abc' \u003e\u003e\u003e str.partition('a') ('', 'a', 'bc') \u003e\u003e\u003e str.partition('b') ('a', 'b', 'c') \u003e\u003e\u003e str.partition('c') ('ab', 'c', '') \u003e\u003e\u003e str.partition('d') ('abc', '', '') ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:8","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"upper()， lower()， swapcase() upper(): 小写字母转大写字母 lower(): 大写字母转小写字母 swapcase(): 将大小写字母进行颠倒，小写-\u003e大写，大写-\u003e小写 \u003e\u003e\u003e str = \"i AM 0x7f\" \u003e\u003e\u003e str.swapcase() 'I am 0X7F' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:9","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"ljust() 和 rjust() ljust(): 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串 rjust():返回一个原字符串右对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串 \u003e\u003e\u003e str = '!abc' \u003e\u003e\u003e str.ljust(6, '*') '!abc**' \u003e\u003e\u003e str.rjust(6, '*') '**!abc' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:10","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"maketrans() 和 translate() maketrans(): 创建字符映射的转换表。第一个参数是字符串，表示需要转换的字符，第二个参数也是字符串表示转换的目标。两个字符串的长度必须相同，为一一对应的关系 translate(): 根据maketrans()生成的转换表，将字符串中的响应字符进行转换 # 这里如果不通过字符串调用maketrans，就需要导入相应模块，哪个字符串调用都无所谓 \u003e\u003e\u003e table = ''.maketrans('abcw', 'xyzc') \u003e\u003e\u003e 'Hellow world'.translate(table) 'Helloc corld' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:11","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"replace() string.replace(old, new, count) 不要求全字匹配，子串即可 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:12","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"strip(), lstrip() 和 rstrip() 3种方法提供的字符串可以是一个字符，或者多个字符，匹配时不是按照整个字符串匹配的，而是一个个匹配的 strip():移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。方法只能删除开头或是结尾的字符，不能删除中间部分的字符 \u003e\u003e\u003e 'aaasdfaaas'.strip(\"as\") 'df' lstrip(): 截掉字符串左边的空格或指定字符 \u003e\u003e\u003e 'aaasdfaaas'.lstrip('as') 'dfaaas' rstrip(): 删除 string 字符串末尾的指定字符（默认为空格） \u003e\u003e\u003e 'aaasdfaaas'.rstrip(\"as\") 'aaasdf' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:13","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"isalnum(), isalpha() 和 isdigit() isalnum(): 检测字符串是否由字母和数字组成 返回值： True：如果所有的字符均是字母或数字 False：如果一个或多个字符不是字母和数字 isalpha(): 检测字符串是否只由字母组成 isdigit(): 检测字符串是否只由数字组成 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:14","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"encode() 和 decode() 默认均为utf-8编码 编码：str.encode(encoding='UTF-8',errors='strict') 解码：str.decode(encoding='UTF-8',errors='strict') ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:15","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"compress() 和 decompress() zlib.compress(): 字符串压缩 zlib.decompress(): 字符串解压缩 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:28:16","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"正则表达式re ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"re.match() 从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none re.match(pattern, string, flags=0) 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：正则表达式修饰符 - 可选标志 匹配成功re.match方法返回一个匹配的对象，否则返回None # 在起始位置匹配 \u003e\u003e\u003e print(re.match('www', 'www.runoob.com').span()) (0, 3) # 不在起始位置匹配 \u003e\u003e\u003e print(re.match('com', 'www.runoob.com')) None ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"re.search() 扫描整个字符串并返回第一个成功的匹配，未找到则返回None re.search(pattern, string, flags=0) 参数 描述 pattern 匹配的正则表达式 string 要匹配的字符串。 flags 标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。 # 在起始位置匹配 \u003e\u003e\u003e print(re.search('www', 'www.runoob.com').span()) (0, 3) # 不在起始位置匹配 print(re.search('com', 'www.runoob.com').span()) (11, 14) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"re.findall() 与 re.search()的差异 \u003e\u003e\u003e re.search(r'\\w*?(?P\u003cf\u003e\\b\\w+\\b)\\s+(?P=f)\\w*?', 'Beautiful is is better than ugly.').group(0) 'is is' \u003e\u003e\u003e re.search(r'\\w*?(?P\u003cf\u003e\\b\\w+\\b)\\s+(?P=f)\\w*?', 'Beautiful is is better than ugly.').group(1) 'is' \u003e\u003e\u003e re.findall(r'\\w*?(?P\u003cf\u003e\\b\\w+\\b)\\s+(?P=f)\\w*?', 'Beautiful is is better than ugly.') ['is'] search任何时候都将整个正则视为一个分组，group(0)，这也是search的默认返回结果，其他括号也都算一个分组可通过group(index)方法来获取对应分组的匹配结果； findall在没有括号时将整个正则视为一个分组，有括号时只认括号内的分组，仅仅匹配分组里面的内容，然后返回这个组的列表; 如果有多个分组，那就把每一个分组看成一个单位，组合为一个元组，然后返回一个含有多个元组的列表。如果想要在使用findall()时将整个正则表达式视为分组，把小括号仅作为一个整体来匹配，可以采用非捕获分组 参考资料 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"re.sub() re.sub(pattern, repl, string, count=0, flags=0) 替换字符串中的匹配项，如果匹配项没有找到，则不加改变地返回 string pattern : 正则中的模式字符串。 repl : 替换的字符串，也可为一个函数。 string : 要被查找替换的原始字符串。 count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。 \u003e\u003e\u003e re.sub('\\d', '1', 'a12345bbbb67c890d0e') 'a11111bbbb11c111d1e' # 注意默认采用的是贪婪模式，因此会尽可能多的进行匹配，所以连着的数字就被匹配为1个元素了 \u003e\u003e\u003e re.sub('\\d+', '1', 'a12345bbbb67c890d0e') 'a1bbbb1c1d1e' ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"re.compile() re.compile(pattern, flags=0) 编译正则表达式，生成一个正则表达式（ Pattern ）对象，供 match() 和 search() 这两个函数使用。 pattern : 一个字符串形式的正则表达式 flags : 可选，表示匹配模式，比如忽略大小写，多行模式等，具体参数为： re.I(IGNORECASE) 忽略大小写 re.L(LOCALE) 表示特殊字符集 \\w, \\W, \\b, \\B, \\s, \\S 依赖于当前环境 re.M(MULTILINE) 多行模式 re.S(DOTALL) 即为 . 并且包括换行符在内的任意字符（. 不包括换行符） re.U(UNICODE) 表示特殊字符集 \\w, \\W, \\b, \\B, \\d, \\D, \\s, \\S 依赖于 Unicode 字符属性数据库 re.X(VERBOSE) 为了增加可读性，忽略空格和 # 后面的注释 \u003e\u003e\u003e pattern = re.compile('\\d+') \u003e\u003e\u003e m = pattern.match('123abc') \u003e\u003e\u003e m \u003c_sre.SRE_Match object; span=(0, 3), match='123'\u003e ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:29:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"模块 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:30:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"模块的作用 提高代码可维护性 提高代码可重用性 重新导入一个模块，使用imp模块的reload函数 在导入模块时，会优先导入相应的pyc文件,如果相应的pyc文件与py文件时间不相符，则导入py文件并重新编译该模块 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:30:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"导入模块时的文件搜索顺序 在 import 导入 module 时，会遵循以下的优先级进行搜索 当前文件夹 sys.path变量指定的文件夹 优先导入pyc文件 我们可以通过如下的方式来查看目前的 module 的搜索路径以及某个具体的 module 所在的路径 \u003e\u003e\u003e from sys import path \u003e\u003e\u003e path ['', '/home/user', '/home/user/miniconda3/lib/python39.zip', '/home/user/miniconda3/lib/python3.9', '/home/user/miniconda3/lib/python3.9/lib-dynload', '/home/user/miniconda3/lib/python3.9/site-packages'] \u003e\u003e\u003e import pip \u003e\u003e\u003e pip \u003cmodule 'pip' from '/home/user/miniconda3/lib/python3.9/site-packages/pip/__init__.py'\u003e 有两种方式修改导入 module 的搜索路径 1 通过 sys.path.append() 通过 PYTHONPATH environment variable 在使用这两种方式指定搜索路径后，即可直接通过 import 引入指定目录下的 module ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:30:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"代码规范性 检查工具：pep8工具，flake8，pylint ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:31:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"包 包是一个包含__init__.py文件的文件夹 打包工具：py2exe，pyinstaller，cx_Freeze ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:32:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"函数的设计与使用 参数传递传的是引用而非值 def add(x): a = x print(id(a)) a += 1 print(id(a)) y = 5 print(id(y)) add(y) 结果： 1409066208 1409066208 1409066240 如果实参为序列对象，在函数内部采用序列对象原地操作的方法就可以实现通过形参修改实参了 2. 参数类型：普通参数，默认值参数，关键参数，可变长度参数 默认值参数必须出现在函数参数列表的最右端，任何一个默认值参数右边不能有非默认值参数 可变长度参数 *parameter用来接收多个位置实参并将其放在元组中 parameter接收多个关键参数**并存放到字典中 def fun1(*x): print(x) def fun2(**x): print(x) fun1(1, 2, 3) fun2(a = 1, b = 2, c = 3) 结果： (1, 2, 3) {'a': 1, 'b': 2, 'c': 3} 对字典进行两次解包后参数传递 \u003c=\u003e 关键参数传递 def fun(a, b): print(a, b) dic = {'a':1, 'b':2} fun(**dic) fun(a = 1, b = 2) 结果： 1 2 1 2 4.当函数执行结束后，局部变量自动删除 5.nonlocal：闭包作用域变量，nonlocal声明的变量会引用距离最近的非全局作用域的变量，用于内部函数中使用外部函数的局部变量 7. 如何理解yield创建生成器对象 6. 修饰器（decorator，包装器），本质上也是一个函数，只不过这个函数接收其他函数作为参数并对其进行一定的改造之后返回新函数。(函数即对象) ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:33:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"面向对象程序设计 OOP支持代码复用 和 设计复用 基本原则：计算机程序由多个能够起到子程序作用的单元或对象组合而成 基本功能：封装，继承，多态，对基类方法的重写 类包含：数据成员(用变量表示的对象属性)，成员方法(用函数表示的对象行为) 类名的首字母一般要大写 Python 类中属性和方法所在的位置是任意的 类的所有实例方法都必须至少有一个名为self的参数，且必须是方法的第一个形参 混入机制(mixin)：可以动态地为自定义类和对象增加或删除成员 实例对象仅可以访问类变量，无法修改，修改实际是在定义新的实例变量; 实例变量和类变量重名时， 实例对象会首选实例变量 class T : val = 5 t = T() print(t.val) t.val = 3 print(t.val) t2 = T() T.val = 4 print(t.val) print(t2.val) 结果： 5 3 3 4 11.如果数据成员为容器类对象，则通过实例修改和通过类修改，所有实例均会发生改变 class T : val = [0] t = T() t2 = T() print(t.val) print(t2.val) t.val[0] = 1 print(t.val) print(t2.val) T.val[0] = 2 print(t.val) print(t2.val) 结果： [0] [0] [1] [1] [2] [2] 12.函数和方法的区别在于方法具有第一个隐式参数self 13. _xxx：受保护成员，不能用’from module import *‘导入； __xxx__：系统定义的特殊成员； __xxx：私有成员(\u003e=2个‘_’开头的数据成员)，只有类对象自己能访问，子类对象不能直接访问到这个成员，但在对象外部可以通过“对象名._类名__xxx”这样的特殊方式来访问。 14.类中方法：公有方法，私有方法，静态方法(@staticmethod)，类方法(@classmethod) 静态方法和类方法只能访问类的成员 15.@property，保护类的封装特性 class T : def __init__(self, val): self.__val = val @property def getVal(self) : return self.__val t = T(5) print(t.getVal) # @property修饰，不需要加() 结果：5 16.特殊方法 17. 多态的定义：基类的同一个方法在不同派生类对象中具有不同的表现和行为 多态的前提条件：1.继承：发生在子类和父类之间 2.重写：子类重写父类方法 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:34:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"简答题 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"简单解释 Python 基于值的自动内存管理方式 在 Python 中可以为不同变量赋值为相同值，这个值在内存中只有一份，多个变量指向同一个内存地址； Python 具有自动内存管理功能，会自动跟踪内存中所有的值，对于没有任何变量指向的值，Python 自动将其删除。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:1","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Python 运算符\u0026的两种功能 数字位运算 集合交集运算 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:2","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"Python 中导入模块中的对象的几种方式 import 模块名 [as 别名] from 模块名 import 对象名 [as 别名] from 模块名 import * 1与3的区别在于，对于模块内的方法名，1需要以模块名为前导，3则可以直接使用 \u003e\u003e\u003e sqrt(4.0) Traceback (most recent call last): File \"\u003cpyshell#0\u003e\", line 1, in \u003cmodule\u003e sqrt(4.0) NameError: name 'sqrt' is not defined \u003e\u003e\u003e import math \u003e\u003e\u003e sqrt(4.0) Traceback (most recent call last): File \"\u003cpyshell#2\u003e\", line 1, in \u003cmodule\u003e sqrt(4.0) NameError: name 'sqrt' is not defined \u003e\u003e\u003e math.sqrt(4.0) 2.0 \u003e\u003e\u003e from math import * \u003e\u003e\u003e sqrt(4.0) 2.0 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:3","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"解释 Python 脚本程序的“name”变量及其作用 每个 Python 脚本在运行时都有一个“name”属性。 如果脚本作为模块被导入，则其“name”属性的值被自动设置为模块名； 如果脚本独立运行，则其“name”属性值被自动设置为“main”。 利用“name”属性即可控制 Python 程序的运行方式。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:4","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"为什么应尽量从列表的尾部进行元素的增加与删除操作 当列表增加或删除元素时，列表对象自动进行内存扩展或收缩，从而保证元素之间没有缝隙， 但这涉及到列表元素的移动，效率较低，应尽量从列表尾部进行元素的增加与删除操作以提高处理速度。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:5","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"析逻辑运算符“or”的短路求值特性 假设有表达式“表达式 1 or 表达式 2”， 如果表达式 1 的值等价于 True，那么无论表达式 2 的值是什么，整个表达式的值总是等价于 True。 因此，不需要再计算表达式 2 的值。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:6","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"简单解释 Python 中短字符串驻留机制 对于短字符串，将其赋值给多个不同的对象时，内存中只有一个副本，多个对象共享改副本。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:7","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"异常和错误有什么区别 异常是指因为程序执行过程中出错而在正常控制流以外采取的行为。 严格来说，语法错误和逻辑错误不属于异常，但有些语法错误往往会导致异常， 例如由于大小写拼写错误而访问不存在的对象，或者试图访问不存在的文件，等等。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:8","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"使用 pdb 模块进行 Python 程序调试主要有哪几种用法 在交互模式下使用 pdb 模块提供的功能可以直接调试语句块、表达式、函数等多种脚本。 在程序中嵌入断点 来实现调试功能。在程序中首先导入 pdb 模块，然后使用 **pdb.set_trace()**在需要的位置设置断点。 如果程序中存在通过该方法调用显式插入的断点，那么在命令提示符环境下执行该程序或双击执行程序时将自动打开 pdb 调试环境，即使该程序当前不处于调试状态。 使用命令行调试程序。在命令行提示符下执行“python –m pdb 脚本文件名”，则直接进入调试环境；当调试结束或程序正常结束以后，pdb 将重启该程序。 ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:35:9","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Python"],"content":"文件操作 访问模式 说明 r 以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。 w 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a 打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 rb 以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。 wb 以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 ab 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。 r+ 打开一个文件用于读写。文件指针将会放在文件的开头。 w+ 打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 a+ 打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。 rb+ 以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。 wb+ 以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。 ab+ 以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。 文件对象常用方法 2.序列化：把内存中的数据在不丢失其类型信息的情况下转成对象的二进制形式的过程 常用的序列化模块有struct、pickle、marshal和shelve os模块 和 os.path模块 常用方法 os模块 os.path模块 魔术方法（Magic methods） Python 魔术方法指南 第三方拓展魔术命令 IPython-Magic functions Magic functions介绍 Reference [1] How to uninstall python3 from Ubuntu PYTHONPATH Explained | YouTube ↩︎ ","date":"2021-10-04","objectID":"/blog/posts/python/python-basic/:36:0","tags":null,"title":"Python Basic","uri":"/blog/posts/python/python-basic/"},{"categories":["Math"],"content":"点 单个点 ($\\cdot$) ： $\\cdot$ 横向多个点 ($\\cdots$) : $\\cdots$ 竖向多个点 ($\\vdots$) : $\\vdots$ 斜向多个点 ($\\ddots$) : $\\ddots$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:1:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"数学字体 mathbb：blackboard bold（黑板粗体），用于期望 mathbf：math boldface，用于矩阵、向量 mathrm：math roman，罗马体（整体），用于微分符号d、二项式系数C、等号上的def、自然常数e、虚数单位i mathcal：math calligraphy（美术字），用于集合，分布 A $A$ $\\mathbb{A}$ $\\mathbf{A}$ $\\mathrm{A}$ $\\mathcal{A}$ A $A$ $\\mathbb{A}$ $\\mathbf{A}$ $\\mathrm{A}$ $\\mathcal{A}$ 参考 Latex数学字体 【latex】\\mathbf{} \\matrm{} ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:2:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"公式标号 在块级公式($$$$)中使用\\tag{自定义编号} 引用使用$(自定义编号)$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:3:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"表达式 将下标放置于文本正上/下方 $\\sum_{i=1}^n$ $\\sum_{i=1}^n$ $\\sum \\limits_{i=1} \\limits^n$ $\\sum \\limits_{i=1} \\limits^n$ 需要注意的是其仅仅支持应用于数学的操作符,若需要在非数学操作符上下方添加文字,需要通过\\mathop将表达式转化为数学操作符,示例如下 $\\mathop{minimize} \\limits_{w,b} J(w, b)$ $\\mathop{minimize} \\limits_{w,b} J(w, b)$ 参考 [1] LaTex中把下标置于文本正下方的方法 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:4:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"数学模式重音符号1 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:5:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"希腊字母 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:6:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"二元关系 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:7:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"二元运算 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:8:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"“大”运算符 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:9:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"箭头 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:10:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"定界符 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:11:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"大定界符 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:12:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"其它符号 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:13:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"非数学符号 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:14:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS定界符 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:15:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS希腊和希伯来字母 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:16:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS二元关系 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:17:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS箭头 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:18:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS二元否定关系符和箭头 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:19:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS二元运算符 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:20:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"AMS其它符号 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:21:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"数字字母 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:22:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"矩阵 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"无括号 $$ \\begin{matrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{matrix} $$ $$ \\begin{matrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{matrix} $$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:1","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"圆括号 pmatrix (parentheses brackets matrix) $$ \\begin{pmatrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{pmatrix} $$ $$ \\begin{pmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{pmatrix} $$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:2","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"方括号 bmatrix (brackets matrix) $$ \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{bmatrix} $$ $$ \\begin{bmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{bmatrix} $$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:3","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"花括号 $$ \\begin{Bmatrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{Bmatrix} $$ $$ \\begin{Bmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{Bmatrix} $$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:4","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"单竖线括号 vmatrix (vertical bar brackets matrix) $$ \\begin{vmatrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{vmatrix} $$ $$ \\begin{vmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{vmatrix} $$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:5","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"双竖线括号 $$ \\begin{Vmatrix} 1 \u0026 2 \u0026 3 \\ 4 \u0026 5 \u0026 6 \\ 7 \u0026 8 \u0026 9 \\end{Vmatrix} $$ $$ \\begin{Vmatrix} 1 \u0026 2 \u0026 3 \\\\ 4 \u0026 5 \u0026 6 \\\\ 7 \u0026 8 \u0026 9 \\end{Vmatrix} $$ 参考 [1] 各种数学符号 [2] 转义表示 ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:23:6","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"极限符号 $\\lim_{n \\to \\infty}$ $\\lim_{n \\to \\infty}$ $\\lim \\limits_{n \\to \\infty}$ $\\lim \\limits_{n \\to \\infty}$ $\\displaystyle \\lim_{n \\to \\infty}$ $\\displaystyle \\lim_{n \\to \\infty}$ $\\varlimsup \\limits_{n \\to \\infty}$ $\\varlimsup \\limits_{n \\to \\infty}$ $\\varliminf \\limits_{n \\to \\infty}$ $\\varliminf \\limits_{n \\to \\infty}$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:24:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Math"],"content":"存在任意 $\\forall$ $\\forall$ $\\exists$ $\\exists$ ","date":"2021-09-23","objectID":"/blog/posts/math/latex-grammar-summary/:25:0","tags":null,"title":"Latex Grammar Summary","uri":"/blog/posts/math/latex-grammar-summary/"},{"categories":["Algorithm"],"content":"说明 为了突出各类题目的区别，以下例题均选择较为简单的题目。不会涉及一些非常巧妙的技巧，摆脱一些细枝末节，以便更多地关注到题目类型本身 ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:1:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"连通块问题 题目描述 农夫约翰有一片 $N∗M$ 的矩形土地。 最近，由于降雨的原因，部分土地被水淹没了。 现在用一个字符矩阵来表示他的土地。 每个单元格内，如果包含雨水，则用”W”表示，如果不含雨水，则用”.”表示。 现在，约翰想知道他的土地中形成了多少片池塘。 每组相连的积水单元格集合可以看作是一片池塘。 每个单元格视为与其上、下、左、右、左上、右上、左下、右下八个邻近单元格相连。 请你输出共有多少片池塘，即矩阵中共有多少片相连的”W”块。 解题思路 遍历所有格子，如果为\"W\"并且未曾标记过，则从此格子开始搜索，标记其周边所有可达的\"W\"并进行计数 解题代码(C++) #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e #include \u003ccstdio\u003e using namespace std; typedef pair\u003cint, int\u003e PII; const int N = 1010, M = N * N; int n, m; char g[N][N]; bool st[N][N]; PII q[M]; int dx[] = {-1, -1, -1, 0, 0, 1, 1, 1}; int dy[] = {-1, 0, 1, -1, 1, -1, 0, 1}; void dfs(int sx, int sy) { int hh = 0, tt = -1; q[++ tt] = {sx, sy}; st[sx][sy] = true; while (tt \u003e= hh) { PII t = q[hh ++]; int xx = t.first, yy = t.second; for (int i = 0; i \u003c 8; ++ i) { int x = xx + dx[i], y = yy + dy[i]; if (x \u003c 0 || x \u003e= n || y \u003c 0 || y \u003e= m || g[x][y] == '.' || st[x][y]) continue; q[++ tt] = {x, y}; st[x][y] = true; } } } int main() { cin \u003e\u003e n \u003e\u003e m; for (int i = 0; i \u003c n; ++ i) cin \u003e\u003e g[i]; int res = 0; for (int i = 0; i \u003c n; ++ i) for (int j = 0; j \u003c m; ++ j) if (g[i][j] == 'W' \u0026\u0026 !st[i][j]) { ++ res; dfs(i, j); } cout \u003c\u003c res \u003c\u003c endl; return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:2:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"最短路问题 BFS同最短路算法一样，都是用来解决图上最短路问题，不同的是BFS对图有一些更为严格的要求 最短路算法可以解决单源最短路和多源最短路，路径长度只存在是否存在负权边和负权回路的区分 但BFS只能解决单源最短路，并且路径长度只能是全部相等或只存在两种值(由此分为以下两类) ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:3:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"路径长度均相等 题目描述 给定一个 $n × n$ 的二维数组，如下所示： int maze[5][5] = { 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, }; 它表示一个迷宫，其中的1表示墙壁，0表示可以走的路，只能横着走或竖着走，不能斜着走，要求编程序找出从左上角到右下角的最短路线。 数据保证至少存在一条从左上角走到右下角的路径。 解题思路 采用队列，实现层序遍历。所有点只会入队一次，且出队时对应的路径即为最短路径 证明出队时得到的距离一定为最短距离: 方法1-借助Dijkstra算法 首先需要根据数学归纳法证明采用队列进行层序遍历的BFS具有两段性和单调性 例如序列 $|x, x, x, | x+1, x+1, x+1|$，其具备两段性是指数据最多可以分为两部分，即这里的x和x+1 首先选择队头元素x进行扩展，假设边的距离均为1，那么由它扩展出的距离均为x+1，放到队尾，显然序列仍然满足两端性和单调性 在满足两段性和单调性的前提下，考虑堆优化版Dijkstra算法。每次从优先队列的对头取出元素，并更新所有相邻的点，对于遍历顺序而言同样具有两段性和单调性，所以与我们目前的做法是一致的。由于Dijkstra算法是正确的，所以目前的做法就是正确的 方法2-直接证明 ​ 利用反证法，假设此时队头元素$s$并非最短距离，即后续状态中存在$t$，满足$dis[s] \u003e dis[t] + w$。在方法1中已经证得，序列满足单调性，即$dis[s] \u003c= dis[t]$，与假设发生矛盾，所以假设不成立，即队头元素s一定为最短距离。 解题代码(C++) #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e #include \u003ccstdio\u003e using namespace std; typedef pair\u003cint, int\u003e PII; const int N = 1010, M = N * N; int n; int m[N][N]; bool st[N][N]; int dx[] = {-1, 0, 1, 0}; int dy[] = {0, 1, 0, -1}; PII q[M]; PII path[N][N]; PII nextLoca[N][N]; void bfs(int sx, int sy) { int hh = 0, tt = -1; q[++ tt] = {sx, sy}; st[sx][sy] = true; while (tt \u003e= hh) { PII t = q[hh ++]; int xx = t.first, yy = t.second; for (int i = 0; i \u003c 4; ++ i) { int x = xx + dx[i], y = yy + dy[i]; if (x \u003c 0 || x \u003e= n || y \u003c 0 || y \u003e= n || st[x][y] || m[x][y]) continue; st[x][y] = true; q[++ tt] = {x, y}; nextLoca[x][y] = {xx, yy}; } } } int main() { cin \u003e\u003e n; for (int i = 0; i \u003c n; ++ i) for (int j = 0;j \u003c n; ++ j) cin \u003e\u003e m[i][j]; nextLoca[n - 1][n - 1] = {n - 1, n - 1}; bfs(n - 1, n - 1); PII t = {0, 0}; while (1) { int x = t.first, y = t.second; cout \u003c\u003c x \u003c\u003c ' ' \u003c\u003c y \u003c\u003c endl; if (x == n - 1 \u0026\u0026 y == n - 1) break; t = nextLoca[x][y]; } return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:3:1","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"包含两种路径长度 原题链接 题目描述 给定一个长度为 $n$ 的 $3$ 跑道道路 ，一个跑道总共包含 $n + 1$ 个点 ，编号为 $0$ 到 $n$ 。一只青蛙从第二条跑道的 $0$ 号点出发 ，终点为任一跑道的点 $n$ 处。跑道上可能有一些障碍(保证点$0$ 和点 $n$ 处任一跑道均无障碍)。面对前方的障碍时，青蛙可以选择侧跳到其它跑道(两条跑道可以不相邻)的同一点，询问到达终点青蛙最少的侧跳次数 ​ 示例： ​ 下图中青蛙的最少侧跳次数为2 ​ 题目分析 将左右移动的花费设为0，上下移动的花费设为1，显然本题可以抽象为边权仅含0和1的图上单源最短路问题。使用最短路算法自然可以解决，但是需要建图。而BFS是无需建图的，可以直接搜索。但BFS的问题在于，其仅能解决边权均相等的图，所以引入双端队列解决这个缺陷。 解题策略： 仍按照一般BFS的搜索顺序，从双端队列队头取点进行扩展。不同的是当遇到边为0的点放入队头，边为1的点放入队尾。所有状态扩展完毕后得到终点的最短路径 证明双端队列加持下的BFS的正确性： 只需证明此时的序列仍然满足两段性和单调性即可。假设此时的序列为 $|x, x, x, | x+1, x+1, x+1|$，从队头取出元素$x$，若扩展出的点边为0则将$x+0$放入队头，边为1则将$x+1$放入队尾，显然变化后的序列仍然满足两段性和单调性，即双端队列BFS是正确的。 解题代码(C++) // leetcode部分实现 const int N = 500010; class Solution { public: int bfs(vector\u003cvector\u003cint\u003e\u003e \u0026g, int n) { vector\u003cvector\u003cbool\u003e\u003e st(3, vector\u003cbool\u003e(N, false)); vector\u003cvector\u003cint\u003e\u003e dis(3, vector\u003cint\u003e(N, 0x3f3f3f3f)); deque\u003cpair\u003cint, int\u003e\u003e q; int dx[] = {-2, -1, 1, 2, 0, 0}, dy[] = {0, 0, 0, 0, 1, -1}; q.push_front({1, 0}); dis[1][0] = 0; while (q.size()) { auto t = q.front(); q.pop_front(); int x = t.first, y = t.second; if (st[x][y]) continue; st[x][y] = true; for (int i = 0; i \u003c 6; ++ i) { int a = x + dx[i], b = y + dy[i]; if (a \u003c 0 || a \u003e= 3 || b \u003c 0 || b \u003e= n) continue; if (g[a][b] == 1) continue; // 有障碍无法走 if (dis[a][b] \u003e dis[x][y] + (i == 0 || i == 1 || i == 2 || i == 3)) { dis[a][b] = dis[x][y] + (i == 0 || i == 1 || i == 2 || i == 3); if (i == 0 || i == 1 || i == 2 || i == 3) q.push_back({a, b}); else q.push_front({a, b}); } } } int res = 0x3f3f3f3f; for (int i = 0; i \u003c 3; ++ i) res = min(res, dis[i][n - 1]); return res; } int minSideJumps(vector\u003cint\u003e\u0026 obstacles) { vector\u003cvector\u003cint\u003e\u003e g(3, vector\u003cint\u003e(N, 0)); int n = obstacles.size(); for (int i = 0; i \u003c n; ++ i) if (obstacles[i]) g[obstacles[i] - 1][i] = 1; return bfs(g, n); } }; // 全部实现 #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e #include \u003ccstdio\u003e #include \u003cdeque\u003e using namespace std; const int N = 500010; int n; int obstacles[N], g[3][N]; int st[3][N]; int dis[3][N]; int bfs() { memset(dis, 0x3f, sizeof dis); deque\u003cpair\u003cint, int\u003e\u003e q; int dx[] = {-2, -1, 1, 2, 0, 0}, dy[] = {0, 0, 0, 0, 1, -1}; q.push_front({1, 0}); dis[1][0] = 0; while (q.size()) { auto t = q.front(); q.pop_front(); int x = t.first, y = t.second; if (st[x][y]) continue; st[x][y] = true; for (int i = 0; i \u003c 6; ++ i) { int a = x + dx[i], b = y + dy[i]; if (a \u003c 0 || a \u003e= 3 || b \u003c 0 || b \u003e= n) continue; if (g[a][b] == 1) continue; // 有障碍无法走 if (dis[a][b] \u003e dis[x][y] + (i == 0 || i == 1 || i == 2 || i == 3)) { dis[a][b] = dis[x][y] + (i == 0 || i == 1 || i == 2 || i == 3); if (i == 0 || i == 1 || i == 2 || i == 3) q.push_back({a, b}); else q.push_front({a, b}); } } } int res = 0x3f3f3f3f; for (int i = 0; i \u003c 3; ++ i) res = min(res, dis[i][n - 1]); return res; } int main() { cin \u003e\u003e n; for (int i = 0; i \u003c n; ++ i) cin \u003e\u003e obstacles[i]; for (int i = 0; i \u003c n; ++ i) if (obstacles[i]) g[obstacles[i] - 1][i] = 1; cout \u003c\u003c bfs() \u003c\u003c endl; return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:3:2","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"最小步数问题 在连通块问题和最短路问题中，搜索的点均为图上的一个有坐标的点。在最小步数问题中，搜索的点变为一个包含各种信息的状态。不过在理解了相关问题之后，可以发现这些状态实际上还是可以看为图上的点。 ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:4:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"一般做法 题目描述 原题链接 一个板子含有8个格子，每一个方格都有一种颜色。从板子的左上角开始，沿顺时针方向依次取出整数，构成一个颜色序列。可以用改颜色序列表示这个板子的状态。 例如：可以用序列12345678表示下面这个板子(同时该状态作为基本状态) 1 2 3 4 8 7 6 5 题目提供三种基本操作(由基本状态进行演示)： A：交换上下两行 8 7 6 5 1 2 3 4 B：将最右边的一列插入到最左边 4 1 2 3 5 8 7 6 C：魔板中央对的4个数作顺时针旋转 1 7 2 4 8 6 3 5 给定目标状态，询问由基本状态到目标状态的操作序列 题目分析 由基本状态到目标状态，每一个状态都是一个颜色序列。搜索的图上的”点”也就变为了这些序列。 两个\"点\"之间仅通过一步操作，所以图上边权均相等，采用一般BFS即可。 目前的重点在于理解“搜索的点实际上是一个状态”，至于代码实现时所需的哈希，通过坐标变换实现一维空间与二维空间的相互映射这里就不再赘述了 代码实现 /** * 坐标映射 * A:字符串翻转 * B:a[3]移动到a[0],a[4]移动到a[7] * c:a[1]-\u003ea[2], a[2]-\u003ea[5], a[5]-\u003ea[6], a[6]-\u003ea[1] * * 由于本题只有两行，所以也可以采用二维数组直接模拟二维空间，不需要进行一维到二维的坐标映射 */ #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003cstring\u003e #include \u003cmap\u003e #include \u003cunordered_map\u003e using namespace std; typedef pair\u003cchar, string\u003e PII; const int N = 40500; unordered_map\u003cstring, int\u003e dis; unordered_map\u003cstring, PII\u003e path; string q[N]; char stk[N]; int bfs(string end) { string start = \"12345678\"; int hh = 0, tt = -1; dis[start] = 0; q[++ tt] = start; while (tt \u003e= hh) { string t = q[hh ++]; if (t == end) return dis[t]; string a(t); reverse(a.begin(), a.end()); if (!dis.count(a)) { dis[a] = dis[t] + 1; path[a].first = 'A', path[a].second = t; q[++ tt] = a; } string b(t); char u(b[3]), v(b[4]); for (int i = 3; i \u003e 0; -- i) b[i] = b[i - 1]; b[0] = u; for (int i = 4; i \u003c 7; ++ i) b[i] = b[i + 1]; b[7] = v; if (!dis.count(b)) { dis[b] = dis[t] + 1; path[b].first = 'B', path[b].second = t; q[++ tt] = b; } string c(t); u = c[6]; c[6] = c[5]; c[5] = c[2]; c[2] = c[1]; c[1] = u; if (!dis.count(c)) { dis[c] = dis[t] + 1; path[c].first = 'C', path[c].second = t; q[++ tt] = c; } } return -1; } int main() { string end(\"\"); for (int i = 0; i \u003c 8; ++ i) { char c; cin \u003e\u003e c; end += c; } cout \u003c\u003c bfs(end) \u003c\u003c endl; int tt = -1; for (string s = end; s != \"12345678\"; s = path[s].second) stk[++ tt] = path[s].first; while (tt \u003e= 0) cout \u003c\u003c stk[tt --]; return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:4:1","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"优化-双向BFS 首先考虑 $a^b$ 与 $2 × a^{\\frac{b}{2}}$ 的大小关系。 $\\frac{a^b}{2 × a^{\\frac{b}{2}}} = \\frac{a^{\\frac{b}{2}}}{2}$, 即两者的大小关系取决于 $\\frac{b}{2}$ 和 $2$ 的大小关系 现实问题中绝大多数情况是$\\frac{b}{2} \u003e 2$，即 $a^b \u003e 2 × a^{\\frac{b}{2}}$ $a^b \u003e 2 × a^{\\frac{b}{2}}$ 就清晰地阐述了一般BFS同双向BFS的关系。一般BFS采用的单向搜索，状态数量的增加并非是线性级别的，而是指数级别的，就类似下图这样，搜到终点时，开口已经非常大了，这就意味着无效搜索非常多。 双向BFS是指从起点和终点同时向中间搜索(注意这里说的同时并非指同步)，对于每一部分，都可以避免随指数级别增加的状态数量的大幅增加，从而加快搜索速度。 题目描述 给定两个字符串A, B和一组字符串变换的规则,询问从A变换到B最少需要几次变换 字符串变换规则abc-\u003exu指: 字符串中的abc可以替换为xu 题目分析 如果按照单向搜索的一般BFS来做，本题和一般做法中所提及的题目解法思路完全相同。 如果按照双向BFS来做，搜索方向应在起点到终点和终点到起点二者中选择当前搜索队列中数量较少的，以减少搜索的状态数量，其余过程与单向搜索相同 解题代码(C++) 单向BFS： /** * 搜索的思路并不难想到，每一个状态都是一个字符串 * 向外拓展就是使用每一个规则进行替换 * 难点在于如何使用每一个规则 * * 看完讲解发现是自己想复杂了，规则的使用就是字符串的一般处理，不会涉及到什么复杂的字符串算法，觉得复杂完全是畏惧心里，就像此前面对树和图的问题一样 * * 本题的核心考点显然不是变换规则如何使用。由于状态数量过多，一般的bfs会超时，应当从起点和终点同时向中间搜索， * 如果是单向搜索，状态数量的增加并不是线性级别的，而是指数级别的，单向搜索与从两端向中间搜索的差别类似a^b与2*a^(b/2)的差别 * 会大幅度减少搜索的状态数量，为了更加清晰的理解，首先实现一下单向bfs * * 写完代码真的发现，感觉字符串问题较难不是我的错觉，是真的和其它问题不一样，在一些问题上很容易就想错或想不明白 */ // 单向bfs #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003cqueue\u003e #include \u003cunordered_map\u003e using namespace std; const int N = 10; int n; string A, B; string a[N], b[N]; queue\u003cstring\u003e q; unordered_map\u003cstring, int\u003e dis; /** * 第一次写遇到一个问题是在用a替换为b时只替换了第一个a就直接返回了 * 写之前确实想到了这个问题，如果有多个匹配的a怎么办 * 实际是当前只替换1个，放进队列后再遇到这个自然就会继续替换，替换1个，2个，。。。的情况都可以搜索到 * 但是如果有多个位置匹配，虽然说只替换一个，但是要将替换每一个位置的情况全部放进队列，而非第一个匹配的位置 */ void extend(string t, string a, string b) // 把t中a的部分换为b { for (int i = 0; i \u003c t.size(); ++ i) if (t.substr(i, a.size()) == a) { string ex = t.substr(0, i) + b + t.substr(i + a.size()); if (dis.count(ex)) continue; q.push(ex); dis[ex] = dis[t] + 1; } } int bfs() { q.push(A); dis[A] = 0; while (q.size()) { string t = q.front(); q.pop(); if (t == B) return dis[t]; for (int i = 0; i \u003c n; ++ i) extend(t, a[i], b[i]); } return 11; } int main() { cin \u003e\u003e A \u003e\u003e B; while (cin \u003e\u003e a[n] \u003e\u003e b[n]) ++ n; int t = bfs(); if (t \u003e 10) cout \u003c\u003c \"NO ANSWER!\" \u003c\u003c endl; else cout \u003c\u003c t \u003c\u003c endl; return 0; } 双向BFS： /** * 双向bfs作为bfs的优化 * 主要应用于最小步数模型中，即待搜索状态数极大的问题中 * 棋盘中的路径问题不需要使用双向bfs是因为格点数目不会很大，搜索耗时较少 * * 双向bfs就是从起点和终点同时向中间搜索，从数学角度来看能够大幅度减少搜索的状态数量 * 每次从元素数量较少的队列中取元素 */ #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e #include \u003ccstring\u003e #include \u003cqueue\u003e #include \u003cunordered_map\u003e using namespace std; const int N = 10; int n; string A, B; string a[N], b[N]; queue\u003cstring\u003e qa, qb; unordered_map\u003cstring, int\u003e da, db; /** * 考虑q队列，里面元素的距离为da，另一队列中元素距离为db，将其中的a替换为b * 这里必须要加上da，db，否则我们不知道q队列的元素t的距离到底是da[t]还是db[t] */ int extend(queue\u003cstring\u003e \u0026q, unordered_map\u003cstring, int\u003e \u0026da, unordered_map\u003cstring, int\u003e \u0026db, string a[], string b[]) { // 我们要做的是将当前q中的元素全部拓展一遍，但是这样写会将拓展后的点也会被遍历 // while (q.size()) for (int k = 0, qs = q.size(); k \u003c qs; ++ k) { string t = q.front(); q.pop(); for (int i = 0; i \u003c t.size(); ++ i) for (int j = 0; j \u003c n; ++ j) if (t.substr(i, a[j].size()) == a[j]) { string state = t.substr(0, i) + b[j] + t.substr(i + a[j].size()); if (da.count(state)) continue; if (db.count(state)) return da[t] + 1 + db[state] ; // 已经找到交点就可以返回距离了, da[t] + 1就是da[state]，因为此时da[state]还没有更新所以用da[t] da[state] = da[t] + 1; q.push(state); } } return 11; // q在拓展时并没有找到交点 } int bfs() { qa.push(A); da[A] = 0; qb.push(B); db[B] = 0; /** * 有解的条件是从起点向终点走和从终点向起点走应该能够走到同一个状态 * 如果某个方向已经走完了还没有相遇就说明无解 * 上面这个结论为什么是正确的？ * 为了叙述的方便，我们定义从起点向终点走为方向a，从终点向起点走为方向b， * 我考虑一种情况为若b已经把所有情况都搜索完了，a还没有搜索完，此时还没遇到交点(交点就是a和b都走过的某个状态，显然起点和终点都算是交点)，会不会可能交点在b中，但是a还没有走到交点 * 这种想法是错误的，原因在于如果问题是有解的，那么单从b方向而言，最终一定是可以到达起点的 * 就算是a方向上完全没有动，单从b方向也一定是可以走到起点的，这就变为了单向bfs * 而b的所有情况都搜索完成后并没有找到交点(这其中可是包含起点的)，说明起点与终点之间是不存在通路的，即无解 * * 所以bfs的条件是两个队列均不为空，在这期间如果找到了答案说明有解，某个队列已经空了还没找到答案说明无解 */ while (qa.size() \u0026\u0026 qb.size()) { int t; if (qa.size() \u003c= qb.size()) t = extend(qa, da, db, a, b); // 对于qa 将a替换为b else t = extend(qb, db, da, b, a); if (t \u003c= 10) return t; } return 11; } int main() { cin \u003e\u003e A \u003e\u003e B; while (cin \u003e\u003e a[n] \u003e\u003e b[n]) ++ n; int t = bfs(); if (t \u003e 10) cout \u003c\u003c \"NO ANSWER!\" \u003c\u003c endl; else cout \u003c\u003c t \u003c\u003c endl; return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:4:2","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"优化-A* 如何理解A* A*作为一种优化，必然是针对一般BFS的某个缺点而产生的。在最小步数问题中，搜索空间可能非常大，以至于使用双向BFS仍然会超时。这是因为双向BFS的优化只是从数学维度降低了搜索空间的大小，搜索逻辑和一般BFS相比并没有发生改变，它们采用的逻辑均为首先搜索距离起点较近的状态，但这些状态到终点的距离可能很大，综合来看它们并非最终答案。优先搜索这些状态浪费了大量时间，A*就是将这种仅考察局部因素的搜索策略改为考察全局因素，不仅参考前段路长度还参考后段路径长度，即优先搜索那些距离起点路径长度+距离终点距离长度更小的状态，这些状态显然更容易到达终点。 从代码实现上来看，A*将一般BFS采用的队列更改为优先队列。队列只有在路径长度均相等的情况下才可以保证序列的两段性和单调性，即保证搜索的正确性。但距离起点路径长度+距离终点距离长度显然不会全部相等，同时搜索是具备优先级的，所以需要使用优先队列 从逻辑上来看，A*引入了一个估价函数，从而改变了BFS的搜索顺序。从起点a走到状态b，b距离a的距离是已知的，但到达终点的距离是未知的，但是我们需要使用这个值来判断搜索的优先级，所以引入了估价函数作为某个状态到达终点的预估距离。预估距离并不会计算到答案上，它只是改变了搜索的顺序 估价函数 从上述分析中可以得知，A*的关键在于找到估价函数。估价函数的选取有以下两点规则和性质 估价值与真实值偏差越小，优化效果越好 这并不难理解，当估价值$==$真实值时，搜索路径就是最佳路径，直接走到终点 $估价值≤真实值$ 考虑有两个状态$a$和$b$，从$a$和$b$均可以到达终点，$两者的估价值均分别\u003e其自身真实值$，并有$估价值a\u003e估价值b$，$真实值a\u003c真实值b$，根据估价值，首先搜索状态b，并搜索到终点，搜索过程结束。显然得到的结果是错误的，从状态a到达终点可以获取到更短距离，但由于$a的估价值\u003eb的估价值$，所以选择了错误的搜索顺序。所以保证$估价值≤真实值$的意义在于当$a的真实值\u003cb的真实值$时，可以保证$a的估价值\u003cb的估价值$；当$a的真实值\u003eb的真实值$时，即$b的真实值\u003ca的真实值$时，保证$b的估价值\u003ca的估价值$，无论在以上哪种情况下， 都可以保证根据估价值的大小选择的搜索路径一定是正确的。 需要注意的是在$2$的讨论中，根据真实值的大小关系可以得到估价值的大小关系，但反之是不成立的。在上述证明中，我们考虑了$a的真实值\u003cb的真实值$和$a的真实值\u003eb的真实值$两种情况，这两种情况已经包含了所有可能，并且在$估价值≤真实值$的条件下，可以确定这两种情况均可得到正确答案，所以证明是正确的。但实际执行过程是根据估价值的大小关系确定搜索的先后顺序，但是估价值小的状态真实值可能更大，但最终仍可得到正确答案，考虑两个状态a和b，满足$估价值a\u003c估价值b$，$真实值a\u003e真实值b$，从a开始搜索，虽然走了错误的路径，但在终点未出队之前某个状态c(该状态可能是终点，当a和b与终点直接相连时，这里的状态就是指终点)的估价值一定会\u003eb的估价值($估价值≤真实值$，$真实值b\u003c真实值c$，所以可得$估价值b\u003c估价值c$)，所以一定会从b再走一次以完成修正的过程。 需要关注的问题 A*只有在保证有解时具有较高的搜索效率，无解时甚至不如一般BFS效率高。这是由于，在无解时A*与一般BFS一样要搜索完搜索可搜索状态，但BFS采用的是队列，读写均为$O(1)$，但是A*采用优先队列，堆中的写操作是$O(logn)$的，所以效率反而会更差一些。这就解释了在下面的A*代码中为何要首先判断是否有解才开始进行搜索。 当然在实际问题中很难在解决问题之前就判断出是否有解，采用A*也只能是一般做法无法解决，抱着一种试试看的态度 题目描述 在一个 $3×3$ 的网格中，$1∼8$ 这 $8$ 个数字和一个 X 恰好不重不漏地分布在这 $3×3$ 的网格中。 例如： 1 2 3 X 4 6 7 5 8 可以把 X 与其上、下、左、右四个方向之一的数字交换（如果存在） 目的是通过交换，使得网格变为如下排列（称为正确排列）： 1 2 3 4 5 6 7 8 X 把 X 与上下左右方向数字交换的行动记录为 u、d、l、r 给你一个初始网格，询问最少通过几次移动可以得到正确排列，若存在解决方案，则输出得到正确排列的完整行动记录，如果答案不唯一，输出任意一种合法方案。如果不存在解决方案，则输出 unsolvable 题目分析 为何采用A*而非一般BFS在上述A*的介绍中已经提到，这里不再赘述，直接考虑A*的实现方式。 关键在于确定估价函数以保证$估价值≤真实值$.对于一个状态，变换为正确排列需要把每个数移动到正确位置，仅对一个数而言，移动到目标位置最少的移动次数是当前位置距离目标位置的曼哈顿距离，所以我们考虑将所有数距离各自目标位置的曼哈顿距离求和作为估价值，一定能够保证$估价值≤真实值$，因为仅对一个数而言最少移动次数是曼哈顿距离，但多个数同时考虑可能需要一些额外操作，$真实值是\\geq曼哈顿距离和$的。 对于八数码问题，一定有解的充要条件为将二维数组按照行优先的顺序从左到右依次读取获得的序列的逆序对数量一定为偶数 必要性证明(问题有解说明逆序对数量一定为偶数)：因为行内移动不会改变逆序对，行间移动对于逆序对数量的改变为偶数，所以任何变换都不会改变序列逆序对数量的奇偶，目标序列的逆序对数量为0，即偶数，所以只有当初始状态序列的逆序对数量为偶数时才有可能化为目标状态 充分性证明(初始逆序对数量为偶数则问题一定有解)：较难证明 解题代码(C++) 一般BFS: #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003cqueue\u003e #include \u003cunordered_map\u003e using namespace std; string bfs(string start) { string end = \"12345678x\"; queue\u003cstring\u003e q; unordered_map\u003cstring, int\u003e dis; unordered_map\u003cstring, pair\u003cstring, char\u003e\u003e prev; char op[] = {'u', 'r', 'd', 'l'}; int dx[] = {-1, 0, 1, 0}, dy[] = {0, 1, 0, -1}; q.push(start); dis[start] = 0; while (q.size()) { string t = q.front(); q.pop(); int k = t.find('x'); int x = k / 3, y = k % 3; if (t == end) { string res(\"\"); while (end != start) { res += prev[end].second; end = prev[end].first; } reverse(res.begin(), res.end()); return res; } for (int i = 0; i \u003c 4; ++ i) { int a = x + dx[i], b = y + dy[i]; string str(t); swap(str[k], str[a * 3 + b]); string state =str; if (a \u003c 0 || a \u003e= 3 || b \u003c 0 || b \u003e= 3) continue; if (dis.count(state)) continue; dis[state] = dis[t] + 1; prev[state] = {t, op[i]}; q.push(state); } } return \"unsolvable\"; } int main() { string start(\"\"); char c; while (cin \u003e\u003e c) start += c; string t = bfs(start); cout \u003c\u003c t \u003c\u003c endl; return 0; } A*优化 #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003cqueue\u003e #include \u003cunordered_map\u003e using namespace std; int f(string state) // 估价函数-获取状态state的估价值 { int res = 0; for (int i = 0; i \u003c state.size(); ++ i) if (state[i] != 'x') { int t = state[i] - '1'; res += abs(i / 3 - t / 3) + abs(i % 3 - t % 3); } return res; } string bfs(string start) { string end = \"12345678x\"; char op[] = {'u', 'r', 'd', 'l'}; int dx[] = {-1, 0, 1, 0}, dy[] = {0, 1, 0, -1}; unordered_map\u003cstring, int\u003e dis; unordered_map\u003cstring, pair\u003cstring, char\u003e\u003e prev; priority_queue\u003cpair\u003cint, string\u003e, vector\u003cpair\u003cint, string\u003e\u003e, greater\u003cpair\u003cin","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:4:3","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"多源BFS 题目描述 给定一个 $N$ 行 $M$ 列的 $01$ 矩阵 $A$，$A[i][j]$ 与 $A[k][l]$ 之间的曼哈顿距离定义为： $dist(A[i][j],A[k][l])=|i−k|+|j−l|$ 输出一个 $N$ 行 $M$ 列的整数矩阵 $B$，其中： $B[i][j]=min_{1≤x≤N,1≤y≤M,A[x][y]=1}dist(A[i][j],A[x][y])$ 题目分析 题目通俗地讲就是求矩阵中所有0距离1的最小曼哈顿距离 正向思路是遍历矩阵,从所有0开始BFS求距离1的最短距离,结果没有错误但是会TLE 俗话说\"正向求解困难就尝试反向求解\" 反向思路显然是从所有1开始BFS,过程中更新各个0的答案,这样做的正确性证明是比较难想的.很巧妙地是引入一个虚拟源点的概念,该点距离所有1的距离均为0.对所有0而言,距离1的最近距离即为距离虚拟源点的最近距离.所以问题已经转变为从虚拟源点开始的单源最短路问题,即Dijkstra.Dijkstra是正确的,所以显然该做法也是正确的. 解题代码(C++) 正向求解: #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e using namespace std; typedef pair\u003cint, int\u003e PII; const int N = 1010, M = N * N; int n, m; int g[N][N]; char ch[N][N]; PII q[M]; bool st[N][N]; int dis[N][N], step; void bfs(int sx, int sy) { int hh = 0, tt = -1; int dx[] = {-1, 0, 1, 0}; int dy[] = {0, 1, 0, -1}; memset(st, 0, sizeof st); st[sx][sy] = true; q[++ tt] = {sx, sy}; step = 0; while (tt \u003e= hh) { int size = tt - hh + 1; while (size --) { PII t = q[hh ++]; int a = t.first, b = t.second; if (g[a][b]) { dis[sx][sy] = step; return ; } for (int i = 0; i \u003c 4; ++ i) { int x = a + dx[i], y = b + dy[i]; if (x \u003c 0 || x \u003e= n || y \u003c 0 || y \u003e= m || st[x][y]) continue; st[x][y] = true; q[++ tt] = {x, y}; } } ++ step; } } int main() { cin \u003e\u003e n \u003e\u003e m; for (int i = 0; i \u003c n; ++ i) cin \u003e\u003e ch[i]; for (int i = 0; i \u003c n; ++ i) for (int j = 0; j \u003c m; ++ j) g[i][j] = ch[i][j] - '0'; for (int i = 0; i \u003c n; ++ i) for (int j = 0; j \u003c m; ++ j) if (!g[i][j]) bfs(i, j); for (int i = 0; i \u003c n; ++ i) { for (int j = 0; j \u003c m; ++ j) cout \u003c\u003c dis[i][j] \u003c\u003c ' '; cout \u003c\u003c endl; } return 0; } 反向求解: #include \u003ciostream\u003e #include \u003calgorithm\u003e #include \u003ccstring\u003e using namespace std; typedef pair\u003cint, int\u003e PII; const int N = 1010, M = N * N; int n, m; char g[N][N]; int dis[N][N]; PII q[M]; void bfs() { int dx[] = {-1, 0, 1, 0}, dy[] = {0, 1, 0, -1}; int hh = 0, tt = -1; memset(dis, -1, sizeof dis); for (int i = 0; i \u003c n; ++ i) for (int j = 0; j \u003c m; ++ j) if (g[i][j] == '1') { dis[i][j] = 0; q[++ tt] = {i, j}; } while (tt \u003e= hh) { PII t = q[hh ++]; int a = t.first, b = t.second; for (int i = 0; i \u003c 4; ++ i) { int x = a + dx[i], y = b + dy[i]; if (x \u003c 0 || x \u003e= n || y \u003c 0 || y \u003e= m || dis[x][y] != -1) continue; dis[x][y] = dis[a][b] + 1; q[++ tt] = {x, y}; } } } int main() { cin \u003e\u003e n \u003e\u003e m; for (int i = 0; i \u003c n; ++ i) cin \u003e\u003e g[i]; bfs(); for (int i = 0; i \u003c n; ++ i) { for (int j = 0; j \u003c m; ++ j) cout \u003c\u003c dis[i][j] \u003c\u003c ' '; cout \u003c\u003c endl; } return 0; } ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:5:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"},{"categories":["Algorithm"],"content":"区别与联系 这里主要讨论Dijkstra，一般BFS，双端队列BFS和A*之间的区别和联系 联系 无论使用哪种解决方法，本质上解决的都是单源最短路问题，所以本质上均为Dijkstra的思想 区别 算法 特征 Dijkstra(堆优化版) 入队多次，每个点第一次出队时即为最短路径 一般BFS 入队一次，每个点第一次出队时即为最短路径 双端队列BFS 入队多次，每个点第一次出队时即为最短路径 A* 入队多次，除终点外其余点出队时均不一定为最短路径，终点第一次出队即为最短路径 虽然本质上均采用的Dijkstra算法思想，但是由于条件的不同实际的执行过程也不相同，接下来对一般BFS，双端队列BFS和A*进行分别论述 某个点可以被放入对队列说明该点的距离值得到更新 一般BFS 入队一次的原因在于路径长度唯一(假设为1)，队列中有两个点a和b，两者到c点的距离均为1，若$d_a == d_b$,显然$d_a + 1 = d_b + 1$，由于扩展出的距离相等，所以c点仅需入队一次，若$d_a \u003c d_b$，显然$d_a + 1 \u003c d_b + 1$，第一次入队后第二次距离不需要更新所以仍是仅入队一次。 在最短路问题中已经证明了每个点出队时对应的路径即为最短路径，这里不再赘述 双端队列BFS 入队多次的原因在于路径长度不唯一(假设为0和1)，队列中有两个点$d_a == d_b$，两种到c点的距离分别为1和0，显然$d_a + 1 \u003e d_b + 0$，所以c点就会两次入队。 与一般BFS一样具有两段性和单调性，所以可证明得到每个点第一次出队时即为最短路径(证明方法与一般BFS相同) A* 入队多次的原因在于路径长度不唯一 由于我们搜索顺序的依据始终是距离终点的预估距离，优先搜索的是距离终点预估距离小的点，而预估距离是考虑的是全段而非仅仅是距离起点的距离，所以只能保证终点出对时得到最短距离，其余点均无法得到保证 ","date":"2021-04-08","objectID":"/blog/posts/algorithm/bfs/:6:0","tags":["BFS"],"title":"BFS总结","uri":"/blog/posts/algorithm/bfs/"}]